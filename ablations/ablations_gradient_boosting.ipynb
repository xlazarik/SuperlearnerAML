{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56047412-109f-4f00-bbbc-e4f06cadd9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e895586-1274-4b13-a031-4c799015d1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -f http://h2o-release.s3.amazonaws.com/h2o/latest_stable_Py.html h2o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ebe00c0-b3d2-4ca5-aa70-dde4ad6ebcef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install altair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "668aebb2-473c-4835-a538-b773ff24348c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321. connected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "\n",
       "#h2o-table-1.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-1 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-1 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-1 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-1 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-1 .h2o-table th,\n",
       "#h2o-table-1 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-1 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-1\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption></caption>\n",
       "    <thead></thead>\n",
       "    <tbody><tr><td>H2O_cluster_uptime:</td>\n",
       "<td>4 days 0 hours 19 mins</td></tr>\n",
       "<tr><td>H2O_cluster_timezone:</td>\n",
       "<td>Europe/Prague</td></tr>\n",
       "<tr><td>H2O_data_parsing_timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O_cluster_version:</td>\n",
       "<td>3.46.0.6</td></tr>\n",
       "<tr><td>H2O_cluster_version_age:</td>\n",
       "<td>2 months and 8 days</td></tr>\n",
       "<tr><td>H2O_cluster_name:</td>\n",
       "<td>H2O_from_python_vladi_8uz4d9</td></tr>\n",
       "<tr><td>H2O_cluster_total_nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O_cluster_free_memory:</td>\n",
       "<td>4.897 Gb</td></tr>\n",
       "<tr><td>H2O_cluster_total_cores:</td>\n",
       "<td>16</td></tr>\n",
       "<tr><td>H2O_cluster_allowed_cores:</td>\n",
       "<td>16</td></tr>\n",
       "<tr><td>H2O_cluster_status:</td>\n",
       "<td>locked, healthy</td></tr>\n",
       "<tr><td>H2O_connection_url:</td>\n",
       "<td>http://localhost:54321</td></tr>\n",
       "<tr><td>H2O_connection_proxy:</td>\n",
       "<td>{\"http\": null, \"https\": null}</td></tr>\n",
       "<tr><td>H2O_internal_security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>Python_version:</td>\n",
       "<td>3.11.7 final</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n"
      ],
      "text/plain": [
       "--------------------------  -----------------------------\n",
       "H2O_cluster_uptime:         4 days 0 hours 19 mins\n",
       "H2O_cluster_timezone:       Europe/Prague\n",
       "H2O_data_parsing_timezone:  UTC\n",
       "H2O_cluster_version:        3.46.0.6\n",
       "H2O_cluster_version_age:    2 months and 8 days\n",
       "H2O_cluster_name:           H2O_from_python_vladi_8uz4d9\n",
       "H2O_cluster_total_nodes:    1\n",
       "H2O_cluster_free_memory:    4.897 Gb\n",
       "H2O_cluster_total_cores:    16\n",
       "H2O_cluster_allowed_cores:  16\n",
       "H2O_cluster_status:         locked, healthy\n",
       "H2O_connection_url:         http://localhost:54321\n",
       "H2O_connection_proxy:       {\"http\": null, \"https\": null}\n",
       "H2O_internal_security:      False\n",
       "Python_version:             3.11.7 final\n",
       "--------------------------  -----------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import h2o\n",
    "from h2o.estimators import (\n",
    "    H2OGeneralizedLinearEstimator, \n",
    "    H2ORandomForestEstimator, \n",
    "    H2OGradientBoostingEstimator, \n",
    "    H2ONaiveBayesEstimator,\n",
    "    H2OStackedEnsembleEstimator,\n",
    "    H2ODeepLearningEstimator\n",
    "\n",
    ")\n",
    "from h2o.frame import H2OFrame\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "h2o.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f58eaa-76e0-4f1f-9a27-1f226a47557c",
   "metadata": {},
   "source": [
    "### GLOBAL PRESETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e7bc9feb-07d7-4b1e-8378-4d9f765c0b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "TEST_SIZE = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f58317b-ee47-4476-90cb-9440f0a63c2d",
   "metadata": {},
   "source": [
    "Throughout the project we reference many times the paper: **Practical considerations for specifying a super learner**\n",
    "https://arxiv.org/pdf/2204.06139"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a6973e-a3e7-4b1b-bcda-541feb7a8d63",
   "metadata": {},
   "source": [
    "### DATA LOADING AND PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9d8d9852-ce43-4b48-b1aa-f6701bf176bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "63c2ad27-6da8-404c-9f2c-e4d7cf54b768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "Training set size: 2944\n",
      "Validation set size: 736\n",
      "Testing set size: 921\n"
     ]
    }
   ],
   "source": [
    "spam_data = fetch_openml(data_id=44, as_frame=True)\n",
    "spam_df = spam_data.frame\n",
    "\n",
    "X = spam_df.iloc[:, :-1]  # All columns except the last are features\n",
    "y = spam_df.iloc[:, -1]   # The last column is the target (spam or not)\n",
    "\n",
    "\n",
    "y = y.astype(int)\n",
    "\n",
    "# Split the dataset into training (80%) and testing (20%)\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=TEST_SIZE, random_state=42)\n",
    "\n",
    "# We split the temporary dataset into training and test\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=TEST_SIZE, random_state=42)\n",
    "\n",
    "# We use validation here as test data to compare the individual stacks to not spoil the final test data\n",
    "h2o_train = H2OFrame(pd.DataFrame(X_train).assign(label=y_train.values))\n",
    "h2o_val = H2OFrame(pd.DataFrame(X_val).assign(label=y_val.values))\n",
    "h2o_test = H2OFrame(pd.DataFrame(X_test).assign(label=y_test.values))\n",
    "\n",
    "# Conversion of target columns to categorical\n",
    "h2o_train['label'] = h2o_train['label'].asfactor()\n",
    "h2o_val['label'] = h2o_val['label'].asfactor()\n",
    "h2o_test['label'] = h2o_test['label'].asfactor()\n",
    "\n",
    "print(\"Training set size:\", h2o_train.nrows)\n",
    "print(\"Validation set size:\", h2o_val.nrows)\n",
    "print(\"Testing set size:\", h2o_test.nrows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c91792-1ec8-4fca-b714-c024a9df1177",
   "metadata": {},
   "source": [
    "#### Is SPAM class underepresented?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "820d0484-447e-47d5-a571-b81da3a9ce15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records containing spam: 1813\n",
      "Records not containing spam: 2788\n"
     ]
    }
   ],
   "source": [
    "class_1 = len(spam_df[spam_df['class'] == '1'])\n",
    "class_0 = len(spam_df[spam_df['class'] == '0'])\n",
    "print(f\"Records containing spam: {class_1}\")\n",
    "print(f\"Records not containing spam: {class_0}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a416ec65-3b47-4474-aa36-6e2f04f8694f",
   "metadata": {},
   "source": [
    "#### Computing the effective sample size n_eff (from paper)\n",
    "\n",
    "We have binary data, the prevalence of Y is **p=class_1 / total_size**, subsequently **n_rare=n*min(p, 1-p)**, and finally **n_eff=min(n, 5*n_rare)** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3617cd42-233b-4ace-b2a2-3b5f892f0346",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4601"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = len(spam_df)\n",
    "\n",
    "p = class_1 / n\n",
    "n_rare = n * min(p, 1-p)\n",
    "n_eff = min(n, 5*n_rare)\n",
    "n_eff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50c87ec-b54d-43f4-a51a-19a295ae274f",
   "metadata": {},
   "source": [
    "#### Computing the V for V-fold cross-validation\n",
    "Since n_eff >= 500 but not >= 5000 we should select a value between 20 and 10. We take in account that n_eff is closer to 5000 and so we focus on V slightly higher than 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f9ee561d-d6f0-4583-babe-66fc7835ffe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_FOLDS = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c7f67b-4ad5-4d78-a96a-5b21ba3566c6",
   "metadata": {},
   "source": [
    "### BASE LEARNERS - TRAINING & EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9ee8fbbf-aff0-4cd7-878d-84d6b0f0a07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_evaluate_stack(base_learners, metalearner, h2o_train, h2o_test, X_train):\n",
    "    \n",
    "    # TRAIN BASE LEARNERS\n",
    "    print(\"\\n>>> Training base learners:\\n\")\n",
    "    for name, learner in base_learners.items():\n",
    "        print(f\"    Training {name} with {N_FOLDS}-fold cross-validation...\")\n",
    "        learner.train(x=list(range(X_train.shape[1])), y=\"label\", training_frame=h2o_train)\n",
    "\n",
    "    super_learner = H2OStackedEnsembleEstimator(\n",
    "        base_models=list(base_learners.values()),\n",
    "        metalearner_algorithm=metalearner\n",
    "    )\n",
    "    # TRAIN THE METALEARNER\n",
    "    print(\"\\n>>> Training super learner:\\n\")\n",
    "    super_learner.train(x=list(range(X_train.shape[1])), y=\"label\", training_frame=h2o_train)\n",
    "\n",
    "    # EVAL BASE LEARNERS\n",
    "    print(\"\\n>>> Base learners' results:\\n\")\n",
    "    results = {}\n",
    "    for name, learner in base_learners.items():\n",
    "        performance = learner.model_performance(test_data=h2o_test)\n",
    "        f1_score = performance.F1()[0][1]  \n",
    "        auc_pr = performance.aucpr()      \n",
    "        accuracy = performance.accuracy()[0][1]\n",
    "        results[name] = accuracy\n",
    "        results[name] = {\"F1-Score\": f1_score, \"AUC-PR\": auc_pr, \"Accuracy\": accuracy}\n",
    "        print(f\"    {name} - F1-Score: {f1_score:.4f}, AUC-PR: {auc_pr:.4f}, Accuracy (Test Set): {accuracy:.4f}\")\n",
    "    \n",
    "    # EVAL THE METALEARNER\n",
    "    print(\"\\n>>> Metalearner's results:\\n\")\n",
    "    super_performance = super_learner.model_performance(test_data=h2o_test)\n",
    "    super_accuracy = super_performance.accuracy()[0][1]\n",
    "    super_f1 = super_performance.F1()[0][1]  \n",
    "    super_auc_pr = super_performance.aucpr()  \n",
    "    # print(f\"\\n    Super Learner - F1-Score: {super_f1:.4f}, AUC-PR: {super_auc_pr:.4f} | Super Learner Accuracy: {super_accuracy:.4f}\")\n",
    "    \n",
    "    \n",
    "    # print(\"\\nFinal Results Comparison:\")\n",
    "    # for name, metrics in results.items():\n",
    "    #     print(f\"{name} - F1-Score: {metrics['F1-Score']:.4f}, AUC-PR: {metrics['AUC-PR']:.4f}, Accuracy: {metrics['Accuracy']:.4f}\")\n",
    "        \n",
    "    print(f\"    Super Learner - F1-Score: {super_f1:.4f}, AUC-PR: {super_auc_pr:.4f}, Accuracy: {super_accuracy:.4f}\")\n",
    "    return {\"F1-Score\": super_f1, \"AUC-PR\": super_auc_pr, \"Accuracy\": super_accuracy}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456ea211-3dd9-4845-ab77-c176675b55a8",
   "metadata": {},
   "source": [
    "# Ablation studies\n",
    "\n",
    "In the following we tried a more methodological way of building the stack. \n",
    "We tried two approaches and evaluated their effects on the final test metrics:\n",
    "\n",
    "**1) Building the stack from simpler models adding more complex ones:**\n",
    "\n",
    "In this method we start from a base consisting of simple models which we assume would capture the main / most general pattern in the data.\n",
    "Afterwards we gradually try adding more complex models to extend the stack capabilities to capture more finer intricacies and more complex (perhaps non-linear) relationships in the data and we observe the effect on the test metrics.\n",
    "\n",
    "\n",
    "**1) Building the stack from more complex models adding more general/simple ones:**\n",
    "In this method we start from a base consisting of more complex models which we assume would capture the complex relationships in data well and then\n",
    "we try to bring down the variance by adding simpler models that don't overfit to the data so much.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6198921-0a69-413b-bd7b-257a367ec07a",
   "metadata": {},
   "source": [
    "### A more efficient variant would be training each model only once in case it is present in multiple combinations.\n",
    "\n",
    "Due to the tradeoff between the scope of this project and time capabilities we perform only superficial overview. If the problem would be a topic of major research where the time needed to search the vast hypothesis space is available, we would suggest performing more extensive per-class tests with higher hyperparameter sampling granularity to better observe how they affect the models performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6a3c163d-2c4f-4d80-9e9f-95eb602b1ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_to_complex01 = {                   \n",
    "    \"LogisticRegression_binomial\": H2OGeneralizedLinearEstimator(\n",
    "                        family=\"binomial\", nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "                    ), \n",
    "}\n",
    "\n",
    "simple_to_complex02 = {                   \n",
    "    \"LogisticRegression_binomial\": H2OGeneralizedLinearEstimator(\n",
    "                        family=\"binomial\", nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "                    ), \n",
    "    \"GradientBoosting_10trees\": H2OGradientBoostingEstimator(\n",
    "                        ntrees=10, max_depth=10, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "                    ),   \n",
    "}\n",
    "\n",
    "simple_to_complex03 = {                   \n",
    "    \"LogisticRegression_binomial\": H2OGeneralizedLinearEstimator(\n",
    "                        family=\"binomial\", nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "                    ), \n",
    "    \"GradientBoosting_10trees\": H2OGradientBoostingEstimator(\n",
    "                        ntrees=10, max_depth=10, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "                    ),   \n",
    "    \"GradientBoosting_20trees\": H2OGradientBoostingEstimator(\n",
    "    ntrees=20, max_depth=10, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "),\n",
    "}\n",
    "\n",
    "simple_to_complex04= {                   \n",
    "    \"LogisticRegression_binomial\": H2OGeneralizedLinearEstimator(\n",
    "                        family=\"binomial\", nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "                    ), \n",
    "    \"GradientBoosting_10trees\": H2OGradientBoostingEstimator(\n",
    "                        ntrees=10, max_depth=10, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "                    ),   \n",
    "    \"GradientBoosting_20trees\": H2OGradientBoostingEstimator(\n",
    "    ntrees=20, max_depth=10, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "),\n",
    "    \"GradientBoosting_50trees\": H2OGradientBoostingEstimator(\n",
    "    ntrees=50, max_depth=10, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "),\n",
    "}\n",
    "\n",
    "\n",
    "simple_to_complex05 = {                   \n",
    "    \"LogisticRegression_binomial\": H2OGeneralizedLinearEstimator(\n",
    "                        family=\"binomial\", nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "                    ), \n",
    "    \"GradientBoosting_10trees\": H2OGradientBoostingEstimator(\n",
    "                        ntrees=10, max_depth=10, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "                    ),   \n",
    "    \"GradientBoosting_50trees\": H2OGradientBoostingEstimator(\n",
    "    ntrees=50, max_depth=10, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "),\n",
    "}\n",
    "\n",
    "\n",
    "simple_to_complex06 = {                   \n",
    "    \"LogisticRegression_binomial\": H2OGeneralizedLinearEstimator(\n",
    "                        family=\"binomial\", nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "                    ), \n",
    "    \"GradientBoosting_10trees_unbounded_D\": H2OGradientBoostingEstimator(\n",
    "        ntrees=10, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "    ),\n",
    "}\n",
    "\n",
    "\n",
    "simple_to_complex07 = {                   \n",
    "    \"LogisticRegression_binomial\": H2OGeneralizedLinearEstimator(\n",
    "                        family=\"binomial\", nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "                    ), \n",
    "    \"GradientBoosting_10trees\": H2OGradientBoostingEstimator(\n",
    "                    ntrees=10, max_depth=10, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "                ),   \n",
    "    \"GradientBoosting_10trees_unbounded_D\": H2OGradientBoostingEstimator(\n",
    "        ntrees=10, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "    ),\n",
    "}\n",
    "\n",
    "\n",
    "simple_to_complex08 = {                   \n",
    "    \"LogisticRegression_binomial\": H2OGeneralizedLinearEstimator(\n",
    "                        family=\"binomial\", nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "                    ), \n",
    "    \"GradientBoosting_10trees_unbounded_D\": H2OGradientBoostingEstimator(\n",
    "        ntrees=10, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "    ),\n",
    "    \"GradientBoosting_50trees\": H2OGradientBoostingEstimator(\n",
    "    ntrees=50, max_depth=10, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "),\n",
    "}\n",
    "\n",
    "\n",
    "simple_to_complex09 = {                   \n",
    "    \"LogisticRegression_binomial\": H2OGeneralizedLinearEstimator(\n",
    "                        family=\"binomial\", nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "                    ), \n",
    "    \"GradientBoosting_10trees_unbounded_D\": H2OGradientBoostingEstimator(\n",
    "        ntrees=10, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "    ),\n",
    "    \"GradientBoosting_20trees_unbounded_D\": H2OGradientBoostingEstimator(\n",
    "    ntrees=20, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "),\n",
    "}\n",
    "\n",
    "simple_to_complex10 = {                   \n",
    "    \"LogisticRegression_binomial\": H2OGeneralizedLinearEstimator(\n",
    "                        family=\"binomial\", nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "                    ), \n",
    "    \"GradientBoosting_10trees_unbounded_D\": H2OGradientBoostingEstimator(\n",
    "        ntrees=10, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "    ),\n",
    "    \"GradientBoosting_20trees_unbounded_D\": H2OGradientBoostingEstimator(\n",
    "    ntrees=20, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "),\n",
    "    \"GradientBoosting_50trees_unbounded_D\": H2OGradientBoostingEstimator(\n",
    "    ntrees=50, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "),\n",
    "}\n",
    "\n",
    "gradient_boosting_stacks = [\n",
    "                        simple_to_complex01,\n",
    "                        simple_to_complex02,\n",
    "                        simple_to_complex03,\n",
    "                        simple_to_complex04,\n",
    "                        simple_to_complex05,\n",
    "                        simple_to_complex06,\n",
    "                        simple_to_complex07,\n",
    "                        simple_to_complex08,\n",
    "                        simple_to_complex09,\n",
    "                        simple_to_complex10\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "df9e2da1-4fd3-4ba1-a771-05c08ebe5ab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Training base learners:\n",
      "\n",
      "    Training LogisticRegression_binomial with 12-fold cross-validation...\n",
      "glm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Training super learner:\n",
      "\n",
      "stackedensemble Model Build progress: |██████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Base learners' results:\n",
      "\n",
      "    LogisticRegression_binomial - F1-Score: 0.9160, AUC-PR: 0.9554, Accuracy (Test Set): 0.9334\n",
      "\n",
      ">>> Metalearner's results:\n",
      "\n",
      "    Super Learner - F1-Score: 0.9160, AUC-PR: 0.9554, Accuracy: 0.9334\n",
      "\n",
      ">>> Training base learners:\n",
      "\n",
      "    Training LogisticRegression_binomial with 12-fold cross-validation...\n",
      "glm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting_10trees with 12-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Training super learner:\n",
      "\n",
      "stackedensemble Model Build progress: |██████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Base learners' results:\n",
      "\n",
      "    LogisticRegression_binomial - F1-Score: 0.9160, AUC-PR: 0.9554, Accuracy (Test Set): 0.9334\n",
      "    GradientBoosting_10trees - F1-Score: 0.9186, AUC-PR: 0.9722, Accuracy (Test Set): 0.9348\n",
      "\n",
      ">>> Metalearner's results:\n",
      "\n",
      "    Super Learner - F1-Score: 0.9286, AUC-PR: 0.9778, Accuracy: 0.9429\n",
      "\n",
      ">>> Training base learners:\n",
      "\n",
      "    Training LogisticRegression_binomial with 12-fold cross-validation...\n",
      "glm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting_10trees with 12-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting_20trees with 12-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Training super learner:\n",
      "\n",
      "stackedensemble Model Build progress: |██████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Base learners' results:\n",
      "\n",
      "    LogisticRegression_binomial - F1-Score: 0.9160, AUC-PR: 0.9554, Accuracy (Test Set): 0.9334\n",
      "    GradientBoosting_10trees - F1-Score: 0.9186, AUC-PR: 0.9722, Accuracy (Test Set): 0.9348\n",
      "    GradientBoosting_20trees - F1-Score: 0.9320, AUC-PR: 0.9788, Accuracy (Test Set): 0.9443\n",
      "\n",
      ">>> Metalearner's results:\n",
      "\n",
      "    Super Learner - F1-Score: 0.9386, AUC-PR: 0.9816, Accuracy: 0.9511\n",
      "\n",
      ">>> Training base learners:\n",
      "\n",
      "    Training LogisticRegression_binomial with 12-fold cross-validation...\n",
      "glm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting_10trees with 12-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting_20trees with 12-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting_50trees with 12-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Training super learner:\n",
      "\n",
      "stackedensemble Model Build progress: |██████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Base learners' results:\n",
      "\n",
      "    LogisticRegression_binomial - F1-Score: 0.9160, AUC-PR: 0.9554, Accuracy (Test Set): 0.9334\n",
      "    GradientBoosting_10trees - F1-Score: 0.9186, AUC-PR: 0.9722, Accuracy (Test Set): 0.9348\n",
      "    GradientBoosting_20trees - F1-Score: 0.9320, AUC-PR: 0.9788, Accuracy (Test Set): 0.9443\n",
      "    GradientBoosting_50trees - F1-Score: 0.9472, AUC-PR: 0.9857, Accuracy (Test Set): 0.9579\n",
      "\n",
      ">>> Metalearner's results:\n",
      "\n",
      "    Super Learner - F1-Score: 0.9463, AUC-PR: 0.9831, Accuracy: 0.9579\n",
      "\n",
      ">>> Training base learners:\n",
      "\n",
      "    Training LogisticRegression_binomial with 12-fold cross-validation...\n",
      "glm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting_10trees with 12-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting_50trees with 12-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Training super learner:\n",
      "\n",
      "stackedensemble Model Build progress: |██████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Base learners' results:\n",
      "\n",
      "    LogisticRegression_binomial - F1-Score: 0.9160, AUC-PR: 0.9554, Accuracy (Test Set): 0.9334\n",
      "    GradientBoosting_10trees - F1-Score: 0.9186, AUC-PR: 0.9722, Accuracy (Test Set): 0.9348\n",
      "    GradientBoosting_50trees - F1-Score: 0.9472, AUC-PR: 0.9857, Accuracy (Test Set): 0.9579\n",
      "\n",
      ">>> Metalearner's results:\n",
      "\n",
      "    Super Learner - F1-Score: 0.9463, AUC-PR: 0.9831, Accuracy: 0.9579\n",
      "\n",
      ">>> Training base learners:\n",
      "\n",
      "    Training LogisticRegression_binomial with 12-fold cross-validation...\n",
      "glm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting_10trees_unbounded_D with 12-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Training super learner:\n",
      "\n",
      "stackedensemble Model Build progress: |██████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Base learners' results:\n",
      "\n",
      "    LogisticRegression_binomial - F1-Score: 0.9160, AUC-PR: 0.9554, Accuracy (Test Set): 0.9334\n",
      "    GradientBoosting_10trees_unbounded_D - F1-Score: 0.9062, AUC-PR: 0.9630, Accuracy (Test Set): 0.9266\n",
      "\n",
      ">>> Metalearner's results:\n",
      "\n",
      "    Super Learner - F1-Score: 0.9275, AUC-PR: 0.9722, Accuracy: 0.9416\n",
      "\n",
      ">>> Training base learners:\n",
      "\n",
      "    Training LogisticRegression_binomial with 12-fold cross-validation...\n",
      "glm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting_10trees with 12-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting_10trees_unbounded_D with 12-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Training super learner:\n",
      "\n",
      "stackedensemble Model Build progress: |██████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Base learners' results:\n",
      "\n",
      "    LogisticRegression_binomial - F1-Score: 0.9160, AUC-PR: 0.9554, Accuracy (Test Set): 0.9334\n",
      "    GradientBoosting_10trees - F1-Score: 0.9186, AUC-PR: 0.9722, Accuracy (Test Set): 0.9348\n",
      "    GradientBoosting_10trees_unbounded_D - F1-Score: 0.9062, AUC-PR: 0.9630, Accuracy (Test Set): 0.9266\n",
      "\n",
      ">>> Metalearner's results:\n",
      "\n",
      "    Super Learner - F1-Score: 0.9286, AUC-PR: 0.9778, Accuracy: 0.9429\n",
      "\n",
      ">>> Training base learners:\n",
      "\n",
      "    Training LogisticRegression_binomial with 12-fold cross-validation...\n",
      "glm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting_10trees_unbounded_D with 12-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting_50trees with 12-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Training super learner:\n",
      "\n",
      "stackedensemble Model Build progress: |██████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Base learners' results:\n",
      "\n",
      "    LogisticRegression_binomial - F1-Score: 0.9160, AUC-PR: 0.9554, Accuracy (Test Set): 0.9334\n",
      "    GradientBoosting_10trees_unbounded_D - F1-Score: 0.9062, AUC-PR: 0.9630, Accuracy (Test Set): 0.9266\n",
      "    GradientBoosting_50trees - F1-Score: 0.9472, AUC-PR: 0.9857, Accuracy (Test Set): 0.9579\n",
      "\n",
      ">>> Metalearner's results:\n",
      "\n",
      "    Super Learner - F1-Score: 0.9446, AUC-PR: 0.9853, Accuracy: 0.9565\n",
      "\n",
      ">>> Training base learners:\n",
      "\n",
      "    Training LogisticRegression_binomial with 12-fold cross-validation...\n",
      "glm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting_10trees_unbounded_D with 12-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting_20trees_unbounded_D with 12-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Training super learner:\n",
      "\n",
      "stackedensemble Model Build progress: |██████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Base learners' results:\n",
      "\n",
      "    LogisticRegression_binomial - F1-Score: 0.9160, AUC-PR: 0.9554, Accuracy (Test Set): 0.9334\n",
      "    GradientBoosting_10trees_unbounded_D - F1-Score: 0.9062, AUC-PR: 0.9630, Accuracy (Test Set): 0.9266\n",
      "    GradientBoosting_20trees_unbounded_D - F1-Score: 0.9125, AUC-PR: 0.9693, Accuracy (Test Set): 0.9293\n",
      "\n",
      ">>> Metalearner's results:\n",
      "\n",
      "    Super Learner - F1-Score: 0.9252, AUC-PR: 0.9672, Accuracy: 0.9402\n",
      "\n",
      ">>> Training base learners:\n",
      "\n",
      "    Training LogisticRegression_binomial with 12-fold cross-validation...\n",
      "glm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting_10trees_unbounded_D with 12-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting_20trees_unbounded_D with 12-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting_50trees_unbounded_D with 12-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Training super learner:\n",
      "\n",
      "stackedensemble Model Build progress: |██████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Base learners' results:\n",
      "\n",
      "    LogisticRegression_binomial - F1-Score: 0.9160, AUC-PR: 0.9554, Accuracy (Test Set): 0.9334\n",
      "    GradientBoosting_10trees_unbounded_D - F1-Score: 0.9062, AUC-PR: 0.9630, Accuracy (Test Set): 0.9266\n",
      "    GradientBoosting_20trees_unbounded_D - F1-Score: 0.9125, AUC-PR: 0.9693, Accuracy (Test Set): 0.9293\n",
      "    GradientBoosting_50trees_unbounded_D - F1-Score: 0.9442, AUC-PR: 0.9791, Accuracy (Test Set): 0.9552\n",
      "\n",
      ">>> Metalearner's results:\n",
      "\n",
      "    Super Learner - F1-Score: 0.9412, AUC-PR: 0.9785, Accuracy: 0.9524\n"
     ]
    }
   ],
   "source": [
    "comparative_results_gb = dict()\n",
    "\n",
    "for i, stack in enumerate(gradient_boosting_stacks):\n",
    "    comparative_results_gb[i] = train_evaluate_stack(stack, \"glm\", h2o_train, h2o_val, X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0b6a259e-6a32-4c87-a763-593edd286143",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'F1-Score': 0.9159519725557461,\n",
       "  'AUC-PR': 0.9553716837388596,\n",
       "  'Accuracy': 0.9334239130434783},\n",
       " 1: {'F1-Score': 0.9285714285714286,\n",
       "  'AUC-PR': 0.9777966725342202,\n",
       "  'Accuracy': 0.9429347826086957},\n",
       " 2: {'F1-Score': 0.938566552901024,\n",
       "  'AUC-PR': 0.981637595362014,\n",
       "  'Accuracy': 0.9510869565217391},\n",
       " 3: {'F1-Score': 0.9462738301559792,\n",
       "  'AUC-PR': 0.983060568473683,\n",
       "  'Accuracy': 0.9578804347826086},\n",
       " 4: {'F1-Score': 0.9462738301559792,\n",
       "  'AUC-PR': 0.9831438722446287,\n",
       "  'Accuracy': 0.9578804347826086},\n",
       " 5: {'F1-Score': 0.927487352445194,\n",
       "  'AUC-PR': 0.9722495829289366,\n",
       "  'Accuracy': 0.9415760869565217},\n",
       " 6: {'F1-Score': 0.9285714285714286,\n",
       "  'AUC-PR': 0.9777950552352713,\n",
       "  'Accuracy': 0.9429347826086957},\n",
       " 7: {'F1-Score': 0.9446366782006922,\n",
       "  'AUC-PR': 0.985264566284969,\n",
       "  'Accuracy': 0.9565217391304348},\n",
       " 8: {'F1-Score': 0.9251700680272109,\n",
       "  'AUC-PR': 0.967172674862178,\n",
       "  'Accuracy': 0.9402173913043478},\n",
       " 9: {'F1-Score': 0.9411764705882352,\n",
       "  'AUC-PR': 0.9784765422527536,\n",
       "  'Accuracy': 0.9524456521739131}}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparative_results_gb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "66fade31-9a20-42fe-a1ec-67d12e2e3d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_to_complex01 = {                   \n",
    "    \"NaiveBayes\": H2ONaiveBayesEstimator(nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True), \n",
    "}\n",
    "\n",
    "simple_to_complex02 = {                   \n",
    "\"NaiveBayes\": H2ONaiveBayesEstimator(nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True), \n",
    "    \"GradientBoosting_10trees\": H2OGradientBoostingEstimator(\n",
    "                        ntrees=10, max_depth=10, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "                    ),   \n",
    "}\n",
    "\n",
    "simple_to_complex03 = {                   \n",
    "\"NaiveBayes\": H2ONaiveBayesEstimator(nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True), \n",
    "    \"GradientBoosting_10trees\": H2OGradientBoostingEstimator(\n",
    "                        ntrees=10, max_depth=10, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "                    ),   \n",
    "    \"GradientBoosting_20trees\": H2OGradientBoostingEstimator(\n",
    "    ntrees=20, max_depth=10, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "),\n",
    "}\n",
    "\n",
    "simple_to_complex04= {                   \n",
    "\"NaiveBayes\": H2ONaiveBayesEstimator(nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True), \n",
    "    \"GradientBoosting_10trees\": H2OGradientBoostingEstimator(\n",
    "                        ntrees=10, max_depth=10, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "                    ),   \n",
    "    \"GradientBoosting_20trees\": H2OGradientBoostingEstimator(\n",
    "    ntrees=20, max_depth=10, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "),\n",
    "    \"GradientBoosting_50trees\": H2OGradientBoostingEstimator(\n",
    "    ntrees=50, max_depth=10, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "),\n",
    "}\n",
    "\n",
    "\n",
    "simple_to_complex05 = {                   \n",
    "\"NaiveBayes\": H2ONaiveBayesEstimator(nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True), \n",
    "    \"GradientBoosting_10trees\": H2OGradientBoostingEstimator(\n",
    "                        ntrees=10, max_depth=10, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "                    ),   \n",
    "    \"GradientBoosting_50trees\": H2OGradientBoostingEstimator(\n",
    "    ntrees=50, max_depth=10, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "),\n",
    "}\n",
    "\n",
    "\n",
    "simple_to_complex06 = {                   \n",
    "\"NaiveBayes\": H2ONaiveBayesEstimator(nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True), \n",
    "    \"GradientBoosting_10trees_unbounded_D\": H2OGradientBoostingEstimator(\n",
    "        ntrees=10, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "    ),\n",
    "}\n",
    "\n",
    "\n",
    "simple_to_complex07 = {                   \n",
    "\"NaiveBayes\": H2ONaiveBayesEstimator(nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True), \n",
    "    \"GradientBoosting_10trees\": H2OGradientBoostingEstimator(\n",
    "                    ntrees=10, max_depth=10, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "                ),   \n",
    "    \"GradientBoosting_10trees_unbounded_D\": H2OGradientBoostingEstimator(\n",
    "        ntrees=10, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "    ),\n",
    "}\n",
    "\n",
    "\n",
    "simple_to_complex08 = {                   \n",
    "\"NaiveBayes\": H2ONaiveBayesEstimator(nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True), \n",
    "    \"GradientBoosting_10trees_unbounded_D\": H2OGradientBoostingEstimator(\n",
    "        ntrees=10, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "    ),\n",
    "        \"GradientBoosting_50trees\": H2OGradientBoostingEstimator(\n",
    "    ntrees=50, max_depth=10, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "),\n",
    "}\n",
    "\n",
    "\n",
    "simple_to_complex09 = {                   \n",
    "\"NaiveBayes\": H2ONaiveBayesEstimator(nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True), \n",
    "    \"GradientBoosting_10trees_unbounded_D\": H2OGradientBoostingEstimator(\n",
    "        ntrees=10, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "    ),\n",
    "    \"GradientBoosting_20trees_unbounded_D\": H2OGradientBoostingEstimator(\n",
    "    ntrees=20, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "),\n",
    "}\n",
    "\n",
    "simple_to_complex10 = {                   \n",
    "\"NaiveBayes\": H2ONaiveBayesEstimator(nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True), \n",
    "    \"GradientBoosting_10trees_unbounded_D\": H2OGradientBoostingEstimator(\n",
    "        ntrees=10, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "    ),\n",
    "    \"GradientBoosting_20trees_unbounded_D\": H2OGradientBoostingEstimator(\n",
    "    ntrees=20, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "),\n",
    "    \"GradientBoosting_50trees_unbounded_D\": H2OGradientBoostingEstimator(\n",
    "    ntrees=50, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "),\n",
    "}\n",
    "\n",
    "gradient_boosting_stacks_nbayes = [\n",
    "                        simple_to_complex01,\n",
    "                        simple_to_complex02,\n",
    "                        simple_to_complex03,\n",
    "                        simple_to_complex04,\n",
    "                        simple_to_complex05,\n",
    "                        simple_to_complex06,\n",
    "                        simple_to_complex07,\n",
    "                        simple_to_complex08,\n",
    "                        simple_to_complex09,\n",
    "                        simple_to_complex10\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1643c5c8-087d-4351-b439-72769152c1e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Training base learners:\n",
      "\n",
      "    Training NaiveBayes with 12-fold cross-validation...\n",
      "naivebayes Model Build progress: |███████████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Training super learner:\n",
      "\n",
      "stackedensemble Model Build progress: |██████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Base learners' results:\n",
      "\n",
      "    NaiveBayes - F1-Score: 0.8303, AUC-PR: 0.7914, Accuracy (Test Set): 0.8628\n",
      "\n",
      ">>> Metalearner's results:\n",
      "\n",
      "    Super Learner - F1-Score: 0.8303, AUC-PR: 0.7895, Accuracy: 0.8628\n",
      "\n",
      ">>> Training base learners:\n",
      "\n",
      "    Training NaiveBayes with 12-fold cross-validation...\n",
      "naivebayes Model Build progress: |███████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting_10trees with 12-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Training super learner:\n",
      "\n",
      "stackedensemble Model Build progress: |██████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Base learners' results:\n",
      "\n",
      "    NaiveBayes - F1-Score: 0.8303, AUC-PR: 0.7914, Accuracy (Test Set): 0.8628\n",
      "    GradientBoosting_10trees - F1-Score: 0.9186, AUC-PR: 0.9722, Accuracy (Test Set): 0.9348\n",
      "\n",
      ">>> Metalearner's results:\n",
      "\n",
      "    Super Learner - F1-Score: 0.9194, AUC-PR: 0.9728, Accuracy: 0.9361\n",
      "\n",
      ">>> Training base learners:\n",
      "\n",
      "    Training NaiveBayes with 12-fold cross-validation...\n",
      "naivebayes Model Build progress: |███████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting_10trees with 12-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting_20trees with 12-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Training super learner:\n",
      "\n",
      "stackedensemble Model Build progress: |██████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Base learners' results:\n",
      "\n",
      "    NaiveBayes - F1-Score: 0.8303, AUC-PR: 0.7914, Accuracy (Test Set): 0.8628\n",
      "    GradientBoosting_10trees - F1-Score: 0.9186, AUC-PR: 0.9722, Accuracy (Test Set): 0.9348\n",
      "    GradientBoosting_20trees - F1-Score: 0.9320, AUC-PR: 0.9788, Accuracy (Test Set): 0.9443\n",
      "\n",
      ">>> Metalearner's results:\n",
      "\n",
      "    Super Learner - F1-Score: 0.9410, AUC-PR: 0.9788, Accuracy: 0.9524\n",
      "\n",
      ">>> Training base learners:\n",
      "\n",
      "    Training NaiveBayes with 12-fold cross-validation...\n",
      "naivebayes Model Build progress: |███████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting_10trees with 12-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting_20trees with 12-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting_50trees with 12-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Training super learner:\n",
      "\n",
      "stackedensemble Model Build progress: |██████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Base learners' results:\n",
      "\n",
      "    NaiveBayes - F1-Score: 0.8303, AUC-PR: 0.7914, Accuracy (Test Set): 0.8628\n",
      "    GradientBoosting_10trees - F1-Score: 0.9186, AUC-PR: 0.9722, Accuracy (Test Set): 0.9348\n",
      "    GradientBoosting_20trees - F1-Score: 0.9320, AUC-PR: 0.9788, Accuracy (Test Set): 0.9443\n",
      "    GradientBoosting_50trees - F1-Score: 0.9472, AUC-PR: 0.9857, Accuracy (Test Set): 0.9579\n",
      "\n",
      ">>> Metalearner's results:\n",
      "\n",
      "    Super Learner - F1-Score: 0.9475, AUC-PR: 0.9839, Accuracy: 0.9579\n",
      "\n",
      ">>> Training base learners:\n",
      "\n",
      "    Training NaiveBayes with 12-fold cross-validation...\n",
      "naivebayes Model Build progress: |███████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting_10trees with 12-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting_50trees with 12-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Training super learner:\n",
      "\n",
      "stackedensemble Model Build progress: |██████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Base learners' results:\n",
      "\n",
      "    NaiveBayes - F1-Score: 0.8303, AUC-PR: 0.7914, Accuracy (Test Set): 0.8628\n",
      "    GradientBoosting_10trees - F1-Score: 0.9186, AUC-PR: 0.9722, Accuracy (Test Set): 0.9348\n",
      "    GradientBoosting_50trees - F1-Score: 0.9472, AUC-PR: 0.9857, Accuracy (Test Set): 0.9579\n",
      "\n",
      ">>> Metalearner's results:\n",
      "\n",
      "    Super Learner - F1-Score: 0.9475, AUC-PR: 0.9839, Accuracy: 0.9579\n",
      "\n",
      ">>> Training base learners:\n",
      "\n",
      "    Training NaiveBayes with 12-fold cross-validation...\n",
      "naivebayes Model Build progress: |███████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting_10trees_unbounded_D with 12-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Training super learner:\n",
      "\n",
      "stackedensemble Model Build progress: |██████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Base learners' results:\n",
      "\n",
      "    NaiveBayes - F1-Score: 0.8303, AUC-PR: 0.7914, Accuracy (Test Set): 0.8628\n",
      "    GradientBoosting_10trees_unbounded_D - F1-Score: 0.9062, AUC-PR: 0.9630, Accuracy (Test Set): 0.9266\n",
      "\n",
      ">>> Metalearner's results:\n",
      "\n",
      "    Super Learner - F1-Score: 0.9120, AUC-PR: 0.9644, Accuracy: 0.9321\n",
      "\n",
      ">>> Training base learners:\n",
      "\n",
      "    Training NaiveBayes with 12-fold cross-validation...\n",
      "naivebayes Model Build progress: |███████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting_10trees with 12-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting_10trees_unbounded_D with 12-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Training super learner:\n",
      "\n",
      "stackedensemble Model Build progress: |██████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Base learners' results:\n",
      "\n",
      "    NaiveBayes - F1-Score: 0.8303, AUC-PR: 0.7914, Accuracy (Test Set): 0.8628\n",
      "    GradientBoosting_10trees - F1-Score: 0.9186, AUC-PR: 0.9722, Accuracy (Test Set): 0.9348\n",
      "    GradientBoosting_10trees_unbounded_D - F1-Score: 0.9062, AUC-PR: 0.9630, Accuracy (Test Set): 0.9266\n",
      "\n",
      ">>> Metalearner's results:\n",
      "\n",
      "    Super Learner - F1-Score: 0.9194, AUC-PR: 0.9728, Accuracy: 0.9361\n",
      "\n",
      ">>> Training base learners:\n",
      "\n",
      "    Training NaiveBayes with 12-fold cross-validation...\n",
      "naivebayes Model Build progress: |███████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting_10trees_unbounded_D with 12-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting_50trees with 12-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Training super learner:\n",
      "\n",
      "stackedensemble Model Build progress: |██████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Base learners' results:\n",
      "\n",
      "    NaiveBayes - F1-Score: 0.8303, AUC-PR: 0.7914, Accuracy (Test Set): 0.8628\n",
      "    GradientBoosting_10trees_unbounded_D - F1-Score: 0.9062, AUC-PR: 0.9630, Accuracy (Test Set): 0.9266\n",
      "    GradientBoosting_50trees - F1-Score: 0.9472, AUC-PR: 0.9857, Accuracy (Test Set): 0.9579\n",
      "\n",
      ">>> Metalearner's results:\n",
      "\n",
      "    Super Learner - F1-Score: 0.9472, AUC-PR: 0.9849, Accuracy: 0.9579\n",
      "\n",
      ">>> Training base learners:\n",
      "\n",
      "    Training NaiveBayes with 12-fold cross-validation...\n",
      "naivebayes Model Build progress: |███████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting_10trees_unbounded_D with 12-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting_20trees_unbounded_D with 12-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Training super learner:\n",
      "\n",
      "stackedensemble Model Build progress: |██████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Base learners' results:\n",
      "\n",
      "    NaiveBayes - F1-Score: 0.8303, AUC-PR: 0.7914, Accuracy (Test Set): 0.8628\n",
      "    GradientBoosting_10trees_unbounded_D - F1-Score: 0.9062, AUC-PR: 0.9630, Accuracy (Test Set): 0.9266\n",
      "    GradientBoosting_20trees_unbounded_D - F1-Score: 0.9125, AUC-PR: 0.9693, Accuracy (Test Set): 0.9293\n",
      "\n",
      ">>> Metalearner's results:\n",
      "\n",
      "    Super Learner - F1-Score: 0.9213, AUC-PR: 0.9599, Accuracy: 0.9361\n",
      "\n",
      ">>> Training base learners:\n",
      "\n",
      "    Training NaiveBayes with 12-fold cross-validation...\n",
      "naivebayes Model Build progress: |███████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting_10trees_unbounded_D with 12-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting_20trees_unbounded_D with 12-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting_50trees_unbounded_D with 12-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Training super learner:\n",
      "\n",
      "stackedensemble Model Build progress: |██████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Base learners' results:\n",
      "\n",
      "    NaiveBayes - F1-Score: 0.8303, AUC-PR: 0.7914, Accuracy (Test Set): 0.8628\n",
      "    GradientBoosting_10trees_unbounded_D - F1-Score: 0.9062, AUC-PR: 0.9630, Accuracy (Test Set): 0.9266\n",
      "    GradientBoosting_20trees_unbounded_D - F1-Score: 0.9125, AUC-PR: 0.9693, Accuracy (Test Set): 0.9293\n",
      "    GradientBoosting_50trees_unbounded_D - F1-Score: 0.9442, AUC-PR: 0.9791, Accuracy (Test Set): 0.9552\n",
      "\n",
      ">>> Metalearner's results:\n",
      "\n",
      "    Super Learner - F1-Score: 0.9426, AUC-PR: 0.9774, Accuracy: 0.9538\n"
     ]
    }
   ],
   "source": [
    "comparative_results_gb_nbayes = dict()\n",
    "\n",
    "for i, stack in enumerate(gradient_boosting_stacks_nbayes):\n",
    "    comparative_results_gb_nbayes[i] = train_evaluate_stack(stack, \"glm\", h2o_train, h2o_val, X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d84c2a-8ecd-45f4-b3c3-30df8670b8b8",
   "metadata": {},
   "source": [
    "### RESULTS COMPARISON BETWEEN LOG REGRESSION AND NAIVE BAYES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a8860852-6bd4-43b5-b896-015812aff2b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'F1-Score': 0.9159519725557461,\n",
       "  'AUC-PR': 0.9553716837388596,\n",
       "  'Accuracy': 0.9334239130434783},\n",
       " 1: {'F1-Score': 0.9285714285714286,\n",
       "  'AUC-PR': 0.9777966725342202,\n",
       "  'Accuracy': 0.9429347826086957},\n",
       " 2: {'F1-Score': 0.938566552901024,\n",
       "  'AUC-PR': 0.981637595362014,\n",
       "  'Accuracy': 0.9510869565217391},\n",
       " 3: {'F1-Score': 0.9462738301559792,\n",
       "  'AUC-PR': 0.983060568473683,\n",
       "  'Accuracy': 0.9578804347826086},\n",
       " 4: {'F1-Score': 0.9462738301559792,\n",
       "  'AUC-PR': 0.9831438722446287,\n",
       "  'Accuracy': 0.9578804347826086},\n",
       " 5: {'F1-Score': 0.927487352445194,\n",
       "  'AUC-PR': 0.9722495829289366,\n",
       "  'Accuracy': 0.9415760869565217},\n",
       " 6: {'F1-Score': 0.9285714285714286,\n",
       "  'AUC-PR': 0.9777950552352713,\n",
       "  'Accuracy': 0.9429347826086957},\n",
       " 7: {'F1-Score': 0.9446366782006922,\n",
       "  'AUC-PR': 0.985264566284969,\n",
       "  'Accuracy': 0.9565217391304348},\n",
       " 8: {'F1-Score': 0.9251700680272109,\n",
       "  'AUC-PR': 0.967172674862178,\n",
       "  'Accuracy': 0.9402173913043478},\n",
       " 9: {'F1-Score': 0.9411764705882352,\n",
       "  'AUC-PR': 0.9784765422527536,\n",
       "  'Accuracy': 0.9524456521739131}}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparative_results_gb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c7e533eb-8e7e-4874-8d98-b346b91dae2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'F1-Score': 0.8302521008403362,\n",
       "  'AUC-PR': 0.7894555265975739,\n",
       "  'Accuracy': 0.8627717391304348},\n",
       " 1: {'F1-Score': 0.9193825042881646,\n",
       "  'AUC-PR': 0.9727718440346178,\n",
       "  'Accuracy': 0.936141304347826},\n",
       " 2: {'F1-Score': 0.9409780775716695,\n",
       "  'AUC-PR': 0.9788133400682251,\n",
       "  'Accuracy': 0.9524456521739131},\n",
       " 3: {'F1-Score': 0.9475465313028766,\n",
       "  'AUC-PR': 0.9838830527595532,\n",
       "  'Accuracy': 0.9578804347826086},\n",
       " 4: {'F1-Score': 0.9475465313028766,\n",
       "  'AUC-PR': 0.9838812882449601,\n",
       "  'Accuracy': 0.9578804347826086},\n",
       " 5: {'F1-Score': 0.9119718309859155,\n",
       "  'AUC-PR': 0.964425069604786,\n",
       "  'Accuracy': 0.9320652173913043},\n",
       " 6: {'F1-Score': 0.9193825042881646,\n",
       "  'AUC-PR': 0.9728081571984101,\n",
       "  'Accuracy': 0.936141304347826},\n",
       " 7: {'F1-Score': 0.9471890971039182,\n",
       "  'AUC-PR': 0.9848699071120667,\n",
       "  'Accuracy': 0.9578804347826086},\n",
       " 8: {'F1-Score': 0.9212730318257957,\n",
       "  'AUC-PR': 0.9598894331390697,\n",
       "  'Accuracy': 0.936141304347826},\n",
       " 9: {'F1-Score': 0.9425675675675677,\n",
       "  'AUC-PR': 0.9774254151742999,\n",
       "  'Accuracy': 0.9538043478260869}}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparative_results_gb_nbayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67de3b8a-d776-456f-af28-978a59480473",
   "metadata": {},
   "source": [
    "### LEGEND EXPLANATION\n",
    "#### LR - Logistic Regression\n",
    "#### GBX - Gradient Boosting X trees (max depth=10)\n",
    "#### GBXu - Gradient Boosting X trees (unbounded depth)\n",
    "#### NB - Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2f29d686-e643-4c43-95bf-4eab67d20f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"LR\", \"LR_GB10\", \"LR_GB10_GB20\", \"LR_GB10_GB20_GB50\", \"LR_GB10_GB50\", \"LR_GB10u\", \"LR_GB10_GB10u\", \"LR_GB50_GB10u\", \"LR_GB10u_GB20u\", \"LR_GB10u_GB20u_GB50u\"]\n",
    "\n",
    "data = []\n",
    "for label, record in zip(labels, comparative_results_gb.values()):\n",
    "    record[\"Configuration\"] = label\n",
    "    data.append(record)\n",
    "data\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "da30d39b-f18d-4dfd-8316-e8cb6dd4c4b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-98f34de706fc4a36aa1a592af0bdf38c.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-98f34de706fc4a36aa1a592af0bdf38c.vega-embed details,\n",
       "  #altair-viz-98f34de706fc4a36aa1a592af0bdf38c.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-98f34de706fc4a36aa1a592af0bdf38c\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-98f34de706fc4a36aa1a592af0bdf38c\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-98f34de706fc4a36aa1a592af0bdf38c\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.8.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.8.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"hconcat\": [{\"mark\": {\"type\": \"point\", \"fill\": \"orange\", \"stroke\": \"orange\"}, \"encoding\": {\"x\": {\"field\": \"AUC-PR\", \"scale\": {\"zero\": false}, \"type\": \"quantitative\"}, \"y\": {\"field\": \"Configuration\", \"sort\": \"-x\", \"type\": \"nominal\"}}, \"width\": 150}, {\"mark\": {\"type\": \"point\", \"fill\": \"blue\"}, \"encoding\": {\"x\": {\"field\": \"F1-Score\", \"scale\": {\"zero\": false}, \"type\": \"quantitative\"}, \"y\": {\"field\": \"Configuration\", \"sort\": \"-x\", \"type\": \"nominal\"}}, \"width\": 150}, {\"mark\": {\"type\": \"point\", \"fill\": \"purple\", \"stroke\": \"purple\"}, \"encoding\": {\"x\": {\"field\": \"Accuracy\", \"scale\": {\"zero\": false}, \"type\": \"quantitative\"}, \"y\": {\"field\": \"Configuration\", \"sort\": \"-x\", \"type\": \"nominal\"}}, \"width\": 150}], \"data\": {\"name\": \"data-29e4e2279bfd145bdc51eebbe42360df\"}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.8.0.json\", \"datasets\": {\"data-29e4e2279bfd145bdc51eebbe42360df\": [{\"F1-Score\": 0.9159519725557461, \"AUC-PR\": 0.9553716837388596, \"Accuracy\": 0.9334239130434783, \"Configuration\": \"LR\"}, {\"F1-Score\": 0.9285714285714286, \"AUC-PR\": 0.9777966725342202, \"Accuracy\": 0.9429347826086957, \"Configuration\": \"LR_GB10\"}, {\"F1-Score\": 0.938566552901024, \"AUC-PR\": 0.981637595362014, \"Accuracy\": 0.9510869565217391, \"Configuration\": \"LR_GB10_GB20\"}, {\"F1-Score\": 0.9462738301559792, \"AUC-PR\": 0.983060568473683, \"Accuracy\": 0.9578804347826086, \"Configuration\": \"LR_GB10_GB20_GB50\"}, {\"F1-Score\": 0.9462738301559792, \"AUC-PR\": 0.9831438722446287, \"Accuracy\": 0.9578804347826086, \"Configuration\": \"LR_GB10_GB50\"}, {\"F1-Score\": 0.927487352445194, \"AUC-PR\": 0.9722495829289366, \"Accuracy\": 0.9415760869565217, \"Configuration\": \"LR_GB10u\"}, {\"F1-Score\": 0.9285714285714286, \"AUC-PR\": 0.9777950552352713, \"Accuracy\": 0.9429347826086957, \"Configuration\": \"LR_GB10_GB10u\"}, {\"F1-Score\": 0.9446366782006922, \"AUC-PR\": 0.985264566284969, \"Accuracy\": 0.9565217391304348, \"Configuration\": \"LR_GB50_GB10u\"}, {\"F1-Score\": 0.9251700680272109, \"AUC-PR\": 0.967172674862178, \"Accuracy\": 0.9402173913043478, \"Configuration\": \"LR_GB10u_GB20u\"}, {\"F1-Score\": 0.9411764705882352, \"AUC-PR\": 0.9784765422527536, \"Accuracy\": 0.9524456521739131, \"Configuration\": \"LR_GB10u_GB20u_GB50u\"}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.HConcatChart(...)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import altair as alt\n",
    "\n",
    "f1_chart = alt.Chart(df).mark_point(fill=\"blue\").encode(\n",
    "    y=alt.Y('Configuration', sort=\"-x\"),\n",
    "    x=alt.X('F1-Score').scale(zero=False)\n",
    ").properties(width=150)\n",
    "\n",
    "aucpr_chart = alt.Chart(df).mark_point(fill=\"orange\", stroke=\"orange\").encode(\n",
    "    y=alt.Y('Configuration', sort=\"-x\"),\n",
    "    x=alt.X('AUC-PR').scale(zero=False)\n",
    ").properties(width=150)\n",
    "\n",
    "accuracy_chart = alt.Chart(df).mark_point(fill=\"purple\", stroke=\"purple\").encode(\n",
    "    y=alt.Y('Configuration', sort=\"-x\"),\n",
    "    x=alt.X('Accuracy').scale(zero=False)\n",
    ").properties(width=150)\n",
    "aucpr_chart | f1_chart | accuracy_chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d615145c-f465-4876-a53b-8c8cf92d4ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"NB\", \"NB_GB10\", \"NB_GB10_GB20\", \"NB_GB10_GB20_GB50\", \"NB_GB10_GB50\", \"NB_GB10u\", \"NB_GB10_GB10u\", \"NB_GB50_GB10u\", \"NB_GB10u_GB20u\", \"NB_GB10u_GB20u_GB50u\"]\n",
    "\n",
    "data = []\n",
    "for label, record in zip(labels, comparative_results_gb_nbayes.values()):\n",
    "    record[\"Configuration\"] = label\n",
    "    data.append(record)\n",
    "data\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "55abbef8-e5e0-4f65-9481-17a8487a5eb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-6f5276df56de4d8f8776ae1dc8583f7c.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-6f5276df56de4d8f8776ae1dc8583f7c.vega-embed details,\n",
       "  #altair-viz-6f5276df56de4d8f8776ae1dc8583f7c.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-6f5276df56de4d8f8776ae1dc8583f7c\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-6f5276df56de4d8f8776ae1dc8583f7c\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-6f5276df56de4d8f8776ae1dc8583f7c\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.8.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.8.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"hconcat\": [{\"mark\": {\"type\": \"point\", \"fill\": \"orange\", \"stroke\": \"orange\"}, \"encoding\": {\"x\": {\"field\": \"AUC-PR\", \"scale\": {\"zero\": false}, \"type\": \"quantitative\"}, \"y\": {\"field\": \"Configuration\", \"sort\": \"-x\", \"type\": \"nominal\"}}, \"width\": 150}, {\"mark\": {\"type\": \"point\", \"fill\": \"blue\"}, \"encoding\": {\"x\": {\"field\": \"F1-Score\", \"scale\": {\"zero\": false}, \"type\": \"quantitative\"}, \"y\": {\"field\": \"Configuration\", \"sort\": \"-x\", \"type\": \"nominal\"}}, \"width\": 150}, {\"mark\": {\"type\": \"point\", \"fill\": \"purple\", \"stroke\": \"purple\"}, \"encoding\": {\"x\": {\"field\": \"Accuracy\", \"scale\": {\"zero\": false}, \"type\": \"quantitative\"}, \"y\": {\"field\": \"Configuration\", \"sort\": \"-x\", \"type\": \"nominal\"}}, \"width\": 150}], \"data\": {\"name\": \"data-620ef79152fc4f1df7dffe42bc730649\"}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.8.0.json\", \"datasets\": {\"data-620ef79152fc4f1df7dffe42bc730649\": [{\"F1-Score\": 0.8302521008403362, \"AUC-PR\": 0.7894555265975739, \"Accuracy\": 0.8627717391304348, \"Configuration\": \"NB\"}, {\"F1-Score\": 0.9193825042881646, \"AUC-PR\": 0.9727718440346178, \"Accuracy\": 0.936141304347826, \"Configuration\": \"NB_GB10\"}, {\"F1-Score\": 0.9409780775716695, \"AUC-PR\": 0.9788133400682251, \"Accuracy\": 0.9524456521739131, \"Configuration\": \"NB_GB10_GB20\"}, {\"F1-Score\": 0.9475465313028766, \"AUC-PR\": 0.9838830527595532, \"Accuracy\": 0.9578804347826086, \"Configuration\": \"NB_GB10_GB20_GB50\"}, {\"F1-Score\": 0.9475465313028766, \"AUC-PR\": 0.9838812882449601, \"Accuracy\": 0.9578804347826086, \"Configuration\": \"NB_GB10_GB50\"}, {\"F1-Score\": 0.9119718309859155, \"AUC-PR\": 0.964425069604786, \"Accuracy\": 0.9320652173913043, \"Configuration\": \"NB_GB10u\"}, {\"F1-Score\": 0.9193825042881646, \"AUC-PR\": 0.9728081571984101, \"Accuracy\": 0.936141304347826, \"Configuration\": \"NB_GB10_GB10u\"}, {\"F1-Score\": 0.9471890971039182, \"AUC-PR\": 0.9848699071120667, \"Accuracy\": 0.9578804347826086, \"Configuration\": \"NB_GB50_GB10u\"}, {\"F1-Score\": 0.9212730318257957, \"AUC-PR\": 0.9598894331390697, \"Accuracy\": 0.936141304347826, \"Configuration\": \"NB_GB10u_GB20u\"}, {\"F1-Score\": 0.9425675675675677, \"AUC-PR\": 0.9774254151742999, \"Accuracy\": 0.9538043478260869, \"Configuration\": \"NB_GB10u_GB20u_GB50u\"}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.HConcatChart(...)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_chart = alt.Chart(df).mark_point(fill=\"blue\").encode(\n",
    "    y=alt.Y('Configuration', sort=\"-x\"),\n",
    "    x=alt.X('F1-Score').scale(zero=False)\n",
    ").properties(width=150)\n",
    "\n",
    "aucpr_chart = alt.Chart(df).mark_point(fill=\"orange\", stroke=\"orange\").encode(\n",
    "    y=alt.Y('Configuration', sort=\"-x\"),\n",
    "    x=alt.X('AUC-PR').scale(zero=False)\n",
    ").properties(width=150)\n",
    "\n",
    "accuracy_chart = alt.Chart(df).mark_point(fill=\"purple\", stroke=\"purple\").encode(\n",
    "    y=alt.Y('Configuration', sort=\"-x\"),\n",
    "    x=alt.X('Accuracy').scale(zero=False)\n",
    ").properties(width=150)\n",
    "aucpr_chart | f1_chart | accuracy_chart"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
