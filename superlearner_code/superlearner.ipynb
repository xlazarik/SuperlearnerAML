{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbfa90e8-da3d-4cbd-8adc-4e5147976553",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e895586-1274-4b13-a031-4c799015d1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -f http://h2o-release.s3.amazonaws.com/h2o/latest_stable_Py.html h2o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ebe00c0-b3d2-4ca5-aa70-dde4ad6ebcef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install altair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "668aebb2-473c-4835-a538-b773ff24348c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321..... not found.\n",
      "Attempting to start a local H2O server...\n",
      "; OpenJDK 64-Bit Server VM JBR-11.0.13.7-1751.21-jcef (build 11.0.13+7-b1751.21, mixed mode)\n",
      "  Starting server from D:\\Archivos de programa\\Anaconda3\\envs\\Master_1\\Lib\\site-packages\\h2o\\backend\\bin\\h2o.jar\n",
      "  Ice root: C:\\Users\\david\\AppData\\Local\\Temp\\tmp73tmtmmz\n",
      "  JVM stdout: C:\\Users\\david\\AppData\\Local\\Temp\\tmp73tmtmmz\\h2o_david_started_from_python.out\n",
      "  JVM stderr: C:\\Users\\david\\AppData\\Local\\Temp\\tmp73tmtmmz\\h2o_david_started_from_python.err\n",
      "  Server is running at http://127.0.0.1:54321\n",
      "Connecting to H2O server at http://127.0.0.1:54321 ... successful.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "\n",
       "#h2o-table-1.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-1 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-1 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-1 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-1 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-1 .h2o-table th,\n",
       "#h2o-table-1 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-1 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-1\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption></caption>\n",
       "    <thead></thead>\n",
       "    <tbody><tr><td>H2O_cluster_uptime:</td>\n",
       "<td>04 secs</td></tr>\n",
       "<tr><td>H2O_cluster_timezone:</td>\n",
       "<td>Europe/Paris</td></tr>\n",
       "<tr><td>H2O_data_parsing_timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O_cluster_version:</td>\n",
       "<td>3.46.0.6</td></tr>\n",
       "<tr><td>H2O_cluster_version_age:</td>\n",
       "<td>2 months and 4 days</td></tr>\n",
       "<tr><td>H2O_cluster_name:</td>\n",
       "<td>H2O_from_python_david_9k1xw8</td></tr>\n",
       "<tr><td>H2O_cluster_total_nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O_cluster_free_memory:</td>\n",
       "<td>3.979 Gb</td></tr>\n",
       "<tr><td>H2O_cluster_total_cores:</td>\n",
       "<td>8</td></tr>\n",
       "<tr><td>H2O_cluster_allowed_cores:</td>\n",
       "<td>8</td></tr>\n",
       "<tr><td>H2O_cluster_status:</td>\n",
       "<td>locked, healthy</td></tr>\n",
       "<tr><td>H2O_connection_url:</td>\n",
       "<td>http://127.0.0.1:54321</td></tr>\n",
       "<tr><td>H2O_connection_proxy:</td>\n",
       "<td>{\"http\": null, \"https\": null}</td></tr>\n",
       "<tr><td>H2O_internal_security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>Python_version:</td>\n",
       "<td>3.10.13 final</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n"
      ],
      "text/plain": [
       "--------------------------  -----------------------------\n",
       "H2O_cluster_uptime:         04 secs\n",
       "H2O_cluster_timezone:       Europe/Paris\n",
       "H2O_data_parsing_timezone:  UTC\n",
       "H2O_cluster_version:        3.46.0.6\n",
       "H2O_cluster_version_age:    2 months and 4 days\n",
       "H2O_cluster_name:           H2O_from_python_david_9k1xw8\n",
       "H2O_cluster_total_nodes:    1\n",
       "H2O_cluster_free_memory:    3.979 Gb\n",
       "H2O_cluster_total_cores:    8\n",
       "H2O_cluster_allowed_cores:  8\n",
       "H2O_cluster_status:         locked, healthy\n",
       "H2O_connection_url:         http://127.0.0.1:54321\n",
       "H2O_connection_proxy:       {\"http\": null, \"https\": null}\n",
       "H2O_internal_security:      False\n",
       "Python_version:             3.10.13 final\n",
       "--------------------------  -----------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import h2o\n",
    "from h2o.estimators import (\n",
    "    H2OGeneralizedLinearEstimator, \n",
    "    H2ORandomForestEstimator, \n",
    "    H2OGradientBoostingEstimator, \n",
    "    H2ONaiveBayesEstimator,\n",
    "    H2OStackedEnsembleEstimator,\n",
    "    H2ODeepLearningEstimator\n",
    "\n",
    ")\n",
    "from h2o.frame import H2OFrame\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "h2o.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f58eaa-76e0-4f1f-9a27-1f226a47557c",
   "metadata": {},
   "source": [
    "### GLOBAL PRESETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 696,
   "id": "e7bc9feb-07d7-4b1e-8378-4d9f765c0b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "TEST_SIZE = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f58317b-ee47-4476-90cb-9440f0a63c2d",
   "metadata": {},
   "source": [
    "Throughout the project we reference many times the paper: **Practical considerations for specifying a super learner**\n",
    "https://arxiv.org/pdf/2204.06139"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a6973e-a3e7-4b1b-bcda-541feb7a8d63",
   "metadata": {},
   "source": [
    "### DATA LOADING AND PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d8d9852-ce43-4b48-b1aa-f6701bf176bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 865,
   "id": "63c2ad27-6da8-404c-9f2c-e4d7cf54b768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "Training set size: 2944\n",
      "Validation set size: 736\n",
      "Testing set size: 921\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_freq_make</th>\n",
       "      <th>word_freq_address</th>\n",
       "      <th>word_freq_all</th>\n",
       "      <th>word_freq_3d</th>\n",
       "      <th>word_freq_our</th>\n",
       "      <th>word_freq_over</th>\n",
       "      <th>word_freq_remove</th>\n",
       "      <th>word_freq_internet</th>\n",
       "      <th>word_freq_order</th>\n",
       "      <th>word_freq_mail</th>\n",
       "      <th>...</th>\n",
       "      <th>word_freq_conference</th>\n",
       "      <th>char_freq_%3B</th>\n",
       "      <th>char_freq_%28</th>\n",
       "      <th>char_freq_%5B</th>\n",
       "      <th>char_freq_%21</th>\n",
       "      <th>char_freq_%24</th>\n",
       "      <th>char_freq_%23</th>\n",
       "      <th>capital_run_length_average</th>\n",
       "      <th>capital_run_length_longest</th>\n",
       "      <th>capital_run_length_total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.756</td>\n",
       "      <td>61</td>\n",
       "      <td>278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.048</td>\n",
       "      <td>5.114</td>\n",
       "      <td>101</td>\n",
       "      <td>1028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.010</td>\n",
       "      <td>9.821</td>\n",
       "      <td>485</td>\n",
       "      <td>2259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\n",
       "0            0.00               0.64           0.64           0.0   \n",
       "1            0.21               0.28           0.50           0.0   \n",
       "2            0.06               0.00           0.71           0.0   \n",
       "3            0.00               0.00           0.00           0.0   \n",
       "4            0.00               0.00           0.00           0.0   \n",
       "\n",
       "   word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  \\\n",
       "0           0.32            0.00              0.00                0.00   \n",
       "1           0.14            0.28              0.21                0.07   \n",
       "2           1.23            0.19              0.19                0.12   \n",
       "3           0.63            0.00              0.31                0.63   \n",
       "4           0.63            0.00              0.31                0.63   \n",
       "\n",
       "   word_freq_order  word_freq_mail  ...  word_freq_conference  char_freq_%3B  \\\n",
       "0             0.00            0.00  ...                   0.0           0.00   \n",
       "1             0.00            0.94  ...                   0.0           0.00   \n",
       "2             0.64            0.25  ...                   0.0           0.01   \n",
       "3             0.31            0.63  ...                   0.0           0.00   \n",
       "4             0.31            0.63  ...                   0.0           0.00   \n",
       "\n",
       "   char_freq_%28  char_freq_%5B  char_freq_%21  char_freq_%24  char_freq_%23  \\\n",
       "0          0.000            0.0          0.778          0.000          0.000   \n",
       "1          0.132            0.0          0.372          0.180          0.048   \n",
       "2          0.143            0.0          0.276          0.184          0.010   \n",
       "3          0.137            0.0          0.137          0.000          0.000   \n",
       "4          0.135            0.0          0.135          0.000          0.000   \n",
       "\n",
       "   capital_run_length_average  capital_run_length_longest  \\\n",
       "0                       3.756                          61   \n",
       "1                       5.114                         101   \n",
       "2                       9.821                         485   \n",
       "3                       3.537                          40   \n",
       "4                       3.537                          40   \n",
       "\n",
       "   capital_run_length_total  \n",
       "0                       278  \n",
       "1                      1028  \n",
       "2                      2259  \n",
       "3                       191  \n",
       "4                       191  \n",
       "\n",
       "[5 rows x 57 columns]"
      ]
     },
     "execution_count": 865,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_data = fetch_openml(data_id=44, as_frame=True)\n",
    "spam_df = spam_data.frame\n",
    "\n",
    "X = spam_df.iloc[:, :-1]  # All columns except the last are features\n",
    "y = spam_df.iloc[:, -1]   # The last column is the target (spam or not)\n",
    "\n",
    "\n",
    "y = y.astype(int)\n",
    "\n",
    "# Split the dataset into training (80%) and testing (20%)\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# We split the temporary dataset into training (80%) and validation (20% of temp, i.e., 10% of total)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert to H2O Frames\n",
    "h2o_train = H2OFrame(pd.DataFrame(X_train).assign(label=y_train.values))\n",
    "h2o_val = H2OFrame(pd.DataFrame(X_val).assign(label=y_val.values))\n",
    "h2o_test = H2OFrame(pd.DataFrame(X_test).assign(label=y_test.values))\n",
    "\n",
    "# Convert target columns to categorical\n",
    "h2o_train['label'] = h2o_train['label'].asfactor()\n",
    "h2o_val['label'] = h2o_val['label'].asfactor()\n",
    "h2o_test['label'] = h2o_test['label'].asfactor()\n",
    "\n",
    "# Verify the splits\n",
    "print(\"Training set size:\", h2o_train.nrows)\n",
    "print(\"Validation set size:\", h2o_val.nrows)\n",
    "print(\"Testing set size:\", h2o_test.nrows)\n",
    "# Example of dataset\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ccf1a5b-f7d8-4883-968c-c00631c81b77",
   "metadata": {},
   "source": [
    "## Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a644e1-d993-4c43-b9e5-3f91e7f5e92e",
   "metadata": {},
   "source": [
    "The dataset consists of 58 columns\n",
    "\n",
    "+ 48 columns with the name `words_freq_${WORD}` that indicate the **percentage** (not the frequency but the normalized frequency in the range 0 to 100) of the words in the document that were said word.\n",
    "+ 6 columns with the name `char_freq_${ASCII_CODE}` that indicates the **percentage** of the characters that the character corresponding to that ascii code accounts for.\n",
    "+ 3 columns with the name `capital_run_length_${METRIC}` that indicate the value of that metric for consecutive sequences of capital letters.\n",
    "+ 1 column with the name `type` that indicates wether the message was spam or not.\n",
    "\n",
    "For more detailed information you can go to the [original dataset](https://archive.ics.uci.edu/dataset/94/spambase) from the machine learning repository.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ac78cb1-e88a-4b72-a7b0-6af707e1a280",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_freq_make</th>\n",
       "      <th>word_freq_address</th>\n",
       "      <th>word_freq_all</th>\n",
       "      <th>word_freq_3d</th>\n",
       "      <th>word_freq_our</th>\n",
       "      <th>word_freq_over</th>\n",
       "      <th>word_freq_remove</th>\n",
       "      <th>word_freq_internet</th>\n",
       "      <th>word_freq_order</th>\n",
       "      <th>word_freq_mail</th>\n",
       "      <th>word_freq_receive</th>\n",
       "      <th>word_freq_will</th>\n",
       "      <th>word_freq_people</th>\n",
       "      <th>word_freq_report</th>\n",
       "      <th>word_freq_addresses</th>\n",
       "      <th>word_freq_free</th>\n",
       "      <th>word_freq_business</th>\n",
       "      <th>word_freq_email</th>\n",
       "      <th>word_freq_you</th>\n",
       "      <th>word_freq_credit</th>\n",
       "      <th>word_freq_your</th>\n",
       "      <th>word_freq_font</th>\n",
       "      <th>word_freq_000</th>\n",
       "      <th>word_freq_money</th>\n",
       "      <th>word_freq_hp</th>\n",
       "      <th>word_freq_hpl</th>\n",
       "      <th>word_freq_george</th>\n",
       "      <th>word_freq_650</th>\n",
       "      <th>word_freq_lab</th>\n",
       "      <th>word_freq_labs</th>\n",
       "      <th>word_freq_telnet</th>\n",
       "      <th>word_freq_857</th>\n",
       "      <th>word_freq_data</th>\n",
       "      <th>word_freq_415</th>\n",
       "      <th>word_freq_85</th>\n",
       "      <th>word_freq_technology</th>\n",
       "      <th>word_freq_1999</th>\n",
       "      <th>word_freq_parts</th>\n",
       "      <th>word_freq_pm</th>\n",
       "      <th>word_freq_direct</th>\n",
       "      <th>word_freq_cs</th>\n",
       "      <th>word_freq_meeting</th>\n",
       "      <th>word_freq_original</th>\n",
       "      <th>word_freq_project</th>\n",
       "      <th>word_freq_re</th>\n",
       "      <th>word_freq_edu</th>\n",
       "      <th>word_freq_table</th>\n",
       "      <th>word_freq_conference</th>\n",
       "      <th>char_freq_%3B</th>\n",
       "      <th>char_freq_%28</th>\n",
       "      <th>char_freq_%5B</th>\n",
       "      <th>char_freq_%21</th>\n",
       "      <th>char_freq_%24</th>\n",
       "      <th>char_freq_%23</th>\n",
       "      <th>capital_run_length_average</th>\n",
       "      <th>capital_run_length_longest</th>\n",
       "      <th>capital_run_length_total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.104553</td>\n",
       "      <td>0.213015</td>\n",
       "      <td>0.280656</td>\n",
       "      <td>0.065425</td>\n",
       "      <td>0.312223</td>\n",
       "      <td>0.095901</td>\n",
       "      <td>0.114208</td>\n",
       "      <td>0.105295</td>\n",
       "      <td>0.090067</td>\n",
       "      <td>0.239413</td>\n",
       "      <td>0.059824</td>\n",
       "      <td>0.541702</td>\n",
       "      <td>0.093930</td>\n",
       "      <td>0.058626</td>\n",
       "      <td>0.049205</td>\n",
       "      <td>0.248848</td>\n",
       "      <td>0.142586</td>\n",
       "      <td>0.184745</td>\n",
       "      <td>1.662100</td>\n",
       "      <td>0.085577</td>\n",
       "      <td>0.809761</td>\n",
       "      <td>0.121202</td>\n",
       "      <td>0.101645</td>\n",
       "      <td>0.094269</td>\n",
       "      <td>0.549504</td>\n",
       "      <td>0.265384</td>\n",
       "      <td>0.767305</td>\n",
       "      <td>0.124845</td>\n",
       "      <td>0.098915</td>\n",
       "      <td>0.102852</td>\n",
       "      <td>0.064753</td>\n",
       "      <td>0.047048</td>\n",
       "      <td>0.097229</td>\n",
       "      <td>0.047835</td>\n",
       "      <td>0.105412</td>\n",
       "      <td>0.097477</td>\n",
       "      <td>0.136953</td>\n",
       "      <td>0.013201</td>\n",
       "      <td>0.078629</td>\n",
       "      <td>0.064834</td>\n",
       "      <td>0.043667</td>\n",
       "      <td>0.132339</td>\n",
       "      <td>0.046099</td>\n",
       "      <td>0.079196</td>\n",
       "      <td>0.301224</td>\n",
       "      <td>0.179824</td>\n",
       "      <td>0.005444</td>\n",
       "      <td>0.031869</td>\n",
       "      <td>0.038575</td>\n",
       "      <td>0.139030</td>\n",
       "      <td>0.016976</td>\n",
       "      <td>0.269071</td>\n",
       "      <td>0.075811</td>\n",
       "      <td>0.044238</td>\n",
       "      <td>5.191515</td>\n",
       "      <td>52.172789</td>\n",
       "      <td>283.289285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.305358</td>\n",
       "      <td>1.290575</td>\n",
       "      <td>0.504143</td>\n",
       "      <td>1.395151</td>\n",
       "      <td>0.672513</td>\n",
       "      <td>0.273824</td>\n",
       "      <td>0.391441</td>\n",
       "      <td>0.401071</td>\n",
       "      <td>0.278616</td>\n",
       "      <td>0.644755</td>\n",
       "      <td>0.201545</td>\n",
       "      <td>0.861698</td>\n",
       "      <td>0.301036</td>\n",
       "      <td>0.335184</td>\n",
       "      <td>0.258843</td>\n",
       "      <td>0.825792</td>\n",
       "      <td>0.444055</td>\n",
       "      <td>0.531122</td>\n",
       "      <td>1.775481</td>\n",
       "      <td>0.509767</td>\n",
       "      <td>1.200810</td>\n",
       "      <td>1.025756</td>\n",
       "      <td>0.350286</td>\n",
       "      <td>0.442636</td>\n",
       "      <td>1.671349</td>\n",
       "      <td>0.886955</td>\n",
       "      <td>3.367292</td>\n",
       "      <td>0.538576</td>\n",
       "      <td>0.593327</td>\n",
       "      <td>0.456682</td>\n",
       "      <td>0.403393</td>\n",
       "      <td>0.328559</td>\n",
       "      <td>0.555907</td>\n",
       "      <td>0.329445</td>\n",
       "      <td>0.532260</td>\n",
       "      <td>0.402623</td>\n",
       "      <td>0.423451</td>\n",
       "      <td>0.220651</td>\n",
       "      <td>0.434672</td>\n",
       "      <td>0.349916</td>\n",
       "      <td>0.361205</td>\n",
       "      <td>0.766819</td>\n",
       "      <td>0.223812</td>\n",
       "      <td>0.621976</td>\n",
       "      <td>1.011687</td>\n",
       "      <td>0.911119</td>\n",
       "      <td>0.076274</td>\n",
       "      <td>0.285735</td>\n",
       "      <td>0.243471</td>\n",
       "      <td>0.270355</td>\n",
       "      <td>0.109394</td>\n",
       "      <td>0.815672</td>\n",
       "      <td>0.245882</td>\n",
       "      <td>0.429342</td>\n",
       "      <td>31.729449</td>\n",
       "      <td>194.891310</td>\n",
       "      <td>606.347851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.588000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>35.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.310000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.220000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.065000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.276000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>95.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.380000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.640000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.270000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.110000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.188000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.315000</td>\n",
       "      <td>0.052000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.706000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>266.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.540000</td>\n",
       "      <td>14.280000</td>\n",
       "      <td>5.100000</td>\n",
       "      <td>42.810000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>5.880000</td>\n",
       "      <td>7.270000</td>\n",
       "      <td>11.110000</td>\n",
       "      <td>5.260000</td>\n",
       "      <td>18.180000</td>\n",
       "      <td>2.610000</td>\n",
       "      <td>9.670000</td>\n",
       "      <td>5.550000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>4.410000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>7.140000</td>\n",
       "      <td>9.090000</td>\n",
       "      <td>18.750000</td>\n",
       "      <td>18.180000</td>\n",
       "      <td>11.110000</td>\n",
       "      <td>17.100000</td>\n",
       "      <td>5.450000</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>20.830000</td>\n",
       "      <td>16.660000</td>\n",
       "      <td>33.330000</td>\n",
       "      <td>9.090000</td>\n",
       "      <td>14.280000</td>\n",
       "      <td>5.880000</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>4.760000</td>\n",
       "      <td>18.180000</td>\n",
       "      <td>4.760000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>7.690000</td>\n",
       "      <td>6.890000</td>\n",
       "      <td>8.330000</td>\n",
       "      <td>11.110000</td>\n",
       "      <td>4.760000</td>\n",
       "      <td>7.140000</td>\n",
       "      <td>14.280000</td>\n",
       "      <td>3.570000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>21.420000</td>\n",
       "      <td>22.050000</td>\n",
       "      <td>2.170000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>4.385000</td>\n",
       "      <td>9.752000</td>\n",
       "      <td>4.081000</td>\n",
       "      <td>32.478000</td>\n",
       "      <td>6.003000</td>\n",
       "      <td>19.829000</td>\n",
       "      <td>1102.500000</td>\n",
       "      <td>9989.000000</td>\n",
       "      <td>15841.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\n",
       "count     4601.000000        4601.000000    4601.000000   4601.000000   \n",
       "mean         0.104553           0.213015       0.280656      0.065425   \n",
       "std          0.305358           1.290575       0.504143      1.395151   \n",
       "min          0.000000           0.000000       0.000000      0.000000   \n",
       "25%          0.000000           0.000000       0.000000      0.000000   \n",
       "50%          0.000000           0.000000       0.000000      0.000000   \n",
       "75%          0.000000           0.000000       0.420000      0.000000   \n",
       "max          4.540000          14.280000       5.100000     42.810000   \n",
       "\n",
       "       word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  \\\n",
       "count    4601.000000     4601.000000       4601.000000         4601.000000   \n",
       "mean        0.312223        0.095901          0.114208            0.105295   \n",
       "std         0.672513        0.273824          0.391441            0.401071   \n",
       "min         0.000000        0.000000          0.000000            0.000000   \n",
       "25%         0.000000        0.000000          0.000000            0.000000   \n",
       "50%         0.000000        0.000000          0.000000            0.000000   \n",
       "75%         0.380000        0.000000          0.000000            0.000000   \n",
       "max        10.000000        5.880000          7.270000           11.110000   \n",
       "\n",
       "       word_freq_order  word_freq_mail  word_freq_receive  word_freq_will  \\\n",
       "count      4601.000000     4601.000000        4601.000000     4601.000000   \n",
       "mean          0.090067        0.239413           0.059824        0.541702   \n",
       "std           0.278616        0.644755           0.201545        0.861698   \n",
       "min           0.000000        0.000000           0.000000        0.000000   \n",
       "25%           0.000000        0.000000           0.000000        0.000000   \n",
       "50%           0.000000        0.000000           0.000000        0.100000   \n",
       "75%           0.000000        0.160000           0.000000        0.800000   \n",
       "max           5.260000       18.180000           2.610000        9.670000   \n",
       "\n",
       "       word_freq_people  word_freq_report  word_freq_addresses  \\\n",
       "count       4601.000000       4601.000000          4601.000000   \n",
       "mean           0.093930          0.058626             0.049205   \n",
       "std            0.301036          0.335184             0.258843   \n",
       "min            0.000000          0.000000             0.000000   \n",
       "25%            0.000000          0.000000             0.000000   \n",
       "50%            0.000000          0.000000             0.000000   \n",
       "75%            0.000000          0.000000             0.000000   \n",
       "max            5.550000         10.000000             4.410000   \n",
       "\n",
       "       word_freq_free  word_freq_business  word_freq_email  word_freq_you  \\\n",
       "count     4601.000000         4601.000000      4601.000000    4601.000000   \n",
       "mean         0.248848            0.142586         0.184745       1.662100   \n",
       "std          0.825792            0.444055         0.531122       1.775481   \n",
       "min          0.000000            0.000000         0.000000       0.000000   \n",
       "25%          0.000000            0.000000         0.000000       0.000000   \n",
       "50%          0.000000            0.000000         0.000000       1.310000   \n",
       "75%          0.100000            0.000000         0.000000       2.640000   \n",
       "max         20.000000            7.140000         9.090000      18.750000   \n",
       "\n",
       "       word_freq_credit  word_freq_your  word_freq_font  word_freq_000  \\\n",
       "count       4601.000000     4601.000000     4601.000000    4601.000000   \n",
       "mean           0.085577        0.809761        0.121202       0.101645   \n",
       "std            0.509767        1.200810        1.025756       0.350286   \n",
       "min            0.000000        0.000000        0.000000       0.000000   \n",
       "25%            0.000000        0.000000        0.000000       0.000000   \n",
       "50%            0.000000        0.220000        0.000000       0.000000   \n",
       "75%            0.000000        1.270000        0.000000       0.000000   \n",
       "max           18.180000       11.110000       17.100000       5.450000   \n",
       "\n",
       "       word_freq_money  word_freq_hp  word_freq_hpl  word_freq_george  \\\n",
       "count      4601.000000   4601.000000    4601.000000       4601.000000   \n",
       "mean          0.094269      0.549504       0.265384          0.767305   \n",
       "std           0.442636      1.671349       0.886955          3.367292   \n",
       "min           0.000000      0.000000       0.000000          0.000000   \n",
       "25%           0.000000      0.000000       0.000000          0.000000   \n",
       "50%           0.000000      0.000000       0.000000          0.000000   \n",
       "75%           0.000000      0.000000       0.000000          0.000000   \n",
       "max          12.500000     20.830000      16.660000         33.330000   \n",
       "\n",
       "       word_freq_650  word_freq_lab  word_freq_labs  word_freq_telnet  \\\n",
       "count    4601.000000    4601.000000     4601.000000       4601.000000   \n",
       "mean        0.124845       0.098915        0.102852          0.064753   \n",
       "std         0.538576       0.593327        0.456682          0.403393   \n",
       "min         0.000000       0.000000        0.000000          0.000000   \n",
       "25%         0.000000       0.000000        0.000000          0.000000   \n",
       "50%         0.000000       0.000000        0.000000          0.000000   \n",
       "75%         0.000000       0.000000        0.000000          0.000000   \n",
       "max         9.090000      14.280000        5.880000         12.500000   \n",
       "\n",
       "       word_freq_857  word_freq_data  word_freq_415  word_freq_85  \\\n",
       "count    4601.000000     4601.000000    4601.000000   4601.000000   \n",
       "mean        0.047048        0.097229       0.047835      0.105412   \n",
       "std         0.328559        0.555907       0.329445      0.532260   \n",
       "min         0.000000        0.000000       0.000000      0.000000   \n",
       "25%         0.000000        0.000000       0.000000      0.000000   \n",
       "50%         0.000000        0.000000       0.000000      0.000000   \n",
       "75%         0.000000        0.000000       0.000000      0.000000   \n",
       "max         4.760000       18.180000       4.760000     20.000000   \n",
       "\n",
       "       word_freq_technology  word_freq_1999  word_freq_parts  word_freq_pm  \\\n",
       "count           4601.000000     4601.000000      4601.000000   4601.000000   \n",
       "mean               0.097477        0.136953         0.013201      0.078629   \n",
       "std                0.402623        0.423451         0.220651      0.434672   \n",
       "min                0.000000        0.000000         0.000000      0.000000   \n",
       "25%                0.000000        0.000000         0.000000      0.000000   \n",
       "50%                0.000000        0.000000         0.000000      0.000000   \n",
       "75%                0.000000        0.000000         0.000000      0.000000   \n",
       "max                7.690000        6.890000         8.330000     11.110000   \n",
       "\n",
       "       word_freq_direct  word_freq_cs  word_freq_meeting  word_freq_original  \\\n",
       "count       4601.000000   4601.000000        4601.000000         4601.000000   \n",
       "mean           0.064834      0.043667           0.132339            0.046099   \n",
       "std            0.349916      0.361205           0.766819            0.223812   \n",
       "min            0.000000      0.000000           0.000000            0.000000   \n",
       "25%            0.000000      0.000000           0.000000            0.000000   \n",
       "50%            0.000000      0.000000           0.000000            0.000000   \n",
       "75%            0.000000      0.000000           0.000000            0.000000   \n",
       "max            4.760000      7.140000          14.280000            3.570000   \n",
       "\n",
       "       word_freq_project  word_freq_re  word_freq_edu  word_freq_table  \\\n",
       "count        4601.000000   4601.000000    4601.000000      4601.000000   \n",
       "mean            0.079196      0.301224       0.179824         0.005444   \n",
       "std             0.621976      1.011687       0.911119         0.076274   \n",
       "min             0.000000      0.000000       0.000000         0.000000   \n",
       "25%             0.000000      0.000000       0.000000         0.000000   \n",
       "50%             0.000000      0.000000       0.000000         0.000000   \n",
       "75%             0.000000      0.110000       0.000000         0.000000   \n",
       "max            20.000000     21.420000      22.050000         2.170000   \n",
       "\n",
       "       word_freq_conference  char_freq_%3B  char_freq_%28  char_freq_%5B  \\\n",
       "count           4601.000000    4601.000000    4601.000000    4601.000000   \n",
       "mean               0.031869       0.038575       0.139030       0.016976   \n",
       "std                0.285735       0.243471       0.270355       0.109394   \n",
       "min                0.000000       0.000000       0.000000       0.000000   \n",
       "25%                0.000000       0.000000       0.000000       0.000000   \n",
       "50%                0.000000       0.000000       0.065000       0.000000   \n",
       "75%                0.000000       0.000000       0.188000       0.000000   \n",
       "max               10.000000       4.385000       9.752000       4.081000   \n",
       "\n",
       "       char_freq_%21  char_freq_%24  char_freq_%23  \\\n",
       "count    4601.000000    4601.000000    4601.000000   \n",
       "mean        0.269071       0.075811       0.044238   \n",
       "std         0.815672       0.245882       0.429342   \n",
       "min         0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000   \n",
       "75%         0.315000       0.052000       0.000000   \n",
       "max        32.478000       6.003000      19.829000   \n",
       "\n",
       "       capital_run_length_average  capital_run_length_longest  \\\n",
       "count                 4601.000000                 4601.000000   \n",
       "mean                     5.191515                   52.172789   \n",
       "std                     31.729449                  194.891310   \n",
       "min                      1.000000                    1.000000   \n",
       "25%                      1.588000                    6.000000   \n",
       "50%                      2.276000                   15.000000   \n",
       "75%                      3.706000                   43.000000   \n",
       "max                   1102.500000                 9989.000000   \n",
       "\n",
       "       capital_run_length_total  \n",
       "count               4601.000000  \n",
       "mean                 283.289285  \n",
       "std                  606.347851  \n",
       "min                    1.000000  \n",
       "25%                   35.000000  \n",
       "50%                   95.000000  \n",
       "75%                  266.000000  \n",
       "max                15841.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with pd.option_context('display.max_columns', None):\n",
    "    display(X.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30eb51a9-2a83-48e1-8964-8fb5349140fa",
   "metadata": {},
   "source": [
    "From this plot we see that for both frequency variables, the values are in most cases 0, as in almost all but `will`, `you`, `your` and `+` are the only ones were the median is above zero and even at the 75 percentile only eleven have nonzero values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2317372-a233-44c9-8b81-bd9db4404399",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d27ba9c-132c-4bc7-a8eb-1527da3cff93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 6))\n",
    "\n",
    "words = spam_df[[col for col in spam_df.columns if col.startswith(\"word_freq\")]].to_numpy()\n",
    "index, count = np.unique(words, return_counts=True)\n",
    "ax1.bar(index, count / words.shape[1], width=0.01)\n",
    "ax1.bar(index[0], count[0] / words.shape[1], width=0.01, color=\"red\")\n",
    "ax1.set_yscale(\"log\")\n",
    "ax1.set_xlim(-0.1, 20)\n",
    "chars = spam_df[[col for col in spam_df.columns if col.startswith(\"char_freq\")]].to_numpy()\n",
    "index, count = np.unique(chars, return_counts=True)\n",
    "ax2.bar(index, count / chars.shape[1], width=0.001)\n",
    "ax2.bar(index[0], count[0] / chars.shape[1], width=0.001, color=\"red\")\n",
    "ax2.set_yscale(\"log\")\n",
    "ax2.set_xlim(-0.01, 2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c575890-fa9f-451f-b636-6c9b5cbaca86",
   "metadata": {},
   "source": [
    "Checking the distribution of the values of word frequencies (top) and character frequencies (bottom), we can see more clearly the spike at zero (in red). With the full distribution shown, see the different behaviour at zero (a spike) and after zero (an exponentail decay), this means that the disribution of the variables is a mixture of a discrete and continuous variable. Another notable fact is that for the characters the rate for the exponential decay is faster than for words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a523bdc-ae06-4398-a523-0a6dc7c8b70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b963ea29-e7c5-4dcb-a886-ffa8b8d6404f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf.fit(spam_data.data, spam_data.target)\n",
    "importance = rf.feature_importances_\n",
    "order = np.argsort(importance)\n",
    "names = spam_data.data.columns\n",
    "colors = np.array([\"blue\"] * 48 + [\"orange\"] * 6 + [\"green\"] * 3)\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.barh(names[order[-20:]], importance[order[-20:]], color=colors[order[-20:]])\n",
    "plt.title(\"Top 20 features\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330671e3-a2e9-401e-a942-052831d63903",
   "metadata": {},
   "source": [
    "Measuring the importance of the features using a random forest, we get that the two most important features are the characters `!` (%21) and `$` (%24) respectively, then followed by the words `remove` and `free`, After that come all three variables about capitalization, followed then by a list of words.\n",
    "\n",
    "With this we see that almost half of the most important variables fall in the captegories of:\n",
    "+ Highlighting or emphasizing: the character `!` and writting in capital letters\n",
    "+ Money: the character `$`, the words `free`, `money`, `000` (probably as part of £1.000 separated by the parser) or `buisness`\n",
    "\n",
    "This two categories are two of the main components of scam emails for the time the dataset was made (1999), for the importance of what the contents of the email entailed and the oportinity of making money by previously paying a little bit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c91792-1ec8-4fca-b714-c024a9df1177",
   "metadata": {},
   "source": [
    "#### Is SPAM class underepresented?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "id": "820d0484-447e-47d5-a571-b81da3a9ce15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records containing spam: 1813\n",
      "Records not containing spam: 2788\n"
     ]
    }
   ],
   "source": [
    "class_1 = len(spam_df[spam_df['class'] == '1'])\n",
    "class_0 = len(spam_df[spam_df['class'] == '0'])\n",
    "print(f\"Records containing spam: {class_1}\")\n",
    "print(f\"Records not containing spam: {class_0}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a416ec65-3b47-4474-aa36-6e2f04f8694f",
   "metadata": {},
   "source": [
    "#### Computing the effective sample size n_eff (from paper)\n",
    "\n",
    "We have binary data, the prevalence of Y is **p=class_1 / total_size**, subsequently **n_rare=n*min(p, 1-p)**, and finally **n_eff=min(n, 5*n_rare)** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 668,
   "id": "3617cd42-233b-4ace-b2a2-3b5f892f0346",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4601"
      ]
     },
     "execution_count": 668,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = len(spam_df)\n",
    "\n",
    "p = class_1 / n\n",
    "n_rare = n * min(p, 1-p)\n",
    "n_eff = min(n, 5*n_rare)\n",
    "n_eff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50c87ec-b54d-43f4-a51a-19a295ae274f",
   "metadata": {},
   "source": [
    "#### Computing the V for V-fold cross-validation\n",
    "Since n_eff >= 500 but not >= 5000 we should select a value between 20 and 10. We take in account that n_eff is closer to 5000 and so we focus on V slightly higher than 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 698,
   "id": "f9ee561d-d6f0-4583-babe-66fc7835ffe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_FOLDS = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223e2513-612b-43f5-8e60-557e13eb01f8",
   "metadata": {},
   "source": [
    "### BASE LEARNERS - SPECIFICATION\n",
    "\n",
    "When choosing the base learners for the first layer we have considered the properties of the dataset and the task in this case being binary classification. As the paper *Practical considerations for specifying a super learner* suggests \"An ideal, rich library is diverse in its learning strategies, able to adapt to a range of underlying functional forms for the true prediction function, computationally feasible, and effective at handling high dimensional data. Diverse libraries include parametric learners, highly data-adaptive learners, multiple variants of the same learner with different tuning parameter specifications...\". So the first layer should consist of diverse algorithms with different inductive biases to ensure a rich set of predictions for the metalearnerearner\".\n",
    "\n",
    "We have selected: \n",
    "\n",
    "**Random Forest:**\n",
    "\n",
    "Because they are robust to overfitting on datasets with many features and they handle noisy or irrelevant features well, which is can be a thing in this case.\n",
    "\n",
    "**Generalized Linear Model - Logistic regression:**\n",
    "\n",
    "We chose to add it because it's a simple yet effective baseline model, especially logistic regression for binary classification. It should provide a low-variance learner to complement the other high-variance ones.\n",
    "\n",
    "**Deep Learning (H20's MLP):**\n",
    "\n",
    "We add the neural networks, because of it's flexibility so it could capture non-linear relationships which should broaden the diversity of the stacks prediction.\n",
    "\n",
    "**Naive Bayes:**\n",
    "\n",
    "Why: Spam datasets often benefit from Naive Bayes since it assumes independence among features and thus might capture something more general than the other models.\n",
    "\n",
    "**Gradient Boosting Machines:**\n",
    "\n",
    "We choose them as another complement ensemble method that can capture rather complex relationship and so maybe overfit more to th data.\n",
    "\n",
    "\n",
    "We assume the simpler models like naive bayes and logistic regression should bring in the stack a more general view without focusing too much on the quirks in the data and to balance it out we have selected a more accurate and flexible methods like MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4444e6-ca57-4aa0-b2d2-47f88b70c244",
   "metadata": {},
   "source": [
    "Also we try various configurations of hyperparameters for each class of learners as the paper specifies: *\"Since the true functional form is unknown, it is a good idea to consider a variety of base learners, and to construct multiple variations of the same base learner with different tuning specifications. There is no harm in including a learner that performs poorly in the library, as it will be given a weight of zero...\"* (or close to 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "id": "8f66af53-4ce2-4ae7-87f2-b13466b994d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_learners_simple01 = {\n",
    "    \"LogisticRegression\": H2OGeneralizedLinearEstimator(family=\"binomial\", nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True),\n",
    "    \"RandomForest\": H2ORandomForestEstimator(ntrees=50, max_depth=10, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True),\n",
    "    \"GradientBoosting\": H2OGradientBoostingEstimator(ntrees=50, max_depth=5, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True),\n",
    "    \"NaiveBayes\": H2ONaiveBayesEstimator(nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True)\n",
    "}\n",
    "\n",
    "# TODO consider balance_class=True\n",
    "\n",
    "base_learners_mix_duplicates01 = {\n",
    "    \"LogisticRegression_binomial\": H2OGeneralizedLinearEstimator(\n",
    "        family=\"binomial\", nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "    ),\n",
    "    \"RandomForest_50trees\": H2ORandomForestEstimator(\n",
    "        ntrees=50, max_depth=10, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "    ),\n",
    "    \"RandomForest_50trees_unbounded_D\": H2ORandomForestEstimator(\n",
    "        ntrees=50, max_depth=10, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "    ),\n",
    "    \"RandomForest_10trees\": H2ORandomForestEstimator(\n",
    "        ntrees=10, max_depth=10, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "    ),\n",
    "    \"RandomForest_10trees_unbounded_D\": H2ORandomForestEstimator(\n",
    "        ntrees=10, max_depth=10, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "    ),\n",
    "    \"GradientBoosting\": H2OGradientBoostingEstimator(\n",
    "        ntrees=50, max_depth=5, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True, balance_classes=True\n",
    "    ),\n",
    "    \"NaiveBayes\": H2ONaiveBayesEstimator(\n",
    "        nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "    ),\n",
    "    \"NeuralNetwork_32\": H2ODeepLearningEstimator(\n",
    "        hidden=[32], epochs=10, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "    ),\n",
    "    \"NeuralNetwork_32_16\": H2ODeepLearningEstimator(\n",
    "        hidden=[32, 16], epochs=10, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "    )\n",
    "}\n",
    "\n",
    "base_learners_mix_rf_nns_01 = {\n",
    "    \"LogisticRegression_binomial\": H2OGeneralizedLinearEstimator(\n",
    "        family=\"binomial\", nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "    ),\n",
    "    \"RandomForest_50trees\": H2ORandomForestEstimator(\n",
    "        ntrees=50, max_depth=10, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "    ),\n",
    "    \"RandomForest_50trees_unbounded_D\": H2ORandomForestEstimator(\n",
    "    ntrees=50, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "    ),\n",
    "    \"RandomForest_10trees\": H2ORandomForestEstimator(\n",
    "        ntrees=10, max_depth=10, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "    ),\n",
    "    \"RandomForest_10trees_unbounded_D\": H2ORandomForestEstimator(\n",
    "        ntrees=10, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "    ),\n",
    "    \"GradientBoosting_10trees\": H2OGradientBoostingEstimator(\n",
    "        ntrees=10, max_depth=5, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True, balance_classes=True\n",
    "    ),\n",
    "    \"GradientBoosting_50trees\": H2OGradientBoostingEstimator(\n",
    "        ntrees=50, max_depth=5, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True, balance_classes=True\n",
    "    ),\n",
    "    \"NaiveBayes\": H2ONaiveBayesEstimator(\n",
    "        nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "    ),\n",
    "    \"NeuralNetwork_32_16\": H2ODeepLearningEstimator(\n",
    "        hidden=[32, 16], epochs=300, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "    ),\n",
    "    \"NeuralNetwork_32_32\": H2ODeepLearningEstimator(\n",
    "        hidden=[32, 32], epochs=300, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "    ),\n",
    "    \"NeuralNetwork_32\": H2ODeepLearningEstimator(\n",
    "        hidden=[32], epochs=300, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c7f67b-4ad5-4d78-a96a-5b21ba3566c6",
   "metadata": {},
   "source": [
    "### BASE LEARNERS - TRAINING & EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "id": "9ee8fbbf-aff0-4cd7-878d-84d6b0f0a07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_evaluate_stack(base_learners, metalearner, h2o_train, h2o_test, X_train):\n",
    "    \n",
    "    # TRAIN BASE LEARNERS\n",
    "    print(\"\\n>>> Training base learners:\\n\")\n",
    "    for name, learner in base_learners.items():\n",
    "        print(f\"    Training {name} with {N_FOLDS}-fold cross-validation...\")\n",
    "        learner.train(x=list(range(X_train.shape[1])), y=\"label\", training_frame=h2o_train)\n",
    "\n",
    "    super_learner = H2OStackedEnsembleEstimator(\n",
    "        base_models=list(base_learners.values()),\n",
    "        metalearner_algorithm=metalearner\n",
    "    )\n",
    "    # TRAIN THE METALEARNER\n",
    "    print(\"\\n>>> Training super learner:\\n\")\n",
    "    super_learner.train(x=list(range(X_train.shape[1])), y=\"label\", training_frame=h2o_train)\n",
    "\n",
    "    # EVAL BASE LEARNERS\n",
    "    print(\"\\n>>> Base learners' results:\\n\")\n",
    "    results = {}\n",
    "    for name, learner in base_learners.items():\n",
    "        performance = learner.model_performance(test_data=h2o_test)\n",
    "        f1_score = performance.F1()[0][1]  \n",
    "        auc_pr = performance.aucpr()      \n",
    "        accuracy = performance.accuracy()[0][1]\n",
    "        results[name] = accuracy\n",
    "        results[name] = {\"F1-Score\": f1_score, \"AUC-PR\": auc_pr, \"Accuracy\": accuracy}\n",
    "        print(f\"    {name} - F1-Score: {f1_score:.4f}, AUC-PR: {auc_pr:.4f}, Accuracy (Test Set): {accuracy:.4f}\")\n",
    "    \n",
    "    # EVAL THE METALEARNER\n",
    "    print(\"\\n>>> Metalearner's results:\\n\")\n",
    "    super_performance = super_learner.model_performance(test_data=h2o_test)\n",
    "    super_accuracy = super_performance.accuracy()[0][1]\n",
    "    super_f1 = super_performance.F1()[0][1]  \n",
    "    super_auc_pr = super_performance.aucpr()  \n",
    "    # print(f\"\\n    Super Learner - F1-Score: {super_f1:.4f}, AUC-PR: {super_auc_pr:.4f} | Super Learner Accuracy: {super_accuracy:.4f}\")\n",
    "    \n",
    "    \n",
    "    # print(\"\\nFinal Results Comparison:\")\n",
    "    # for name, metrics in results.items():\n",
    "    #     print(f\"{name} - F1-Score: {metrics['F1-Score']:.4f}, AUC-PR: {metrics['AUC-PR']:.4f}, Accuracy: {metrics['Accuracy']:.4f}\")\n",
    "        \n",
    "    print(f\"    Super Learner - F1-Score: {super_f1:.4f}, AUC-PR: {super_auc_pr:.4f}, Accuracy: {super_accuracy:.4f}\")\n",
    "    return {\"F1-Score\": super_f1, \"AUC-PR\": super_auc_pr, \"Accuracy\": super_accuracy}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b97691-0800-43f5-944e-4579f0563eb7",
   "metadata": {},
   "source": [
    "### METALEARNER - TRAINING & EVALUATION\n",
    "\n",
    "\n",
    "For the metalearner we principally selected two possible options for testing:\n",
    "\n",
    "**GLM:**\n",
    "\n",
    "We chose logistic regression because it is simple and interpretable and as a meta-learner we want it just combine the predictions of individual learners by weighting the them reducing the risk of overfitting when combining predictions. So in this case we are more focused on finding the best combination of predictions rather than adding more complexity.\n",
    "\n",
    "**Gradient Boosting Machine / MLP:**\n",
    "\n",
    "As an alternative second option we wanted something stronger, a bit of a bigger hammer sort to say, especially for our stacks which are more diverse in which case their predictions could be more complex, so they could capture non-linear relationships among them.\n",
    "\n",
    "**Evaluation metrics:**\n",
    "In accordance with the paper where our task is binary classification of imbalanced classes we chose AUCPR as a primary evaluation metric. In addition as alternatives we provide F1 (once again due uneven class distribution) and finally accuracy as complement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 700,
   "id": "f7e61dcd-28d1-4a92-8fc1-cfba19777b6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Training base learners:\n",
      "\n",
      "    Training LogisticRegression with 12-fold cross-validation...\n",
      "glm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training RandomForest with 12-fold cross-validation...\n",
      "drf Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting with 12-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training NaiveBayes with 12-fold cross-validation...\n",
      "naivebayes Model Build progress: |███████████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Training super learner:\n",
      "\n",
      "stackedensemble Model Build progress: |██████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Base learners' results:\n",
      "\n",
      "    LogisticRegression - F1-Score: 0.9125, AUC-PR: 0.9597, Accuracy (Test Set): 0.9251\n",
      "    RandomForest - F1-Score: 0.9375, AUC-PR: 0.9790, Accuracy (Test Set): 0.9479\n",
      "    GradientBoosting - F1-Score: 0.9490, AUC-PR: 0.9848, Accuracy (Test Set): 0.9566\n",
      "    NaiveBayes - F1-Score: 0.8303, AUC-PR: 0.8182, Accuracy (Test Set): 0.8588\n",
      "\n",
      ">>> Metalearner's results:\n",
      "\n",
      "    Super Learner - F1-Score: 0.9537, AUC-PR: 0.9839, Accuracy: 0.9609\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'F1-Score': 0.9537275064267353,\n",
       " 'AUC-PR': 0.98388486064698,\n",
       " 'Accuracy': 0.9609120521172638}"
      ]
     },
     "execution_count": 700,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_evaluate_stack(base_learners_simple01, \"glm\", h2o_train, h2o_test, X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "id": "a1caa0dd-550f-412d-9c41-3161d56e149b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Training base learners:\n",
      "\n",
      "    Training LogisticRegression_binomial with 5-fold cross-validation...\n",
      "glm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training RandomForest_50trees with 5-fold cross-validation...\n",
      "drf Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training RandomForest_50trees_unbounded_D with 5-fold cross-validation...\n",
      "drf Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training RandomForest_10trees with 5-fold cross-validation...\n",
      "drf Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training RandomForest_10trees_unbounded_D with 5-fold cross-validation...\n",
      "drf Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training NaiveBayes with 5-fold cross-validation...\n",
      "naivebayes Model Build progress: |███████████████████████████████████████████████| (done) 100%\n",
      "    Training NeuralNetwork with 5-fold cross-validation...\n",
      "deeplearning Model Build progress: |█████████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Training super learner:\n",
      "\n",
      "stackedensemble Model Build progress: |██████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Base learners' results:\n",
      "\n",
      "    LogisticRegression_binomial - F1-Score: 0.9125, AUC-PR: 0.9597, Accuracy (Test Set): 0.9251\n",
      "    RandomForest_50trees - F1-Score: 0.9375, AUC-PR: 0.9790, Accuracy (Test Set): 0.9479\n",
      "    RandomForest_50trees_unbounded_D - F1-Score: 0.9375, AUC-PR: 0.9790, Accuracy (Test Set): 0.9479\n",
      "    RandomForest_10trees - F1-Score: 0.9235, AUC-PR: 0.9688, Accuracy (Test Set): 0.9370\n",
      "    RandomForest_10trees_unbounded_D - F1-Score: 0.9235, AUC-PR: 0.9688, Accuracy (Test Set): 0.9370\n",
      "    NaiveBayes - F1-Score: 0.8303, AUC-PR: 0.8182, Accuracy (Test Set): 0.8588\n",
      "    NeuralNetwork - F1-Score: 0.9376, AUC-PR: 0.9743, Accuracy (Test Set): 0.9468\n",
      "\n",
      ">>> Metalearner's results:\n",
      "\n",
      "    Super Learner - F1-Score: 0.9404, AUC-PR: 0.9818, Accuracy: 0.9490\n"
     ]
    }
   ],
   "source": [
    "train_evaluate_stack(base_learners_mix_duplicates01, \"glm\", h2o_train, h2o_test, X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "id": "42f84d97-413f-43e5-9641-e64ca64c3239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Training base learners:\n",
      "\n",
      "    Training LogisticRegression_binomial with 5-fold cross-validation...\n",
      "glm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training RandomForest_50trees with 5-fold cross-validation...\n",
      "drf Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training RandomForest_50trees_unbounded_D with 5-fold cross-validation...\n",
      "drf Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training RandomForest_10trees with 5-fold cross-validation...\n",
      "drf Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training RandomForest_10trees_unbounded_D with 5-fold cross-validation...\n",
      "drf Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting with 5-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training NaiveBayes with 5-fold cross-validation...\n",
      "naivebayes Model Build progress: |███████████████████████████████████████████████| (done) 100%\n",
      "    Training NeuralNetwork_32_16 with 5-fold cross-validation...\n",
      "deeplearning Model Build progress: |█████████████████████████████████████████████| (done) 100%\n",
      "    Training NeuralNetwork_32_32 with 5-fold cross-validation...\n",
      "deeplearning Model Build progress: |█████████████████████████████████████████████| (done) 100%\n",
      "    Training NeuralNetwork_32 with 5-fold cross-validation...\n",
      "deeplearning Model Build progress: |█████████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Training super learner:\n",
      "\n",
      "stackedensemble Model Build progress: |██████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Base learners' results:\n",
      "\n",
      "    LogisticRegression_binomial - F1-Score: 0.9125, AUC-PR: 0.9597, Accuracy (Test Set): 0.9251\n",
      "    RandomForest_50trees - F1-Score: 0.9375, AUC-PR: 0.9790, Accuracy (Test Set): 0.9479\n",
      "    RandomForest_50trees_unbounded_D - F1-Score: 0.9501, AUC-PR: 0.9839, Accuracy (Test Set): 0.9577\n",
      "    RandomForest_10trees - F1-Score: 0.9235, AUC-PR: 0.9688, Accuracy (Test Set): 0.9370\n",
      "    RandomForest_10trees_unbounded_D - F1-Score: 0.9300, AUC-PR: 0.9756, Accuracy (Test Set): 0.9425\n",
      "    GradientBoosting - F1-Score: 0.9452, AUC-PR: 0.9838, Accuracy (Test Set): 0.9533\n",
      "    NaiveBayes - F1-Score: 0.8303, AUC-PR: 0.8182, Accuracy (Test Set): 0.8588\n",
      "    NeuralNetwork_32_16 - F1-Score: 0.9274, AUC-PR: 0.9594, Accuracy (Test Set): 0.9381\n",
      "    NeuralNetwork_32_32 - F1-Score: 0.9283, AUC-PR: 0.9676, Accuracy (Test Set): 0.9403\n",
      "    NeuralNetwork_32 - F1-Score: 0.9309, AUC-PR: 0.9660, Accuracy (Test Set): 0.9425\n",
      "\n",
      ">>> Metalearner's results:\n",
      "\n",
      "    Super Learner - F1-Score: 0.9494, AUC-PR: 0.9875, Accuracy: 0.9577\n"
     ]
    }
   ],
   "source": [
    "train_evaluate_stack(base_learners_mix_rf_nns_01, \"glm\", h2o_train, h2o_test, X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4a08d9-2542-42c7-a4db-5f4a6479658e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e595ae30-3eed-4f27-9da6-607ef4a31fc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "456ea211-3dd9-4845-ab77-c176675b55a8",
   "metadata": {},
   "source": [
    "# Ablation studies\n",
    "\n",
    "In the following we tried a more methodological way of building the stack. \n",
    "We tried two approaches and evaluated their effects on the final test metrics:\n",
    "\n",
    "**1) Building the stack from simpler models adding more complex ones:**\n",
    "\n",
    "In this method we start from a base consisting of simple models which we assume would capture the main / most general pattern in the data.\n",
    "Afterwards we gradually try adding more complex models to extend the stack capabilities to capture more finer intricacies and more complex (perhaps non-linear) relationships in the data and we observe the effect on the test metrics.\n",
    "\n",
    "\n",
    "**1) Building the stack from more complex models adding more general/simple ones:**\n",
    "In this method we start from a base consisting of more complex models which we assume would capture the complex relationships in data well and then\n",
    "we try to bring down the variance by adding simpler models that don't overfit to the data so much.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 766,
   "id": "ed000c1c-6b4c-4079-8acc-bc8f7b80f791",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_learners = [{\n",
    "                   \"LogisticRegression_binomial\": H2OGeneralizedLinearEstimator(\n",
    "                        family=\"binomial\", nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "                    )}, \n",
    "                   {\"NaiveBayes\": H2ONaiveBayesEstimator(nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True)}]\n",
    "\n",
    "\n",
    "random_forests = {  \n",
    "                    \"RandomForest_10trees\": H2ORandomForestEstimator(\n",
    "                        ntrees=10, max_depth=10, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "                    ),\n",
    "                    \"RandomForest_20trees\": H2ORandomForestEstimator(\n",
    "                        ntrees=20, max_depth=10, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "                    ),\n",
    "                    \"RandomForest_50trees\": H2ORandomForestEstimator(\n",
    "                        ntrees=50, max_depth=10, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "                    ),\n",
    "                    \"RandomForest_10trees_unbounded_D\": H2ORandomForestEstimator(\n",
    "                        ntrees=10, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "                    ),\n",
    "                    \"RandomForest_20trees_unbounded_D\": H2ORandomForestEstimator(\n",
    "                        ntrees=20, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "                    ),\n",
    "                    \"RandomForest_50trees_unbounded_D\": H2ORandomForestEstimator(\n",
    "                        ntrees=50, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "                    )}\n",
    "\n",
    "gradient_boostings = {\n",
    "\n",
    "                    \"GradientBoosting_10trees\": H2OGradientBoostingEstimator(\n",
    "                        ntrees=10, max_depth=5, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True, balance_classes=True\n",
    "                    ),\n",
    "                    \"GradientBoosting_20trees\": H2OGradientBoostingEstimator(\n",
    "                        ntrees=20, max_depth=5, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True, balance_classes=True\n",
    "                    ),\n",
    "                    \"GradientBoosting_50trees\": H2OGradientBoostingEstimator(\n",
    "                        ntrees=50, max_depth=5, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True, balance_classes=True\n",
    "                    ),\n",
    "                    \"GradientBoosting_10trees_unbounded_D\": H2OGradientBoostingEstimator(\n",
    "                        ntrees=10, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True, balance_classes=True\n",
    "                    ),\n",
    "                    \"GradientBoosting_20trees_unbounded_D\": H2OGradientBoostingEstimator(\n",
    "                        ntrees=20, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True, balance_classes=True\n",
    "                    ),\n",
    "                    \"GradientBoosting_50trees_unbounded_D\": H2OGradientBoostingEstimator(\n",
    "                        ntrees=50, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True, balance_classes=True\n",
    "                    )}\n",
    "\n",
    "neural_networks = {\n",
    "                    \"NeuralNetwork_6\": H2ODeepLearningEstimator(\n",
    "                        hidden=[6], epochs=300, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "                    ), \n",
    "                    \"NeuralNetwork_16\": H2ODeepLearningEstimator(\n",
    "                        hidden=[16], epochs=300, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "                    ), \n",
    "                    \"NeuralNetwork_32\": H2ODeepLearningEstimator(\n",
    "                        hidden=[32], epochs=300, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "                    ), \n",
    "                    \"NeuralNetwork_32_16\": H2ODeepLearningEstimator(\n",
    "                    hidden=[32, 16], epochs=300, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "                    ),\n",
    "                    \"NeuralNetwork_32_32\": H2ODeepLearningEstimator(\n",
    "                        hidden=[32, 32], epochs=300, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "                    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6198921-0a69-413b-bd7b-257a367ec07a",
   "metadata": {},
   "source": [
    "### A more efficient variant would be training each model only once in case it is present in multiple combinations.\n",
    "\n",
    "Due to the tradeoff between the scope of this project and time capabilities we perform only superficial overview. If the problem would be a topic of major research where the time needed to search the vast hypothesis space is available, we would suggest performing more extensive per-class tests with higher hyperparameter sampling granularity to better observe how they affect the models performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa8f24c-ed59-4124-ad25-41a64bb34c9f",
   "metadata": {},
   "source": [
    "## SIMPLE TO COMPLEX\n",
    "\n",
    "To try all possible combinations would be computationally unfeaseble. Therefore we chose a more naive tactic, where we examine the combination of a \n",
    "simple learner with the a few representative selections of a single class of complex learners and we choose the best performing options for combinations with others."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7aec74-3919-4e5b-b0d2-1421c4ae3adb",
   "metadata": {},
   "source": [
    "## From the ablations we have selected the following configurations from each class:\n",
    "\n",
    "### RFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 797,
   "id": "cd0ef8c5-9b6d-48ad-a061-eb289217c46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forests = [{                   \n",
    "        \"RandomForest_10trees\": H2ORandomForestEstimator(\n",
    "                            ntrees=10, max_depth=10, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "                        )   \n",
    "}, \n",
    "{                   \n",
    "        \"RandomForest_50trees\": H2ORandomForestEstimator(\n",
    "        ntrees=50, max_depth=10, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "    )\n",
    "},\n",
    "{                   \n",
    "        \"RandomForest_10trees\": H2ORandomForestEstimator(\n",
    "                            ntrees=10, max_depth=10, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "                        ),   \n",
    "        \"RandomForest_50trees\": H2ORandomForestEstimator(\n",
    "        ntrees=50, max_depth=10, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "    )\n",
    "}]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2147fae3-50e9-4401-ac18-20bcef0d4b25",
   "metadata": {},
   "source": [
    "### GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 800,
   "id": "2479f4f7-6deb-420c-9788-86064b8052f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient_boosting = [{    \n",
    "    \"GradientBoosting_10trees\": H2OGradientBoostingEstimator(\n",
    "        ntrees=10, max_depth=10, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "    ),   \n",
    "    \"GradientBoosting_50trees\": H2OGradientBoostingEstimator(\n",
    "    ntrees=50, max_depth=10, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "    ),\n",
    "}, {    \n",
    "    \"GradientBoosting_10trees\": H2OGradientBoostingEstimator(\n",
    "        ntrees=10, max_depth=10, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "    ),   \n",
    "    \"GradientBoosting_20trees\": H2OGradientBoostingEstimator(\n",
    "    ntrees=20, max_depth=10, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "    ),\n",
    "}]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb801a1-f349-4469-827b-369fc7cb99a2",
   "metadata": {},
   "source": [
    "### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 803,
   "id": "d3a39abe-add7-4d13-a9e5-1a55825d81e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlps= [{    \n",
    "    \"NeuralNetwork_10\": H2ODeepLearningEstimator(\n",
    "        hidden=[10], epochs=300, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "    ), \n",
    "}, {    \"NeuralNetwork_16\": H2ODeepLearningEstimator(\n",
    "        hidden=[16], epochs=300, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "    ), }]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 858,
   "id": "4d30e227-b8c7-4acc-904f-400a126c198d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of configurations: 24\n",
      "Sample configuration: {'NaiveBayes': H2ONaiveBayesEstimator({'parms': {}}), 'RandomForest_10trees': H2ORandomForestEstimator({'parms': {}}), 'RandomForest_50trees': H2ORandomForestEstimator({'parms': {}}), 'GradientBoosting_10trees': H2OGradientBoostingEstimator({'parms': {}}), 'GradientBoosting_50trees': H2OGradientBoostingEstimator({'parms': {}}), 'NeuralNetwork_10': H2ODeepLearningEstimator({'parms': {}, 'supervised_learning': True})}\n"
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    "\n",
    "all_combinations = list(product(simple_learners, random_forests, gradient_boosting, mlps))\n",
    "\n",
    "all_combinations\n",
    "\n",
    "configurations = []\n",
    "for combination in all_combinations:\n",
    "    combined_config = {}\n",
    "    for model_dict in combination:\n",
    "        combined_config.update(model_dict)  # Merge dictionaries\n",
    "    configurations.append(combined_config)\n",
    "\n",
    "print(f\"Number of configurations: {len(configurations)}\")\n",
    "print(\"Sample configuration:\", configurations[20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 975,
   "id": "88d79e7c-5f40-425c-b99e-ee37bac5b20a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Training base learners:\n",
      "\n",
      "    Training LogisticRegression_binomial with 12-fold cross-validation...\n",
      "glm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training RandomForest_10trees with 12-fold cross-validation...\n",
      "drf Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting_10trees with 12-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting_50trees with 12-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training NeuralNetwork_10 with 12-fold cross-validation...\n",
      "deeplearning Model Build progress: |█████████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Training super learner:\n",
      "\n",
      "stackedensemble Model Build progress: |██████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Base learners' results:\n",
      "\n",
      "    LogisticRegression_binomial - F1-Score: 0.9160, AUC-PR: 0.9554, Accuracy (Test Set): 0.9334\n",
      "    RandomForest_10trees - F1-Score: 0.9310, AUC-PR: 0.9714, Accuracy (Test Set): 0.9457\n",
      "    GradientBoosting_10trees - F1-Score: 0.9186, AUC-PR: 0.9722, Accuracy (Test Set): 0.9348\n",
      "    GradientBoosting_50trees - F1-Score: 0.9472, AUC-PR: 0.9857, Accuracy (Test Set): 0.9579\n",
      "    NeuralNetwork_10 - F1-Score: 0.9207, AUC-PR: 0.9727, Accuracy (Test Set): 0.9361\n",
      "\n",
      ">>> Metalearner's results:\n",
      "\n",
      "    Super Learner - F1-Score: 0.9493, AUC-PR: 0.9808, Accuracy: 0.9592\n",
      "\n",
      ">>> Training base learners:\n",
      "\n",
      "    Training LogisticRegression_binomial with 12-fold cross-validation...\n",
      "glm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training RandomForest_10trees with 12-fold cross-validation...\n",
      "drf Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting_10trees with 12-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting_50trees with 12-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training NeuralNetwork_16 with 12-fold cross-validation...\n",
      "deeplearning Model Build progress: |█████████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Training super learner:\n",
      "\n",
      "stackedensemble Model Build progress: |██████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Base learners' results:\n",
      "\n",
      "    LogisticRegression_binomial - F1-Score: 0.9160, AUC-PR: 0.9554, Accuracy (Test Set): 0.9334\n",
      "    RandomForest_10trees - F1-Score: 0.9310, AUC-PR: 0.9714, Accuracy (Test Set): 0.9457\n",
      "    GradientBoosting_10trees - F1-Score: 0.9186, AUC-PR: 0.9722, Accuracy (Test Set): 0.9348\n",
      "    GradientBoosting_50trees - F1-Score: 0.9472, AUC-PR: 0.9857, Accuracy (Test Set): 0.9579\n",
      "    NeuralNetwork_16 - F1-Score: 0.9299, AUC-PR: 0.9690, Accuracy (Test Set): 0.9443\n",
      "\n",
      ">>> Metalearner's results:\n",
      "\n",
      "    Super Learner - F1-Score: 0.9490, AUC-PR: 0.9810, Accuracy: 0.9592\n",
      "\n",
      ">>> Training base learners:\n",
      "\n",
      "    Training LogisticRegression_binomial with 12-fold cross-validation...\n",
      "glm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training RandomForest_10trees with 12-fold cross-validation...\n",
      "drf Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting_10trees with 12-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting_20trees with 12-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training NeuralNetwork_10 with 12-fold cross-validation...\n",
      "deeplearning Model Build progress: |█████████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Training super learner:\n",
      "\n",
      "stackedensemble Model Build progress: |██████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Base learners' results:\n",
      "\n",
      "    LogisticRegression_binomial - F1-Score: 0.9160, AUC-PR: 0.9554, Accuracy (Test Set): 0.9334\n",
      "    RandomForest_10trees - F1-Score: 0.9310, AUC-PR: 0.9714, Accuracy (Test Set): 0.9457\n",
      "    GradientBoosting_10trees - F1-Score: 0.9186, AUC-PR: 0.9722, Accuracy (Test Set): 0.9348\n",
      "    GradientBoosting_20trees - F1-Score: 0.9320, AUC-PR: 0.9788, Accuracy (Test Set): 0.9443\n",
      "    NeuralNetwork_10 - F1-Score: 0.9202, AUC-PR: 0.9608, Accuracy (Test Set): 0.9361\n",
      "\n",
      ">>> Metalearner's results:\n",
      "\n",
      "    Super Learner - F1-Score: 0.9418, AUC-PR: 0.9813, Accuracy: 0.9538\n",
      "\n",
      ">>> Training base learners:\n",
      "\n",
      "    Training LogisticRegression_binomial with 12-fold cross-validation...\n",
      "glm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training RandomForest_10trees with 12-fold cross-validation...\n",
      "drf Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting_10trees with 12-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting_20trees with 12-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training NeuralNetwork_16 with 12-fold cross-validation...\n",
      "deeplearning Model Build progress: |█████████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Training super learner:\n",
      "\n",
      "stackedensemble Model Build progress: |██████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Base learners' results:\n",
      "\n",
      "    LogisticRegression_binomial - F1-Score: 0.9160, AUC-PR: 0.9554, Accuracy (Test Set): 0.9334\n",
      "    RandomForest_10trees - F1-Score: 0.9310, AUC-PR: 0.9714, Accuracy (Test Set): 0.9457\n",
      "    GradientBoosting_10trees - F1-Score: 0.9186, AUC-PR: 0.9722, Accuracy (Test Set): 0.9348\n",
      "    GradientBoosting_20trees - F1-Score: 0.9320, AUC-PR: 0.9788, Accuracy (Test Set): 0.9443\n",
      "    NeuralNetwork_16 - F1-Score: 0.9251, AUC-PR: 0.9590, Accuracy (Test Set): 0.9402\n",
      "\n",
      ">>> Metalearner's results:\n",
      "\n",
      "    Super Learner - F1-Score: 0.9434, AUC-PR: 0.9825, Accuracy: 0.9552\n",
      "\n",
      ">>> Training base learners:\n",
      "\n",
      "    Training LogisticRegression_binomial with 12-fold cross-validation...\n",
      "glm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training RandomForest_50trees with 12-fold cross-validation...\n",
      "drf Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting_10trees with 12-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting_50trees with 12-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training NeuralNetwork_10 with 12-fold cross-validation...\n",
      "deeplearning Model Build progress: |█████████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Training super learner:\n",
      "\n",
      "stackedensemble Model Build progress: |██████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Base learners' results:\n",
      "\n",
      "    LogisticRegression_binomial - F1-Score: 0.9160, AUC-PR: 0.9554, Accuracy (Test Set): 0.9334\n",
      "    RandomForest_50trees - F1-Score: 0.9298, AUC-PR: 0.9777, Accuracy (Test Set): 0.9429\n",
      "    GradientBoosting_10trees - F1-Score: 0.9186, AUC-PR: 0.9722, Accuracy (Test Set): 0.9348\n",
      "    GradientBoosting_50trees - F1-Score: 0.9472, AUC-PR: 0.9857, Accuracy (Test Set): 0.9579\n",
      "    NeuralNetwork_10 - F1-Score: 0.9257, AUC-PR: 0.9665, Accuracy (Test Set): 0.9402\n",
      "\n",
      ">>> Metalearner's results:\n",
      "\n",
      "    Super Learner - F1-Score: 0.9477, AUC-PR: 0.9847, Accuracy: 0.9592\n",
      "\n",
      ">>> Training base learners:\n",
      "\n",
      "    Training LogisticRegression_binomial with 12-fold cross-validation...\n",
      "glm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training RandomForest_50trees with 12-fold cross-validation...\n",
      "drf Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting_10trees with 12-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting_50trees with 12-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training NeuralNetwork_16 with 12-fold cross-validation...\n",
      "deeplearning Model Build progress: |█████████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Training super learner:\n",
      "\n",
      "stackedensemble Model Build progress: |██████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Base learners' results:\n",
      "\n",
      "    LogisticRegression_binomial - F1-Score: 0.9160, AUC-PR: 0.9554, Accuracy (Test Set): 0.9334\n",
      "    RandomForest_50trees - F1-Score: 0.9298, AUC-PR: 0.9777, Accuracy (Test Set): 0.9429\n",
      "    GradientBoosting_10trees - F1-Score: 0.9186, AUC-PR: 0.9722, Accuracy (Test Set): 0.9348\n",
      "    GradientBoosting_50trees - F1-Score: 0.9472, AUC-PR: 0.9857, Accuracy (Test Set): 0.9579\n",
      "    NeuralNetwork_16 - F1-Score: 0.9363, AUC-PR: 0.9635, Accuracy (Test Set): 0.9497\n",
      "\n",
      ">>> Metalearner's results:\n",
      "\n",
      "    Super Learner - F1-Score: 0.9521, AUC-PR: 0.9850, Accuracy: 0.9620\n",
      "\n",
      ">>> Training base learners:\n",
      "\n",
      "    Training LogisticRegression_binomial with 12-fold cross-validation...\n",
      "glm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training RandomForest_50trees with 12-fold cross-validation...\n",
      "drf Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting_10trees with 12-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting_20trees with 12-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training NeuralNetwork_10 with 12-fold cross-validation...\n",
      "deeplearning Model Build progress: |█████████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Training super learner:\n",
      "\n",
      "stackedensemble Model Build progress: |██████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Base learners' results:\n",
      "\n",
      "    LogisticRegression_binomial - F1-Score: 0.9160, AUC-PR: 0.9554, Accuracy (Test Set): 0.9334\n",
      "    RandomForest_50trees - F1-Score: 0.9298, AUC-PR: 0.9777, Accuracy (Test Set): 0.9429\n",
      "    GradientBoosting_10trees - F1-Score: 0.9186, AUC-PR: 0.9722, Accuracy (Test Set): 0.9348\n",
      "    GradientBoosting_20trees - F1-Score: 0.9320, AUC-PR: 0.9788, Accuracy (Test Set): 0.9443\n",
      "    NeuralNetwork_10 - F1-Score: 0.9191, AUC-PR: 0.9709, Accuracy (Test Set): 0.9361\n",
      "\n",
      ">>> Metalearner's results:\n",
      "\n",
      "    Super Learner - F1-Score: 0.9430, AUC-PR: 0.9824, Accuracy: 0.9552\n",
      "\n",
      ">>> Training base learners:\n",
      "\n",
      "    Training LogisticRegression_binomial with 12-fold cross-validation...\n",
      "glm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training RandomForest_50trees with 12-fold cross-validation...\n",
      "drf Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting_10trees with 12-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting_20trees with 12-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training NeuralNetwork_16 with 12-fold cross-validation...\n",
      "deeplearning Model Build progress: |█████████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Training super learner:\n",
      "\n",
      "stackedensemble Model Build progress: |██████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Base learners' results:\n",
      "\n",
      "    LogisticRegression_binomial - F1-Score: 0.9160, AUC-PR: 0.9554, Accuracy (Test Set): 0.9334\n",
      "    RandomForest_50trees - F1-Score: 0.9298, AUC-PR: 0.9777, Accuracy (Test Set): 0.9429\n",
      "    GradientBoosting_10trees - F1-Score: 0.9186, AUC-PR: 0.9722, Accuracy (Test Set): 0.9348\n",
      "    GradientBoosting_20trees - F1-Score: 0.9320, AUC-PR: 0.9788, Accuracy (Test Set): 0.9443\n",
      "    NeuralNetwork_16 - F1-Score: 0.9368, AUC-PR: 0.9661, Accuracy (Test Set): 0.9497\n",
      "\n",
      ">>> Metalearner's results:\n",
      "\n",
      "    Super Learner - F1-Score: 0.9422, AUC-PR: 0.9828, Accuracy: 0.9538\n",
      "\n",
      ">>> Training base learners:\n",
      "\n",
      "    Training LogisticRegression_binomial with 12-fold cross-validation...\n",
      "glm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training RandomForest_10trees with 12-fold cross-validation...\n",
      "drf Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training RandomForest_50trees with 12-fold cross-validation...\n",
      "drf Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting_10trees with 12-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting_50trees with 12-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training NeuralNetwork_10 with 12-fold cross-validation...\n",
      "deeplearning Model Build progress: |█████████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Training super learner:\n",
      "\n",
      "stackedensemble Model Build progress: |██████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Base learners' results:\n",
      "\n",
      "    LogisticRegression_binomial - F1-Score: 0.9160, AUC-PR: 0.9554, Accuracy (Test Set): 0.9334\n",
      "    RandomForest_10trees - F1-Score: 0.9310, AUC-PR: 0.9714, Accuracy (Test Set): 0.9457\n",
      "    RandomForest_50trees - F1-Score: 0.9298, AUC-PR: 0.9777, Accuracy (Test Set): 0.9429\n",
      "    GradientBoosting_10trees - F1-Score: 0.9186, AUC-PR: 0.9722, Accuracy (Test Set): 0.9348\n",
      "    GradientBoosting_50trees - F1-Score: 0.9472, AUC-PR: 0.9857, Accuracy (Test Set): 0.9579\n",
      "    NeuralNetwork_10 - F1-Score: 0.9150, AUC-PR: 0.9544, Accuracy (Test Set): 0.9321\n",
      "\n",
      ">>> Metalearner's results:\n",
      "\n",
      "    Super Learner - F1-Score: 0.9477, AUC-PR: 0.9845, Accuracy: 0.9579\n",
      "\n",
      ">>> Training base learners:\n",
      "\n",
      "    Training LogisticRegression_binomial with 12-fold cross-validation...\n",
      "glm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training RandomForest_10trees with 12-fold cross-validation...\n",
      "drf Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training RandomForest_50trees with 12-fold cross-validation...\n",
      "drf Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting_10trees with 12-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting_50trees with 12-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training NeuralNetwork_16 with 12-fold cross-validation...\n",
      "deeplearning Model Build progress: |█████████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Training super learner:\n",
      "\n",
      "stackedensemble Model Build progress: |██████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Base learners' results:\n",
      "\n",
      "    LogisticRegression_binomial - F1-Score: 0.9160, AUC-PR: 0.9554, Accuracy (Test Set): 0.9334\n",
      "    RandomForest_10trees - F1-Score: 0.9310, AUC-PR: 0.9714, Accuracy (Test Set): 0.9457\n",
      "    RandomForest_50trees - F1-Score: 0.9298, AUC-PR: 0.9777, Accuracy (Test Set): 0.9429\n",
      "    GradientBoosting_10trees - F1-Score: 0.9186, AUC-PR: 0.9722, Accuracy (Test Set): 0.9348\n",
      "    GradientBoosting_50trees - F1-Score: 0.9472, AUC-PR: 0.9857, Accuracy (Test Set): 0.9579\n",
      "    NeuralNetwork_16 - F1-Score: 0.9445, AUC-PR: 0.9751, Accuracy (Test Set): 0.9565\n",
      "\n",
      ">>> Metalearner's results:\n",
      "\n",
      "    Super Learner - F1-Score: 0.9493, AUC-PR: 0.9854, Accuracy: 0.9592\n",
      "\n",
      ">>> Training base learners:\n",
      "\n",
      "    Training LogisticRegression_binomial with 12-fold cross-validation...\n",
      "glm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training RandomForest_10trees with 12-fold cross-validation...\n",
      "drf Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training RandomForest_50trees with 12-fold cross-validation...\n",
      "drf Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting_10trees with 12-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting_20trees with 12-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training NeuralNetwork_10 with 12-fold cross-validation...\n",
      "deeplearning Model Build progress: |█████████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Training super learner:\n",
      "\n",
      "stackedensemble Model Build progress: |██████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Base learners' results:\n",
      "\n",
      "    LogisticRegression_binomial - F1-Score: 0.9160, AUC-PR: 0.9554, Accuracy (Test Set): 0.9334\n",
      "    RandomForest_10trees - F1-Score: 0.9310, AUC-PR: 0.9714, Accuracy (Test Set): 0.9457\n",
      "    RandomForest_50trees - F1-Score: 0.9298, AUC-PR: 0.9777, Accuracy (Test Set): 0.9429\n",
      "    GradientBoosting_10trees - F1-Score: 0.9186, AUC-PR: 0.9722, Accuracy (Test Set): 0.9348\n",
      "    GradientBoosting_20trees - F1-Score: 0.9320, AUC-PR: 0.9788, Accuracy (Test Set): 0.9443\n",
      "    NeuralNetwork_10 - F1-Score: 0.9165, AUC-PR: 0.9590, Accuracy (Test Set): 0.9321\n",
      "\n",
      ">>> Metalearner's results:\n",
      "\n",
      "    Super Learner - F1-Score: 0.9402, AUC-PR: 0.9825, Accuracy: 0.9524\n",
      "\n",
      ">>> Training base learners:\n",
      "\n",
      "    Training LogisticRegression_binomial with 12-fold cross-validation...\n",
      "glm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training RandomForest_10trees with 12-fold cross-validation...\n",
      "drf Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training RandomForest_50trees with 12-fold cross-validation...\n",
      "drf Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting_10trees with 12-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting_20trees with 12-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training NeuralNetwork_16 with 12-fold cross-validation...\n",
      "deeplearning Model Build progress: |█████████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Training super learner:\n",
      "\n",
      "stackedensemble Model Build progress: |██████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Base learners' results:\n",
      "\n",
      "    LogisticRegression_binomial - F1-Score: 0.9160, AUC-PR: 0.9554, Accuracy (Test Set): 0.9334\n",
      "    RandomForest_10trees - F1-Score: 0.9310, AUC-PR: 0.9714, Accuracy (Test Set): 0.9457\n",
      "    RandomForest_50trees - F1-Score: 0.9298, AUC-PR: 0.9777, Accuracy (Test Set): 0.9429\n",
      "    GradientBoosting_10trees - F1-Score: 0.9186, AUC-PR: 0.9722, Accuracy (Test Set): 0.9348\n",
      "    GradientBoosting_20trees - F1-Score: 0.9320, AUC-PR: 0.9788, Accuracy (Test Set): 0.9443\n",
      "    NeuralNetwork_16 - F1-Score: 0.9404, AUC-PR: 0.9692, Accuracy (Test Set): 0.9524\n",
      "\n",
      ">>> Metalearner's results:\n",
      "\n",
      "    Super Learner - F1-Score: 0.9454, AUC-PR: 0.9842, Accuracy: 0.9565\n",
      "\n",
      ">>> Training base learners:\n",
      "\n",
      "    Training NaiveBayes with 12-fold cross-validation...\n",
      "naivebayes Model Build progress: |███████████████████████████████████████████████| (done) 100%\n",
      "    Training RandomForest_10trees with 12-fold cross-validation...\n",
      "drf Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting_10trees with 12-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting_50trees with 12-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training NeuralNetwork_10 with 12-fold cross-validation...\n",
      "deeplearning Model Build progress: |█████████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Training super learner:\n",
      "\n",
      "stackedensemble Model Build progress: |██████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Base learners' results:\n",
      "\n",
      "    NaiveBayes - F1-Score: 0.8303, AUC-PR: 0.7914, Accuracy (Test Set): 0.8628\n",
      "    RandomForest_10trees - F1-Score: 0.9310, AUC-PR: 0.9714, Accuracy (Test Set): 0.9457\n",
      "    GradientBoosting_10trees - F1-Score: 0.9186, AUC-PR: 0.9722, Accuracy (Test Set): 0.9348\n",
      "    GradientBoosting_50trees - F1-Score: 0.9472, AUC-PR: 0.9857, Accuracy (Test Set): 0.9579\n",
      "    NeuralNetwork_10 - F1-Score: 0.9199, AUC-PR: 0.9611, Accuracy (Test Set): 0.9361\n",
      "\n",
      ">>> Metalearner's results:\n",
      "\n",
      "    Super Learner - F1-Score: 0.9543, AUC-PR: 0.9796, Accuracy: 0.9633\n",
      "\n",
      ">>> Training base learners:\n",
      "\n",
      "    Training NaiveBayes with 12-fold cross-validation...\n",
      "naivebayes Model Build progress: |███████████████████████████████████████████████| (done) 100%\n",
      "    Training RandomForest_10trees with 12-fold cross-validation...\n",
      "drf Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting_10trees with 12-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting_50trees with 12-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training NeuralNetwork_16 with 12-fold cross-validation...\n",
      "deeplearning Model Build progress: |█████████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Training super learner:\n",
      "\n",
      "stackedensemble Model Build progress: |██████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Base learners' results:\n",
      "\n",
      "    NaiveBayes - F1-Score: 0.8303, AUC-PR: 0.7914, Accuracy (Test Set): 0.8628\n",
      "    RandomForest_10trees - F1-Score: 0.9310, AUC-PR: 0.9714, Accuracy (Test Set): 0.9457\n",
      "    GradientBoosting_10trees - F1-Score: 0.9186, AUC-PR: 0.9722, Accuracy (Test Set): 0.9348\n",
      "    GradientBoosting_50trees - F1-Score: 0.9472, AUC-PR: 0.9857, Accuracy (Test Set): 0.9579\n",
      "    NeuralNetwork_16 - F1-Score: 0.9304, AUC-PR: 0.9677, Accuracy (Test Set): 0.9443\n",
      "\n",
      ">>> Metalearner's results:\n",
      "\n",
      "    Super Learner - F1-Score: 0.9559, AUC-PR: 0.9802, Accuracy: 0.9647\n",
      "\n",
      ">>> Training base learners:\n",
      "\n",
      "    Training NaiveBayes with 12-fold cross-validation...\n",
      "naivebayes Model Build progress: |███████████████████████████████████████████████| (done) 100%\n",
      "    Training RandomForest_10trees with 12-fold cross-validation...\n",
      "drf Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting_10trees with 12-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting_20trees with 12-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training NeuralNetwork_10 with 12-fold cross-validation...\n",
      "deeplearning Model Build progress: |█████████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Training super learner:\n",
      "\n",
      "stackedensemble Model Build progress: |██████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Base learners' results:\n",
      "\n",
      "    NaiveBayes - F1-Score: 0.8303, AUC-PR: 0.7914, Accuracy (Test Set): 0.8628\n",
      "    RandomForest_10trees - F1-Score: 0.9310, AUC-PR: 0.9714, Accuracy (Test Set): 0.9457\n",
      "    GradientBoosting_10trees - F1-Score: 0.9186, AUC-PR: 0.9722, Accuracy (Test Set): 0.9348\n",
      "    GradientBoosting_20trees - F1-Score: 0.9320, AUC-PR: 0.9788, Accuracy (Test Set): 0.9443\n",
      "    NeuralNetwork_10 - F1-Score: 0.9228, AUC-PR: 0.9553, Accuracy (Test Set): 0.9389\n",
      "\n",
      ">>> Metalearner's results:\n",
      "\n",
      "    Super Learner - F1-Score: 0.9465, AUC-PR: 0.9792, Accuracy: 0.9579\n",
      "\n",
      ">>> Training base learners:\n",
      "\n",
      "    Training NaiveBayes with 12-fold cross-validation...\n",
      "naivebayes Model Build progress: |███████████████████████████████████████████████| (done) 100%\n",
      "    Training RandomForest_10trees with 12-fold cross-validation...\n",
      "drf Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting_10trees with 12-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting_20trees with 12-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training NeuralNetwork_16 with 12-fold cross-validation...\n",
      "deeplearning Model Build progress: |█████████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Training super learner:\n",
      "\n",
      "stackedensemble Model Build progress: |██████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Base learners' results:\n",
      "\n",
      "    NaiveBayes - F1-Score: 0.8303, AUC-PR: 0.7914, Accuracy (Test Set): 0.8628\n",
      "    RandomForest_10trees - F1-Score: 0.9310, AUC-PR: 0.9714, Accuracy (Test Set): 0.9457\n",
      "    GradientBoosting_10trees - F1-Score: 0.9186, AUC-PR: 0.9722, Accuracy (Test Set): 0.9348\n",
      "    GradientBoosting_20trees - F1-Score: 0.9320, AUC-PR: 0.9788, Accuracy (Test Set): 0.9443\n",
      "    NeuralNetwork_16 - F1-Score: 0.9404, AUC-PR: 0.9726, Accuracy (Test Set): 0.9524\n",
      "\n",
      ">>> Metalearner's results:\n",
      "\n",
      "    Super Learner - F1-Score: 0.9470, AUC-PR: 0.9827, Accuracy: 0.9579\n",
      "\n",
      ">>> Training base learners:\n",
      "\n",
      "    Training NaiveBayes with 12-fold cross-validation...\n",
      "naivebayes Model Build progress: |███████████████████████████████████████████████| (done) 100%\n",
      "    Training RandomForest_50trees with 12-fold cross-validation...\n",
      "drf Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting_10trees with 12-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting_50trees with 12-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training NeuralNetwork_10 with 12-fold cross-validation...\n",
      "deeplearning Model Build progress: |█████████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Training super learner:\n",
      "\n",
      "stackedensemble Model Build progress: |██████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Base learners' results:\n",
      "\n",
      "    NaiveBayes - F1-Score: 0.8303, AUC-PR: 0.7914, Accuracy (Test Set): 0.8628\n",
      "    RandomForest_50trees - F1-Score: 0.9298, AUC-PR: 0.9777, Accuracy (Test Set): 0.9429\n",
      "    GradientBoosting_10trees - F1-Score: 0.9186, AUC-PR: 0.9722, Accuracy (Test Set): 0.9348\n",
      "    GradientBoosting_50trees - F1-Score: 0.9472, AUC-PR: 0.9857, Accuracy (Test Set): 0.9579\n",
      "    NeuralNetwork_10 - F1-Score: 0.9210, AUC-PR: 0.9646, Accuracy (Test Set): 0.9375\n",
      "\n",
      ">>> Metalearner's results:\n",
      "\n",
      "    Super Learner - F1-Score: 0.9509, AUC-PR: 0.9845, Accuracy: 0.9606\n",
      "\n",
      ">>> Training base learners:\n",
      "\n",
      "    Training NaiveBayes with 12-fold cross-validation...\n",
      "naivebayes Model Build progress: |███████████████████████████████████████████████| (done) 100%\n",
      "    Training RandomForest_50trees with 12-fold cross-validation...\n",
      "drf Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting_10trees with 12-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting_50trees with 12-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training NeuralNetwork_16 with 12-fold cross-validation...\n",
      "deeplearning Model Build progress: |█████████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Training super learner:\n",
      "\n",
      "stackedensemble Model Build progress: |██████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Base learners' results:\n",
      "\n",
      "    NaiveBayes - F1-Score: 0.8303, AUC-PR: 0.7914, Accuracy (Test Set): 0.8628\n",
      "    RandomForest_50trees - F1-Score: 0.9298, AUC-PR: 0.9777, Accuracy (Test Set): 0.9429\n",
      "    GradientBoosting_10trees - F1-Score: 0.9186, AUC-PR: 0.9722, Accuracy (Test Set): 0.9348\n",
      "    GradientBoosting_50trees - F1-Score: 0.9472, AUC-PR: 0.9857, Accuracy (Test Set): 0.9579\n",
      "    NeuralNetwork_16 - F1-Score: 0.9347, AUC-PR: 0.9629, Accuracy (Test Set): 0.9484\n",
      "\n",
      ">>> Metalearner's results:\n",
      "\n",
      "    Super Learner - F1-Score: 0.9542, AUC-PR: 0.9851, Accuracy: 0.9633\n",
      "\n",
      ">>> Training base learners:\n",
      "\n",
      "    Training NaiveBayes with 12-fold cross-validation...\n",
      "naivebayes Model Build progress: |███████████████████████████████████████████████| (done) 100%\n",
      "    Training RandomForest_50trees with 12-fold cross-validation...\n",
      "drf Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting_10trees with 12-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting_20trees with 12-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training NeuralNetwork_10 with 12-fold cross-validation...\n",
      "deeplearning Model Build progress: |█████████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Training super learner:\n",
      "\n",
      "stackedensemble Model Build progress: |██████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Base learners' results:\n",
      "\n",
      "    NaiveBayes - F1-Score: 0.8303, AUC-PR: 0.7914, Accuracy (Test Set): 0.8628\n",
      "    RandomForest_50trees - F1-Score: 0.9298, AUC-PR: 0.9777, Accuracy (Test Set): 0.9429\n",
      "    GradientBoosting_10trees - F1-Score: 0.9186, AUC-PR: 0.9722, Accuracy (Test Set): 0.9348\n",
      "    GradientBoosting_20trees - F1-Score: 0.9320, AUC-PR: 0.9788, Accuracy (Test Set): 0.9443\n",
      "    NeuralNetwork_10 - F1-Score: 0.9160, AUC-PR: 0.9633, Accuracy (Test Set): 0.9334\n",
      "\n",
      ">>> Metalearner's results:\n",
      "\n",
      "    Super Learner - F1-Score: 0.9452, AUC-PR: 0.9822, Accuracy: 0.9565\n",
      "\n",
      ">>> Training base learners:\n",
      "\n",
      "    Training NaiveBayes with 12-fold cross-validation...\n",
      "naivebayes Model Build progress: |███████████████████████████████████████████████| (done) 100%\n",
      "    Training RandomForest_50trees with 12-fold cross-validation...\n",
      "drf Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting_10trees with 12-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting_20trees with 12-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training NeuralNetwork_16 with 12-fold cross-validation...\n",
      "deeplearning Model Build progress: |█████████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Training super learner:\n",
      "\n",
      "stackedensemble Model Build progress: |██████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Base learners' results:\n",
      "\n",
      "    NaiveBayes - F1-Score: 0.8303, AUC-PR: 0.7914, Accuracy (Test Set): 0.8628\n",
      "    RandomForest_50trees - F1-Score: 0.9298, AUC-PR: 0.9777, Accuracy (Test Set): 0.9429\n",
      "    GradientBoosting_10trees - F1-Score: 0.9186, AUC-PR: 0.9722, Accuracy (Test Set): 0.9348\n",
      "    GradientBoosting_20trees - F1-Score: 0.9320, AUC-PR: 0.9788, Accuracy (Test Set): 0.9443\n",
      "    NeuralNetwork_16 - F1-Score: 0.9329, AUC-PR: 0.9641, Accuracy (Test Set): 0.9470\n",
      "\n",
      ">>> Metalearner's results:\n",
      "\n",
      "    Super Learner - F1-Score: 0.9470, AUC-PR: 0.9833, Accuracy: 0.9579\n",
      "\n",
      ">>> Training base learners:\n",
      "\n",
      "    Training NaiveBayes with 12-fold cross-validation...\n",
      "naivebayes Model Build progress: |███████████████████████████████████████████████| (done) 100%\n",
      "    Training RandomForest_10trees with 12-fold cross-validation...\n",
      "drf Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training RandomForest_50trees with 12-fold cross-validation...\n",
      "drf Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting_10trees with 12-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting_50trees with 12-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training NeuralNetwork_10 with 12-fold cross-validation...\n",
      "deeplearning Model Build progress: |█████████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Training super learner:\n",
      "\n",
      "stackedensemble Model Build progress: |██████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Base learners' results:\n",
      "\n",
      "    NaiveBayes - F1-Score: 0.8303, AUC-PR: 0.7914, Accuracy (Test Set): 0.8628\n",
      "    RandomForest_10trees - F1-Score: 0.9310, AUC-PR: 0.9714, Accuracy (Test Set): 0.9457\n",
      "    RandomForest_50trees - F1-Score: 0.9298, AUC-PR: 0.9777, Accuracy (Test Set): 0.9429\n",
      "    GradientBoosting_10trees - F1-Score: 0.9186, AUC-PR: 0.9722, Accuracy (Test Set): 0.9348\n",
      "    GradientBoosting_50trees - F1-Score: 0.9472, AUC-PR: 0.9857, Accuracy (Test Set): 0.9579\n",
      "    NeuralNetwork_10 - F1-Score: 0.9207, AUC-PR: 0.9644, Accuracy (Test Set): 0.9375\n",
      "\n",
      ">>> Metalearner's results:\n",
      "\n",
      "    Super Learner - F1-Score: 0.9513, AUC-PR: 0.9840, Accuracy: 0.9606\n",
      "\n",
      ">>> Training base learners:\n",
      "\n",
      "    Training NaiveBayes with 12-fold cross-validation...\n",
      "naivebayes Model Build progress: |███████████████████████████████████████████████| (done) 100%\n",
      "    Training RandomForest_10trees with 12-fold cross-validation...\n",
      "drf Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training RandomForest_50trees with 12-fold cross-validation...\n",
      "drf Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting_10trees with 12-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting_50trees with 12-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training NeuralNetwork_16 with 12-fold cross-validation...\n",
      "deeplearning Model Build progress: |█████████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Training super learner:\n",
      "\n",
      "stackedensemble Model Build progress: |██████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Base learners' results:\n",
      "\n",
      "    NaiveBayes - F1-Score: 0.8303, AUC-PR: 0.7914, Accuracy (Test Set): 0.8628\n",
      "    RandomForest_10trees - F1-Score: 0.9310, AUC-PR: 0.9714, Accuracy (Test Set): 0.9457\n",
      "    RandomForest_50trees - F1-Score: 0.9298, AUC-PR: 0.9777, Accuracy (Test Set): 0.9429\n",
      "    GradientBoosting_10trees - F1-Score: 0.9186, AUC-PR: 0.9722, Accuracy (Test Set): 0.9348\n",
      "    GradientBoosting_50trees - F1-Score: 0.9472, AUC-PR: 0.9857, Accuracy (Test Set): 0.9579\n",
      "    NeuralNetwork_16 - F1-Score: 0.9275, AUC-PR: 0.9690, Accuracy (Test Set): 0.9416\n",
      "\n",
      ">>> Metalearner's results:\n",
      "\n",
      "    Super Learner - F1-Score: 0.9527, AUC-PR: 0.9849, Accuracy: 0.9620\n",
      "\n",
      ">>> Training base learners:\n",
      "\n",
      "    Training NaiveBayes with 12-fold cross-validation...\n",
      "naivebayes Model Build progress: |███████████████████████████████████████████████| (done) 100%\n",
      "    Training RandomForest_10trees with 12-fold cross-validation...\n",
      "drf Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training RandomForest_50trees with 12-fold cross-validation...\n",
      "drf Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting_10trees with 12-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting_20trees with 12-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training NeuralNetwork_10 with 12-fold cross-validation...\n",
      "deeplearning Model Build progress: |█████████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Training super learner:\n",
      "\n",
      "stackedensemble Model Build progress: |██████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Base learners' results:\n",
      "\n",
      "    NaiveBayes - F1-Score: 0.8303, AUC-PR: 0.7914, Accuracy (Test Set): 0.8628\n",
      "    RandomForest_10trees - F1-Score: 0.9310, AUC-PR: 0.9714, Accuracy (Test Set): 0.9457\n",
      "    RandomForest_50trees - F1-Score: 0.9298, AUC-PR: 0.9777, Accuracy (Test Set): 0.9429\n",
      "    GradientBoosting_10trees - F1-Score: 0.9186, AUC-PR: 0.9722, Accuracy (Test Set): 0.9348\n",
      "    GradientBoosting_20trees - F1-Score: 0.9320, AUC-PR: 0.9788, Accuracy (Test Set): 0.9443\n",
      "    NeuralNetwork_10 - F1-Score: 0.9368, AUC-PR: 0.9721, Accuracy (Test Set): 0.9497\n",
      "\n",
      ">>> Metalearner's results:\n",
      "\n",
      "    Super Learner - F1-Score: 0.9466, AUC-PR: 0.9832, Accuracy: 0.9579\n",
      "\n",
      ">>> Training base learners:\n",
      "\n",
      "    Training NaiveBayes with 12-fold cross-validation...\n",
      "naivebayes Model Build progress: |███████████████████████████████████████████████| (done) 100%\n",
      "    Training RandomForest_10trees with 12-fold cross-validation...\n",
      "drf Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training RandomForest_50trees with 12-fold cross-validation...\n",
      "drf Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting_10trees with 12-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting_20trees with 12-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training NeuralNetwork_16 with 12-fold cross-validation...\n",
      "deeplearning Model Build progress: |█████████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Training super learner:\n",
      "\n",
      "stackedensemble Model Build progress: |██████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Base learners' results:\n",
      "\n",
      "    NaiveBayes - F1-Score: 0.8303, AUC-PR: 0.7914, Accuracy (Test Set): 0.8628\n",
      "    RandomForest_10trees - F1-Score: 0.9310, AUC-PR: 0.9714, Accuracy (Test Set): 0.9457\n",
      "    RandomForest_50trees - F1-Score: 0.9298, AUC-PR: 0.9777, Accuracy (Test Set): 0.9429\n",
      "    GradientBoosting_10trees - F1-Score: 0.9186, AUC-PR: 0.9722, Accuracy (Test Set): 0.9348\n",
      "    GradientBoosting_20trees - F1-Score: 0.9320, AUC-PR: 0.9788, Accuracy (Test Set): 0.9443\n",
      "    NeuralNetwork_16 - F1-Score: 0.9226, AUC-PR: 0.9693, Accuracy (Test Set): 0.9375\n",
      "\n",
      ">>> Metalearner's results:\n",
      "\n",
      "    Super Learner - F1-Score: 0.9424, AUC-PR: 0.9836, Accuracy: 0.9538\n"
     ]
    }
   ],
   "source": [
    "results = dict()\n",
    "\n",
    "for i, stack in enumerate(configurations):\n",
    "    results[i] = train_evaluate_stack(stack, \"glm\", h2o_train, h2o_val, X_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa573bdf-5e78-442a-be72-92d8bb93ba10",
   "metadata": {},
   "source": [
    "## Results achieved from combinations built on single primitive model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 988,
   "id": "82501aaf-9264-4034-82db-5a1651b132a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-e344c27e898c488d926fe4265b2b2623.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-e344c27e898c488d926fe4265b2b2623.vega-embed details,\n",
       "  #altair-viz-e344c27e898c488d926fe4265b2b2623.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-e344c27e898c488d926fe4265b2b2623\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-e344c27e898c488d926fe4265b2b2623\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-e344c27e898c488d926fe4265b2b2623\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.8.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.8.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}, \"axis\": {\"labelLimit\": 1000}}, \"hconcat\": [{\"mark\": {\"type\": \"point\", \"fill\": \"orange\", \"stroke\": \"orange\"}, \"encoding\": {\"x\": {\"field\": \"AUC-PR\", \"scale\": {\"zero\": false}, \"type\": \"quantitative\"}, \"y\": {\"axis\": {\"title\": null}, \"field\": \"Configuration\", \"sort\": \"-x\", \"type\": \"nominal\"}}, \"width\": 120}, {\"mark\": {\"type\": \"point\", \"fill\": \"blue\"}, \"encoding\": {\"x\": {\"field\": \"F1-Score\", \"scale\": {\"zero\": false}, \"type\": \"quantitative\"}, \"y\": {\"axis\": {\"title\": null}, \"field\": \"Configuration\", \"sort\": \"-x\", \"type\": \"nominal\"}}, \"width\": 120}, {\"mark\": {\"type\": \"point\", \"fill\": \"purple\", \"stroke\": \"purple\"}, \"encoding\": {\"x\": {\"field\": \"Accuracy\", \"scale\": {\"zero\": false}, \"type\": \"quantitative\"}, \"y\": {\"axis\": {\"title\": null}, \"field\": \"Configuration\", \"sort\": \"-x\", \"type\": \"nominal\"}}, \"width\": 120}], \"data\": {\"name\": \"data-93d9c8129f36ccd9dbf83679fa4b9542\"}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.8.0.json\", \"datasets\": {\"data-93d9c8129f36ccd9dbf83679fa4b9542\": [{\"F1-Score\": 0.9493243243243243, \"AUC-PR\": 0.9807891471838461, \"Accuracy\": 0.9592391304347826, \"Configuration\": \"LR_RF_10_GB_10_GB_50_MLP_10\"}, {\"F1-Score\": 0.9489795918367347, \"AUC-PR\": 0.9810293781438096, \"Accuracy\": 0.9592391304347826, \"Configuration\": \"LR_RF_10_GB_10_GB_50_MLP_16\"}, {\"F1-Score\": 0.9417808219178082, \"AUC-PR\": 0.9812678446905503, \"Accuracy\": 0.9538043478260869, \"Configuration\": \"LR_RF_10_GB_10_GB_20_MLP_10\"}, {\"F1-Score\": 0.9433962264150944, \"AUC-PR\": 0.9824503467366736, \"Accuracy\": 0.9551630434782609, \"Configuration\": \"LR_RF_10_GB_10_GB_20_MLP_16\"}, {\"F1-Score\": 0.9477351916376306, \"AUC-PR\": 0.9847468863859846, \"Accuracy\": 0.9592391304347826, \"Configuration\": \"LR_RF_50_GB_10_GB_50_MLP_10\"}, {\"F1-Score\": 0.952054794520548, \"AUC-PR\": 0.985011430840665, \"Accuracy\": 0.9619565217391305, \"Configuration\": \"LR_RF_50_GB_10_GB_50_MLP_16\"}, {\"F1-Score\": 0.9430051813471502, \"AUC-PR\": 0.9823550010336619, \"Accuracy\": 0.9551630434782609, \"Configuration\": \"LR_RF_50_GB_10_GB_20_MLP_10\"}, {\"F1-Score\": 0.9421768707482994, \"AUC-PR\": 0.9828287833309839, \"Accuracy\": 0.9538043478260869, \"Configuration\": \"LR_RF_50_GB_10_GB_20_MLP_16\"}, {\"F1-Score\": 0.9477234401349074, \"AUC-PR\": 0.9845410530949259, \"Accuracy\": 0.9578804347826086, \"Configuration\": \"LR_RF_10_RF_50_GB_10_GB_50_MLP_10\"}, {\"F1-Score\": 0.9493243243243243, \"AUC-PR\": 0.9854114310320963, \"Accuracy\": 0.9592391304347826, \"Configuration\": \"LR_RF_10_RF_50_GB_10_GB_50_MLP_16\"}, {\"F1-Score\": 0.9401709401709402, \"AUC-PR\": 0.982507791243966, \"Accuracy\": 0.9524456521739131, \"Configuration\": \"LR_RF_10_RF_50_GB_10_GB_20_MLP_10\"}, {\"F1-Score\": 0.945392491467577, \"AUC-PR\": 0.9841989716544953, \"Accuracy\": 0.9565217391304348, \"Configuration\": \"LR_RF_10_RF_50_GB_10_GB_20_MLP_16\"}, {\"F1-Score\": 0.9543147208121828, \"AUC-PR\": 0.9796008120862898, \"Accuracy\": 0.9633152173913043, \"Configuration\": \"NB_RF_10_GB_10_GB_50_MLP_10\"}, {\"F1-Score\": 0.9559322033898305, \"AUC-PR\": 0.9802046029803277, \"Accuracy\": 0.9646739130434783, \"Configuration\": \"NB_RF_10_GB_10_GB_50_MLP_16\"}, {\"F1-Score\": 0.9464594127806563, \"AUC-PR\": 0.9791675231755099, \"Accuracy\": 0.9578804347826086, \"Configuration\": \"NB_RF_10_GB_10_GB_20_MLP_10\"}, {\"F1-Score\": 0.947008547008547, \"AUC-PR\": 0.9826939101589753, \"Accuracy\": 0.9578804347826086, \"Configuration\": \"NB_RF_10_GB_10_GB_20_MLP_16\"}, {\"F1-Score\": 0.9509306260575295, \"AUC-PR\": 0.984458729931136, \"Accuracy\": 0.9605978260869565, \"Configuration\": \"NB_RF_50_GB_10_GB_50_MLP_10\"}, {\"F1-Score\": 0.9541595925297113, \"AUC-PR\": 0.9850719051688422, \"Accuracy\": 0.9633152173913043, \"Configuration\": \"NB_RF_50_GB_10_GB_50_MLP_16\"}, {\"F1-Score\": 0.9452054794520548, \"AUC-PR\": 0.9821924295000077, \"Accuracy\": 0.9565217391304348, \"Configuration\": \"NB_RF_50_GB_10_GB_20_MLP_10\"}, {\"F1-Score\": 0.947008547008547, \"AUC-PR\": 0.9832520047371182, \"Accuracy\": 0.9578804347826086, \"Configuration\": \"NB_RF_50_GB_10_GB_20_MLP_16\"}, {\"F1-Score\": 0.9512605042016807, \"AUC-PR\": 0.9839610608621263, \"Accuracy\": 0.9605978260869565, \"Configuration\": \"NB_RF_10_RF_50_GB_10_GB_50_MLP_10\"}, {\"F1-Score\": 0.9527027027027025, \"AUC-PR\": 0.9848884134215586, \"Accuracy\": 0.9619565217391305, \"Configuration\": \"NB_RF_10_RF_50_GB_10_GB_50_MLP_16\"}, {\"F1-Score\": 0.9466437177280552, \"AUC-PR\": 0.9832295836921638, \"Accuracy\": 0.9578804347826086, \"Configuration\": \"NB_RF_10_RF_50_GB_10_GB_20_MLP_10\"}, {\"F1-Score\": 0.9423728813559321, \"AUC-PR\": 0.9835857983805019, \"Accuracy\": 0.9538043478260869, \"Configuration\": \"NB_RF_10_RF_50_GB_10_GB_20_MLP_16\"}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.HConcatChart(...)"
      ]
     },
     "execution_count": 988,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import altair as alt \n",
    "\n",
    "labels = []\n",
    "for conf in configurations:\n",
    "    label = \"_\".join(conf.keys())\n",
    "    label = label.replace(\"LogisticRegression_binomial\", \"LR\")\n",
    "    label = label.replace(\"RandomForest\", \"RF\")\n",
    "    label = label.replace(\"GradientBoosting\", \"GB\")\n",
    "    label = label.replace(\"NeuralNetwork\", \"MLP\")\n",
    "    label = label.replace(\"trees\", \"\")\n",
    "    label = label.replace(\"NaiveBayes\", \"NB\")\n",
    "    labels.append(label)\n",
    "    \n",
    "data_single = []\n",
    "for label, record in zip(labels, results.values()):\n",
    "    record[\"Configuration\"] = label\n",
    "    data_single.append(record)\n",
    "data\n",
    "df = pd.DataFrame(data_single)\n",
    "\n",
    "f1_chart = alt.Chart(df).mark_point(fill=\"blue\").encode(\n",
    "    y=alt.Y('Configuration', sort=\"-x\", axis=alt.Axis(title=None)),\n",
    "    x=alt.X('F1-Score').scale(zero=False)\n",
    ").properties(width=120)\n",
    "\n",
    "aucpr_chart = alt.Chart(df).mark_point(fill=\"orange\", stroke=\"orange\").encode(\n",
    "    y=alt.Y('Configuration', sort=\"-x\", axis=alt.Axis(title=None)),\n",
    "    x=alt.X('AUC-PR').scale(zero=False)\n",
    ").properties(width=120)\n",
    "\n",
    "accuracy_chart = alt.Chart(df).mark_point(fill=\"purple\", stroke=\"purple\").encode(\n",
    "    y=alt.Y('Configuration', sort=\"-x\", axis=alt.Axis(title=None)),\n",
    "    x=alt.X('Accuracy').scale(zero=False)\n",
    ").properties(width=120)\n",
    "(aucpr_chart | f1_chart | accuracy_chart).configure_axis(labelLimit=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa7e8a0-0e74-4bae-9bce-a5e36e3d565e",
   "metadata": {},
   "source": [
    "# Now we also add combinations using both LR and NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 945,
   "id": "01aad330-ad4f-4ff8-be88-53d270b3c1f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of configurations: 12\n"
     ]
    }
   ],
   "source": [
    "simple_learners_combined = [{\n",
    "                   \"LogisticRegression_binomial\": H2OGeneralizedLinearEstimator(\n",
    "                        family=\"binomial\", nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "                    ), \n",
    "                   \"NaiveBayes\": H2ONaiveBayesEstimator(nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True)}]\n",
    "\n",
    "all_combinations_combined = list(product(simple_learners_combined, random_forests, gradient_boosting, mlps))\n",
    "\n",
    "\n",
    "configurations_combined = []\n",
    "for combination in all_combinations_combined:\n",
    "    combined_config = {}\n",
    "    for model_dict in combination:\n",
    "        combined_config.update(model_dict)  # Merge dictionaries\n",
    "    configurations_combined.append(combined_config)\n",
    "\n",
    "print(f\"Number of configurations: {len(configurations_combined)}\")\n",
    "# print(\"Sample configuration:\", configurations_combined[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 941,
   "id": "050d598e-5c8a-4eb2-a53f-baf241886181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Training base learners:\n",
      "\n",
      "    Training LogisticRegression_binomial with 12-fold cross-validation...\n",
      "glm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training NaiveBayes with 12-fold cross-validation...\n",
      "naivebayes Model Build progress: |███████████████████████████████████████████████| (done) 100%\n",
      "    Training RandomForest_10trees with 12-fold cross-validation...\n",
      "drf Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting_10trees with 12-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting_50trees with 12-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training NeuralNetwork_10 with 12-fold cross-validation...\n",
      "deeplearning Model Build progress: |█████████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Training super learner:\n",
      "\n",
      "stackedensemble Model Build progress: |██████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Base learners' results:\n",
      "\n",
      "    LogisticRegression_binomial - F1-Score: 0.9160, AUC-PR: 0.9554, Accuracy (Test Set): 0.9334\n",
      "    NaiveBayes - F1-Score: 0.8303, AUC-PR: 0.7914, Accuracy (Test Set): 0.8628\n",
      "    RandomForest_10trees - F1-Score: 0.9310, AUC-PR: 0.9714, Accuracy (Test Set): 0.9457\n",
      "    GradientBoosting_10trees - F1-Score: 0.9186, AUC-PR: 0.9722, Accuracy (Test Set): 0.9348\n",
      "    GradientBoosting_50trees - F1-Score: 0.9472, AUC-PR: 0.9857, Accuracy (Test Set): 0.9579\n",
      "    NeuralNetwork_10 - F1-Score: 0.9257, AUC-PR: 0.9711, Accuracy (Test Set): 0.9402\n",
      "\n",
      ">>> Metalearner's results:\n",
      "\n",
      "    Super Learner - F1-Score: 0.9493, AUC-PR: 0.9796, Accuracy: 0.9592\n",
      "\n",
      ">>> Training base learners:\n",
      "\n",
      "    Training LogisticRegression_binomial with 12-fold cross-validation...\n",
      "glm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training NaiveBayes with 12-fold cross-validation...\n",
      "naivebayes Model Build progress: |███████████████████████████████████████████████| (done) 100%\n",
      "    Training RandomForest_10trees with 12-fold cross-validation...\n",
      "drf Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting_10trees with 12-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting_50trees with 12-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training NeuralNetwork_16 with 12-fold cross-validation...\n",
      "deeplearning Model Build progress: |█████████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Training super learner:\n",
      "\n",
      "stackedensemble Model Build progress: |██████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Base learners' results:\n",
      "\n",
      "    LogisticRegression_binomial - F1-Score: 0.9160, AUC-PR: 0.9554, Accuracy (Test Set): 0.9334\n",
      "    NaiveBayes - F1-Score: 0.8303, AUC-PR: 0.7914, Accuracy (Test Set): 0.8628\n",
      "    RandomForest_10trees - F1-Score: 0.9310, AUC-PR: 0.9714, Accuracy (Test Set): 0.9457\n",
      "    GradientBoosting_10trees - F1-Score: 0.9186, AUC-PR: 0.9722, Accuracy (Test Set): 0.9348\n",
      "    GradientBoosting_50trees - F1-Score: 0.9472, AUC-PR: 0.9857, Accuracy (Test Set): 0.9579\n",
      "    NeuralNetwork_16 - F1-Score: 0.9390, AUC-PR: 0.9707, Accuracy (Test Set): 0.9511\n",
      "\n",
      ">>> Metalearner's results:\n",
      "\n",
      "    Super Learner - F1-Score: 0.9488, AUC-PR: 0.9812, Accuracy: 0.9592\n",
      "\n",
      ">>> Training base learners:\n",
      "\n",
      "    Training LogisticRegression_binomial with 12-fold cross-validation...\n",
      "glm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training NaiveBayes with 12-fold cross-validation...\n",
      "naivebayes Model Build progress: |███████████████████████████████████████████████| (done) 100%\n",
      "    Training RandomForest_10trees with 12-fold cross-validation...\n",
      "drf Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting_10trees with 12-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting_20trees with 12-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training NeuralNetwork_10 with 12-fold cross-validation...\n",
      "deeplearning Model Build progress: |█████████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Training super learner:\n",
      "\n",
      "stackedensemble Model Build progress: |██████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Base learners' results:\n",
      "\n",
      "    LogisticRegression_binomial - F1-Score: 0.9160, AUC-PR: 0.9554, Accuracy (Test Set): 0.9334\n",
      "    NaiveBayes - F1-Score: 0.8303, AUC-PR: 0.7914, Accuracy (Test Set): 0.8628\n",
      "    RandomForest_10trees - F1-Score: 0.9310, AUC-PR: 0.9714, Accuracy (Test Set): 0.9457\n",
      "    GradientBoosting_10trees - F1-Score: 0.9186, AUC-PR: 0.9722, Accuracy (Test Set): 0.9348\n",
      "    GradientBoosting_20trees - F1-Score: 0.9320, AUC-PR: 0.9788, Accuracy (Test Set): 0.9443\n",
      "    NeuralNetwork_10 - F1-Score: 0.9194, AUC-PR: 0.9605, Accuracy (Test Set): 0.9361\n",
      "\n",
      ">>> Metalearner's results:\n",
      "\n",
      "    Super Learner - F1-Score: 0.9450, AUC-PR: 0.9808, Accuracy: 0.9565\n",
      "\n",
      ">>> Training base learners:\n",
      "\n",
      "    Training LogisticRegression_binomial with 12-fold cross-validation...\n",
      "glm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training NaiveBayes with 12-fold cross-validation...\n",
      "naivebayes Model Build progress: |███████████████████████████████████████████████| (done) 100%\n",
      "    Training RandomForest_10trees with 12-fold cross-validation...\n",
      "drf Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting_10trees with 12-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting_20trees with 12-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training NeuralNetwork_16 with 12-fold cross-validation...\n",
      "deeplearning Model Build progress: |█████████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Training super learner:\n",
      "\n",
      "stackedensemble Model Build progress: |██████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Base learners' results:\n",
      "\n",
      "    LogisticRegression_binomial - F1-Score: 0.9160, AUC-PR: 0.9554, Accuracy (Test Set): 0.9334\n",
      "    NaiveBayes - F1-Score: 0.8303, AUC-PR: 0.7914, Accuracy (Test Set): 0.8628\n",
      "    RandomForest_10trees - F1-Score: 0.9310, AUC-PR: 0.9714, Accuracy (Test Set): 0.9457\n",
      "    GradientBoosting_10trees - F1-Score: 0.9186, AUC-PR: 0.9722, Accuracy (Test Set): 0.9348\n",
      "    GradientBoosting_20trees - F1-Score: 0.9320, AUC-PR: 0.9788, Accuracy (Test Set): 0.9443\n",
      "    NeuralNetwork_16 - F1-Score: 0.9276, AUC-PR: 0.9718, Accuracy (Test Set): 0.9429\n",
      "\n",
      ">>> Metalearner's results:\n",
      "\n",
      "    Super Learner - F1-Score: 0.9438, AUC-PR: 0.9809, Accuracy: 0.9552\n",
      "\n",
      ">>> Training base learners:\n",
      "\n",
      "    Training LogisticRegression_binomial with 12-fold cross-validation...\n",
      "glm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training NaiveBayes with 12-fold cross-validation...\n",
      "naivebayes Model Build progress: |███████████████████████████████████████████████| (done) 100%\n",
      "    Training RandomForest_50trees with 12-fold cross-validation...\n",
      "drf Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting_10trees with 12-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting_50trees with 12-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training NeuralNetwork_10 with 12-fold cross-validation...\n",
      "deeplearning Model Build progress: |█████████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Training super learner:\n",
      "\n",
      "stackedensemble Model Build progress: |██████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Base learners' results:\n",
      "\n",
      "    LogisticRegression_binomial - F1-Score: 0.9160, AUC-PR: 0.9554, Accuracy (Test Set): 0.9334\n",
      "    NaiveBayes - F1-Score: 0.8303, AUC-PR: 0.7914, Accuracy (Test Set): 0.8628\n",
      "    RandomForest_50trees - F1-Score: 0.9298, AUC-PR: 0.9777, Accuracy (Test Set): 0.9429\n",
      "    GradientBoosting_10trees - F1-Score: 0.9186, AUC-PR: 0.9722, Accuracy (Test Set): 0.9348\n",
      "    GradientBoosting_50trees - F1-Score: 0.9472, AUC-PR: 0.9857, Accuracy (Test Set): 0.9579\n",
      "    NeuralNetwork_10 - F1-Score: 0.9273, AUC-PR: 0.9712, Accuracy (Test Set): 0.9429\n",
      "\n",
      ">>> Metalearner's results:\n",
      "\n",
      "    Super Learner - F1-Score: 0.9479, AUC-PR: 0.9845, Accuracy: 0.9579\n",
      "\n",
      ">>> Training base learners:\n",
      "\n",
      "    Training LogisticRegression_binomial with 12-fold cross-validation...\n",
      "glm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training NaiveBayes with 12-fold cross-validation...\n",
      "naivebayes Model Build progress: |███████████████████████████████████████████████| (done) 100%\n",
      "    Training RandomForest_50trees with 12-fold cross-validation...\n",
      "drf Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting_10trees with 12-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting_50trees with 12-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training NeuralNetwork_16 with 12-fold cross-validation...\n",
      "deeplearning Model Build progress: |█████████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Training super learner:\n",
      "\n",
      "stackedensemble Model Build progress: |██████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Base learners' results:\n",
      "\n",
      "    LogisticRegression_binomial - F1-Score: 0.9160, AUC-PR: 0.9554, Accuracy (Test Set): 0.9334\n",
      "    NaiveBayes - F1-Score: 0.8303, AUC-PR: 0.7914, Accuracy (Test Set): 0.8628\n",
      "    RandomForest_50trees - F1-Score: 0.9298, AUC-PR: 0.9777, Accuracy (Test Set): 0.9429\n",
      "    GradientBoosting_10trees - F1-Score: 0.9186, AUC-PR: 0.9722, Accuracy (Test Set): 0.9348\n",
      "    GradientBoosting_50trees - F1-Score: 0.9472, AUC-PR: 0.9857, Accuracy (Test Set): 0.9579\n",
      "    NeuralNetwork_16 - F1-Score: 0.9361, AUC-PR: 0.9699, Accuracy (Test Set): 0.9497\n",
      "\n",
      ">>> Metalearner's results:\n",
      "\n",
      "    Super Learner - F1-Score: 0.9490, AUC-PR: 0.9841, Accuracy: 0.9592\n",
      "\n",
      ">>> Training base learners:\n",
      "\n",
      "    Training LogisticRegression_binomial with 12-fold cross-validation...\n",
      "glm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training NaiveBayes with 12-fold cross-validation...\n",
      "naivebayes Model Build progress: |███████████████████████████████████████████████| (done) 100%\n",
      "    Training RandomForest_50trees with 12-fold cross-validation...\n",
      "drf Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting_10trees with 12-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting_20trees with 12-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training NeuralNetwork_10 with 12-fold cross-validation...\n",
      "deeplearning Model Build progress: |█████████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Training super learner:\n",
      "\n",
      "stackedensemble Model Build progress: |██████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Base learners' results:\n",
      "\n",
      "    LogisticRegression_binomial - F1-Score: 0.9160, AUC-PR: 0.9554, Accuracy (Test Set): 0.9334\n",
      "    NaiveBayes - F1-Score: 0.8303, AUC-PR: 0.7914, Accuracy (Test Set): 0.8628\n",
      "    RandomForest_50trees - F1-Score: 0.9298, AUC-PR: 0.9777, Accuracy (Test Set): 0.9429\n",
      "    GradientBoosting_10trees - F1-Score: 0.9186, AUC-PR: 0.9722, Accuracy (Test Set): 0.9348\n",
      "    GradientBoosting_20trees - F1-Score: 0.9320, AUC-PR: 0.9788, Accuracy (Test Set): 0.9443\n",
      "    NeuralNetwork_10 - F1-Score: 0.9265, AUC-PR: 0.9607, Accuracy (Test Set): 0.9416\n",
      "\n",
      ">>> Metalearner's results:\n",
      "\n",
      "    Super Learner - F1-Score: 0.9414, AUC-PR: 0.9813, Accuracy: 0.9538\n",
      "\n",
      ">>> Training base learners:\n",
      "\n",
      "    Training LogisticRegression_binomial with 12-fold cross-validation...\n",
      "glm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training NaiveBayes with 12-fold cross-validation...\n",
      "naivebayes Model Build progress: |███████████████████████████████████████████████| (done) 100%\n",
      "    Training RandomForest_50trees with 12-fold cross-validation...\n",
      "drf Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting_10trees with 12-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting_20trees with 12-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training NeuralNetwork_16 with 12-fold cross-validation...\n",
      "deeplearning Model Build progress: |█████████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Training super learner:\n",
      "\n",
      "stackedensemble Model Build progress: |██████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Base learners' results:\n",
      "\n",
      "    LogisticRegression_binomial - F1-Score: 0.9160, AUC-PR: 0.9554, Accuracy (Test Set): 0.9334\n",
      "    NaiveBayes - F1-Score: 0.8303, AUC-PR: 0.7914, Accuracy (Test Set): 0.8628\n",
      "    RandomForest_50trees - F1-Score: 0.9298, AUC-PR: 0.9777, Accuracy (Test Set): 0.9429\n",
      "    GradientBoosting_10trees - F1-Score: 0.9186, AUC-PR: 0.9722, Accuracy (Test Set): 0.9348\n",
      "    GradientBoosting_20trees - F1-Score: 0.9320, AUC-PR: 0.9788, Accuracy (Test Set): 0.9443\n",
      "    NeuralNetwork_16 - F1-Score: 0.9356, AUC-PR: 0.9689, Accuracy (Test Set): 0.9484\n",
      "\n",
      ">>> Metalearner's results:\n",
      "\n",
      "    Super Learner - F1-Score: 0.9440, AUC-PR: 0.9829, Accuracy: 0.9552\n",
      "\n",
      ">>> Training base learners:\n",
      "\n",
      "    Training LogisticRegression_binomial with 12-fold cross-validation...\n",
      "glm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training NaiveBayes with 12-fold cross-validation...\n",
      "naivebayes Model Build progress: |███████████████████████████████████████████████| (done) 100%\n",
      "    Training RandomForest_10trees with 12-fold cross-validation...\n",
      "drf Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training RandomForest_50trees with 12-fold cross-validation...\n",
      "drf Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting_10trees with 12-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting_50trees with 12-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training NeuralNetwork_10 with 12-fold cross-validation...\n",
      "deeplearning Model Build progress: |█████████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Training super learner:\n",
      "\n",
      "stackedensemble Model Build progress: |██████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Base learners' results:\n",
      "\n",
      "    LogisticRegression_binomial - F1-Score: 0.9160, AUC-PR: 0.9554, Accuracy (Test Set): 0.9334\n",
      "    NaiveBayes - F1-Score: 0.8303, AUC-PR: 0.7914, Accuracy (Test Set): 0.8628\n",
      "    RandomForest_10trees - F1-Score: 0.9310, AUC-PR: 0.9714, Accuracy (Test Set): 0.9457\n",
      "    RandomForest_50trees - F1-Score: 0.9298, AUC-PR: 0.9777, Accuracy (Test Set): 0.9429\n",
      "    GradientBoosting_10trees - F1-Score: 0.9186, AUC-PR: 0.9722, Accuracy (Test Set): 0.9348\n",
      "    GradientBoosting_50trees - F1-Score: 0.9472, AUC-PR: 0.9857, Accuracy (Test Set): 0.9579\n",
      "    NeuralNetwork_10 - F1-Score: 0.9291, AUC-PR: 0.9676, Accuracy (Test Set): 0.9429\n",
      "\n",
      ">>> Metalearner's results:\n",
      "\n",
      "    Super Learner - F1-Score: 0.9492, AUC-PR: 0.9851, Accuracy: 0.9592\n",
      "\n",
      ">>> Training base learners:\n",
      "\n",
      "    Training LogisticRegression_binomial with 12-fold cross-validation...\n",
      "glm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training NaiveBayes with 12-fold cross-validation...\n",
      "naivebayes Model Build progress: |███████████████████████████████████████████████| (done) 100%\n",
      "    Training RandomForest_10trees with 12-fold cross-validation...\n",
      "drf Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training RandomForest_50trees with 12-fold cross-validation...\n",
      "drf Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting_10trees with 12-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting_50trees with 12-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training NeuralNetwork_16 with 12-fold cross-validation...\n",
      "deeplearning Model Build progress: |█████████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Training super learner:\n",
      "\n",
      "stackedensemble Model Build progress: |██████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Base learners' results:\n",
      "\n",
      "    LogisticRegression_binomial - F1-Score: 0.9160, AUC-PR: 0.9554, Accuracy (Test Set): 0.9334\n",
      "    NaiveBayes - F1-Score: 0.8303, AUC-PR: 0.7914, Accuracy (Test Set): 0.8628\n",
      "    RandomForest_10trees - F1-Score: 0.9310, AUC-PR: 0.9714, Accuracy (Test Set): 0.9457\n",
      "    RandomForest_50trees - F1-Score: 0.9298, AUC-PR: 0.9777, Accuracy (Test Set): 0.9429\n",
      "    GradientBoosting_10trees - F1-Score: 0.9186, AUC-PR: 0.9722, Accuracy (Test Set): 0.9348\n",
      "    GradientBoosting_50trees - F1-Score: 0.9472, AUC-PR: 0.9857, Accuracy (Test Set): 0.9579\n",
      "    NeuralNetwork_16 - F1-Score: 0.9396, AUC-PR: 0.9765, Accuracy (Test Set): 0.9524\n",
      "\n",
      ">>> Metalearner's results:\n",
      "\n",
      "    Super Learner - F1-Score: 0.9509, AUC-PR: 0.9842, Accuracy: 0.9606\n",
      "\n",
      ">>> Training base learners:\n",
      "\n",
      "    Training LogisticRegression_binomial with 12-fold cross-validation...\n",
      "glm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training NaiveBayes with 12-fold cross-validation...\n",
      "naivebayes Model Build progress: |███████████████████████████████████████████████| (done) 100%\n",
      "    Training RandomForest_10trees with 12-fold cross-validation...\n",
      "drf Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training RandomForest_50trees with 12-fold cross-validation...\n",
      "drf Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting_10trees with 12-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting_20trees with 12-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training NeuralNetwork_10 with 12-fold cross-validation...\n",
      "deeplearning Model Build progress: |█████████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Training super learner:\n",
      "\n",
      "stackedensemble Model Build progress: |██████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Base learners' results:\n",
      "\n",
      "    LogisticRegression_binomial - F1-Score: 0.9160, AUC-PR: 0.9554, Accuracy (Test Set): 0.9334\n",
      "    NaiveBayes - F1-Score: 0.8303, AUC-PR: 0.7914, Accuracy (Test Set): 0.8628\n",
      "    RandomForest_10trees - F1-Score: 0.9310, AUC-PR: 0.9714, Accuracy (Test Set): 0.9457\n",
      "    RandomForest_50trees - F1-Score: 0.9298, AUC-PR: 0.9777, Accuracy (Test Set): 0.9429\n",
      "    GradientBoosting_10trees - F1-Score: 0.9186, AUC-PR: 0.9722, Accuracy (Test Set): 0.9348\n",
      "    GradientBoosting_20trees - F1-Score: 0.9320, AUC-PR: 0.9788, Accuracy (Test Set): 0.9443\n",
      "    NeuralNetwork_10 - F1-Score: 0.9193, AUC-PR: 0.9737, Accuracy (Test Set): 0.9375\n",
      "\n",
      ">>> Metalearner's results:\n",
      "\n",
      "    Super Learner - F1-Score: 0.9485, AUC-PR: 0.9820, Accuracy: 0.9592\n",
      "\n",
      ">>> Training base learners:\n",
      "\n",
      "    Training LogisticRegression_binomial with 12-fold cross-validation...\n",
      "glm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training NaiveBayes with 12-fold cross-validation...\n",
      "naivebayes Model Build progress: |███████████████████████████████████████████████| (done) 100%\n",
      "    Training RandomForest_10trees with 12-fold cross-validation...\n",
      "drf Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training RandomForest_50trees with 12-fold cross-validation...\n",
      "drf Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting_10trees with 12-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting_20trees with 12-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training NeuralNetwork_16 with 12-fold cross-validation...\n",
      "deeplearning Model Build progress: |█████████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Training super learner:\n",
      "\n",
      "stackedensemble Model Build progress: |██████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Base learners' results:\n",
      "\n",
      "    LogisticRegression_binomial - F1-Score: 0.9160, AUC-PR: 0.9554, Accuracy (Test Set): 0.9334\n",
      "    NaiveBayes - F1-Score: 0.8303, AUC-PR: 0.7914, Accuracy (Test Set): 0.8628\n",
      "    RandomForest_10trees - F1-Score: 0.9310, AUC-PR: 0.9714, Accuracy (Test Set): 0.9457\n",
      "    RandomForest_50trees - F1-Score: 0.9298, AUC-PR: 0.9777, Accuracy (Test Set): 0.9429\n",
      "    GradientBoosting_10trees - F1-Score: 0.9186, AUC-PR: 0.9722, Accuracy (Test Set): 0.9348\n",
      "    GradientBoosting_20trees - F1-Score: 0.9320, AUC-PR: 0.9788, Accuracy (Test Set): 0.9443\n",
      "    NeuralNetwork_16 - F1-Score: 0.9331, AUC-PR: 0.9591, Accuracy (Test Set): 0.9470\n",
      "\n",
      ">>> Metalearner's results:\n",
      "\n",
      "    Super Learner - F1-Score: 0.9390, AUC-PR: 0.9821, Accuracy: 0.9511\n"
     ]
    }
   ],
   "source": [
    "results_combined = dict()\n",
    "\n",
    "for i, stack in enumerate(configurations_combined):\n",
    "    results_combined[i] = train_evaluate_stack(stack, \"glm\", h2o_train, h2o_val, X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 991,
   "id": "3151effb-9f1e-4597-8c7e-2eeb7739eec2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-a7ff28b8e8ca405f8a1e61214f46da6c.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-a7ff28b8e8ca405f8a1e61214f46da6c.vega-embed details,\n",
       "  #altair-viz-a7ff28b8e8ca405f8a1e61214f46da6c.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-a7ff28b8e8ca405f8a1e61214f46da6c\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-a7ff28b8e8ca405f8a1e61214f46da6c\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-a7ff28b8e8ca405f8a1e61214f46da6c\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.8.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.8.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}, \"axis\": {\"labelLimit\": 1000}}, \"hconcat\": [{\"mark\": {\"type\": \"point\", \"fill\": \"orange\", \"stroke\": \"orange\"}, \"encoding\": {\"x\": {\"field\": \"AUC-PR\", \"scale\": {\"zero\": false}, \"type\": \"quantitative\"}, \"y\": {\"axis\": {\"title\": null}, \"field\": \"Configuration\", \"sort\": \"-x\", \"type\": \"nominal\"}}, \"width\": 120}, {\"mark\": {\"type\": \"point\", \"fill\": \"blue\"}, \"encoding\": {\"x\": {\"field\": \"F1-Score\", \"scale\": {\"zero\": false}, \"type\": \"quantitative\"}, \"y\": {\"axis\": {\"title\": null}, \"field\": \"Configuration\", \"sort\": \"-x\", \"type\": \"nominal\"}}, \"width\": 120}, {\"mark\": {\"type\": \"point\", \"fill\": \"purple\", \"stroke\": \"purple\"}, \"encoding\": {\"x\": {\"field\": \"Accuracy\", \"scale\": {\"zero\": false}, \"type\": \"quantitative\"}, \"y\": {\"axis\": {\"title\": null}, \"field\": \"Configuration\", \"sort\": \"-x\", \"type\": \"nominal\"}}, \"width\": 120}], \"data\": {\"name\": \"data-ae9acb51ecd64ae5eaf25d94b15218ea\"}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.8.0.json\", \"datasets\": {\"data-ae9acb51ecd64ae5eaf25d94b15218ea\": [{\"F1-Score\": 0.9493243243243243, \"AUC-PR\": 0.9796472536259462, \"Accuracy\": 0.9592391304347826, \"Configuration\": \"LR_NB_RF_10_GB_10_GB_50_MLP_10\"}, {\"F1-Score\": 0.9488054607508534, \"AUC-PR\": 0.9811573612098816, \"Accuracy\": 0.9592391304347826, \"Configuration\": \"LR_NB_RF_10_GB_10_GB_50_MLP_16\"}, {\"F1-Score\": 0.9450171821305843, \"AUC-PR\": 0.9808417173079648, \"Accuracy\": 0.9565217391304348, \"Configuration\": \"LR_NB_RF_10_GB_10_GB_20_MLP_10\"}, {\"F1-Score\": 0.9437819420783646, \"AUC-PR\": 0.9808569427201781, \"Accuracy\": 0.9551630434782609, \"Configuration\": \"LR_NB_RF_10_GB_10_GB_20_MLP_16\"}, {\"F1-Score\": 0.9478991596638655, \"AUC-PR\": 0.9844912974055539, \"Accuracy\": 0.9578804347826086, \"Configuration\": \"LR_NB_RF_50_GB_10_GB_50_MLP_10\"}, {\"F1-Score\": 0.9489795918367347, \"AUC-PR\": 0.9840855803459208, \"Accuracy\": 0.9592391304347826, \"Configuration\": \"LR_NB_RF_50_GB_10_GB_50_MLP_16\"}, {\"F1-Score\": 0.9413793103448277, \"AUC-PR\": 0.981303958227791, \"Accuracy\": 0.9538043478260869, \"Configuration\": \"LR_NB_RF_50_GB_10_GB_20_MLP_10\"}, {\"F1-Score\": 0.9439728353140917, \"AUC-PR\": 0.9829112428293072, \"Accuracy\": 0.9551630434782609, \"Configuration\": \"LR_NB_RF_50_GB_10_GB_20_MLP_16\"}, {\"F1-Score\": 0.9491525423728814, \"AUC-PR\": 0.9850684038076638, \"Accuracy\": 0.9592391304347826, \"Configuration\": \"LR_NB_RF_10_RF_50_GB_10_GB_50_MLP_10\"}, {\"F1-Score\": 0.9509306260575295, \"AUC-PR\": 0.9841985437818848, \"Accuracy\": 0.9605978260869565, \"Configuration\": \"LR_NB_RF_10_RF_50_GB_10_GB_50_MLP_16\"}, {\"F1-Score\": 0.9484536082474228, \"AUC-PR\": 0.9819864628340905, \"Accuracy\": 0.9592391304347826, \"Configuration\": \"LR_NB_RF_10_RF_50_GB_10_GB_20_MLP_10\"}, {\"F1-Score\": 0.9389830508474577, \"AUC-PR\": 0.9820602118206814, \"Accuracy\": 0.9510869565217391, \"Configuration\": \"LR_NB_RF_10_RF_50_GB_10_GB_20_MLP_16\"}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.HConcatChart(...)"
      ]
     },
     "execution_count": 991,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = []\n",
    "for conf in configurations_combined:\n",
    "    label = \"_\".join(conf.keys())\n",
    "    label = label.replace(\"LogisticRegression_binomial\", \"LR\")\n",
    "    label = label.replace(\"RandomForest\", \"RF\")\n",
    "    label = label.replace(\"GradientBoosting\", \"GB\")\n",
    "    label = label.replace(\"NeuralNetwork\", \"MLP\")\n",
    "    label = label.replace(\"trees\", \"\")\n",
    "    label = label.replace(\"NaiveBayes\", \"NB\")\n",
    "    labels.append(label)\n",
    "    \n",
    "data_combined = []\n",
    "for label, record in zip(labels, results_combined.values()):\n",
    "    record[\"Configuration\"] = label\n",
    "    data_combined.append(record)\n",
    "data\n",
    "df = pd.DataFrame(data_combined)\n",
    "\n",
    "f1_chart = alt.Chart(df).mark_point(fill=\"blue\").encode(\n",
    "    y=alt.Y('Configuration', sort=\"-x\", axis=alt.Axis(title=None)),\n",
    "    x=alt.X('F1-Score').scale(zero=False)\n",
    ").properties(width=120)\n",
    "\n",
    "aucpr_chart = alt.Chart(df).mark_point(fill=\"orange\", stroke=\"orange\").encode(\n",
    "    y=alt.Y('Configuration', sort=\"-x\", axis=alt.Axis(title=None)),\n",
    "    x=alt.X('AUC-PR').scale(zero=False)\n",
    ").properties(width=120)\n",
    "\n",
    "accuracy_chart = alt.Chart(df).mark_point(fill=\"purple\", stroke=\"purple\").encode(\n",
    "    y=alt.Y('Configuration', sort=\"-x\", axis=alt.Axis(title=None)),\n",
    "    x=alt.X('Accuracy').scale(zero=False)\n",
    ").properties(width=120)\n",
    "(aucpr_chart | f1_chart | accuracy_chart).configure_axis(labelLimit=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e1b02f-327c-423e-a14f-d1da6192fe4f",
   "metadata": {},
   "source": [
    "## Putting the results together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 997,
   "id": "076819c3-3801-4d1b-86eb-8c6956cec41e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-0977385654f44111a6c8923d06f63800.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-0977385654f44111a6c8923d06f63800.vega-embed details,\n",
       "  #altair-viz-0977385654f44111a6c8923d06f63800.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-0977385654f44111a6c8923d06f63800\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-0977385654f44111a6c8923d06f63800\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-0977385654f44111a6c8923d06f63800\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.8.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.8.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}, \"axis\": {\"labelLimit\": 1000}}, \"hconcat\": [{\"mark\": {\"type\": \"point\", \"fill\": \"orange\", \"stroke\": \"orange\"}, \"encoding\": {\"x\": {\"field\": \"AUC-PR\", \"scale\": {\"zero\": false}, \"type\": \"quantitative\"}, \"y\": {\"axis\": {\"title\": null}, \"field\": \"Configuration\", \"sort\": \"-x\", \"type\": \"nominal\"}}, \"width\": 120}, {\"mark\": {\"type\": \"point\", \"fill\": \"blue\"}, \"encoding\": {\"x\": {\"field\": \"F1-Score\", \"scale\": {\"zero\": false}, \"type\": \"quantitative\"}, \"y\": {\"axis\": {\"title\": null}, \"field\": \"Configuration\", \"sort\": \"-x\", \"type\": \"nominal\"}}, \"width\": 120}, {\"mark\": {\"type\": \"point\", \"fill\": \"purple\", \"stroke\": \"purple\"}, \"encoding\": {\"x\": {\"field\": \"Accuracy\", \"scale\": {\"zero\": false}, \"type\": \"quantitative\"}, \"y\": {\"axis\": {\"title\": null}, \"field\": \"Configuration\", \"sort\": \"-x\", \"type\": \"nominal\"}}, \"width\": 120}], \"data\": {\"name\": \"data-e557ea01cca0cd5a7dceba234343e9d6\"}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.8.0.json\", \"datasets\": {\"data-e557ea01cca0cd5a7dceba234343e9d6\": [{\"F1-Score\": 0.9493243243243243, \"AUC-PR\": 0.9807891471838461, \"Accuracy\": 0.9592391304347826, \"Configuration\": \"LR_RF_10_GB_10_GB_50_MLP_10\"}, {\"F1-Score\": 0.9489795918367347, \"AUC-PR\": 0.9810293781438096, \"Accuracy\": 0.9592391304347826, \"Configuration\": \"LR_RF_10_GB_10_GB_50_MLP_16\"}, {\"F1-Score\": 0.9417808219178082, \"AUC-PR\": 0.9812678446905503, \"Accuracy\": 0.9538043478260869, \"Configuration\": \"LR_RF_10_GB_10_GB_20_MLP_10\"}, {\"F1-Score\": 0.9433962264150944, \"AUC-PR\": 0.9824503467366736, \"Accuracy\": 0.9551630434782609, \"Configuration\": \"LR_RF_10_GB_10_GB_20_MLP_16\"}, {\"F1-Score\": 0.9477351916376306, \"AUC-PR\": 0.9847468863859846, \"Accuracy\": 0.9592391304347826, \"Configuration\": \"LR_RF_50_GB_10_GB_50_MLP_10\"}, {\"F1-Score\": 0.952054794520548, \"AUC-PR\": 0.985011430840665, \"Accuracy\": 0.9619565217391305, \"Configuration\": \"LR_RF_50_GB_10_GB_50_MLP_16\"}, {\"F1-Score\": 0.9430051813471502, \"AUC-PR\": 0.9823550010336619, \"Accuracy\": 0.9551630434782609, \"Configuration\": \"LR_RF_50_GB_10_GB_20_MLP_10\"}, {\"F1-Score\": 0.9421768707482994, \"AUC-PR\": 0.9828287833309839, \"Accuracy\": 0.9538043478260869, \"Configuration\": \"LR_RF_50_GB_10_GB_20_MLP_16\"}, {\"F1-Score\": 0.9477234401349074, \"AUC-PR\": 0.9845410530949259, \"Accuracy\": 0.9578804347826086, \"Configuration\": \"LR_RF_10_RF_50_GB_10_GB_50_MLP_10\"}, {\"F1-Score\": 0.9493243243243243, \"AUC-PR\": 0.9854114310320963, \"Accuracy\": 0.9592391304347826, \"Configuration\": \"LR_RF_10_RF_50_GB_10_GB_50_MLP_16\"}, {\"F1-Score\": 0.9401709401709402, \"AUC-PR\": 0.982507791243966, \"Accuracy\": 0.9524456521739131, \"Configuration\": \"LR_RF_10_RF_50_GB_10_GB_20_MLP_10\"}, {\"F1-Score\": 0.945392491467577, \"AUC-PR\": 0.9841989716544953, \"Accuracy\": 0.9565217391304348, \"Configuration\": \"LR_RF_10_RF_50_GB_10_GB_20_MLP_16\"}, {\"F1-Score\": 0.9543147208121828, \"AUC-PR\": 0.9796008120862898, \"Accuracy\": 0.9633152173913043, \"Configuration\": \"NB_RF_10_GB_10_GB_50_MLP_10\"}, {\"F1-Score\": 0.9559322033898305, \"AUC-PR\": 0.9802046029803277, \"Accuracy\": 0.9646739130434783, \"Configuration\": \"NB_RF_10_GB_10_GB_50_MLP_16\"}, {\"F1-Score\": 0.9464594127806563, \"AUC-PR\": 0.9791675231755099, \"Accuracy\": 0.9578804347826086, \"Configuration\": \"NB_RF_10_GB_10_GB_20_MLP_10\"}, {\"F1-Score\": 0.947008547008547, \"AUC-PR\": 0.9826939101589753, \"Accuracy\": 0.9578804347826086, \"Configuration\": \"NB_RF_10_GB_10_GB_20_MLP_16\"}, {\"F1-Score\": 0.9509306260575295, \"AUC-PR\": 0.984458729931136, \"Accuracy\": 0.9605978260869565, \"Configuration\": \"NB_RF_50_GB_10_GB_50_MLP_10\"}, {\"F1-Score\": 0.9541595925297113, \"AUC-PR\": 0.9850719051688422, \"Accuracy\": 0.9633152173913043, \"Configuration\": \"NB_RF_50_GB_10_GB_50_MLP_16\"}, {\"F1-Score\": 0.9452054794520548, \"AUC-PR\": 0.9821924295000077, \"Accuracy\": 0.9565217391304348, \"Configuration\": \"NB_RF_50_GB_10_GB_20_MLP_10\"}, {\"F1-Score\": 0.947008547008547, \"AUC-PR\": 0.9832520047371182, \"Accuracy\": 0.9578804347826086, \"Configuration\": \"NB_RF_50_GB_10_GB_20_MLP_16\"}, {\"F1-Score\": 0.9512605042016807, \"AUC-PR\": 0.9839610608621263, \"Accuracy\": 0.9605978260869565, \"Configuration\": \"NB_RF_10_RF_50_GB_10_GB_50_MLP_10\"}, {\"F1-Score\": 0.9527027027027025, \"AUC-PR\": 0.9848884134215586, \"Accuracy\": 0.9619565217391305, \"Configuration\": \"NB_RF_10_RF_50_GB_10_GB_50_MLP_16\"}, {\"F1-Score\": 0.9466437177280552, \"AUC-PR\": 0.9832295836921638, \"Accuracy\": 0.9578804347826086, \"Configuration\": \"NB_RF_10_RF_50_GB_10_GB_20_MLP_10\"}, {\"F1-Score\": 0.9423728813559321, \"AUC-PR\": 0.9835857983805019, \"Accuracy\": 0.9538043478260869, \"Configuration\": \"NB_RF_10_RF_50_GB_10_GB_20_MLP_16\"}, {\"F1-Score\": 0.9493243243243243, \"AUC-PR\": 0.9796472536259462, \"Accuracy\": 0.9592391304347826, \"Configuration\": \"LR_NB_RF_10_GB_10_GB_50_MLP_10\"}, {\"F1-Score\": 0.9488054607508534, \"AUC-PR\": 0.9811573612098816, \"Accuracy\": 0.9592391304347826, \"Configuration\": \"LR_NB_RF_10_GB_10_GB_50_MLP_16\"}, {\"F1-Score\": 0.9450171821305843, \"AUC-PR\": 0.9808417173079648, \"Accuracy\": 0.9565217391304348, \"Configuration\": \"LR_NB_RF_10_GB_10_GB_20_MLP_10\"}, {\"F1-Score\": 0.9437819420783646, \"AUC-PR\": 0.9808569427201781, \"Accuracy\": 0.9551630434782609, \"Configuration\": \"LR_NB_RF_10_GB_10_GB_20_MLP_16\"}, {\"F1-Score\": 0.9478991596638655, \"AUC-PR\": 0.9844912974055539, \"Accuracy\": 0.9578804347826086, \"Configuration\": \"LR_NB_RF_50_GB_10_GB_50_MLP_10\"}, {\"F1-Score\": 0.9489795918367347, \"AUC-PR\": 0.9840855803459208, \"Accuracy\": 0.9592391304347826, \"Configuration\": \"LR_NB_RF_50_GB_10_GB_50_MLP_16\"}, {\"F1-Score\": 0.9413793103448277, \"AUC-PR\": 0.981303958227791, \"Accuracy\": 0.9538043478260869, \"Configuration\": \"LR_NB_RF_50_GB_10_GB_20_MLP_10\"}, {\"F1-Score\": 0.9439728353140917, \"AUC-PR\": 0.9829112428293072, \"Accuracy\": 0.9551630434782609, \"Configuration\": \"LR_NB_RF_50_GB_10_GB_20_MLP_16\"}, {\"F1-Score\": 0.9491525423728814, \"AUC-PR\": 0.9850684038076638, \"Accuracy\": 0.9592391304347826, \"Configuration\": \"LR_NB_RF_10_RF_50_GB_10_GB_50_MLP_10\"}, {\"F1-Score\": 0.9509306260575295, \"AUC-PR\": 0.9841985437818848, \"Accuracy\": 0.9605978260869565, \"Configuration\": \"LR_NB_RF_10_RF_50_GB_10_GB_50_MLP_16\"}, {\"F1-Score\": 0.9484536082474228, \"AUC-PR\": 0.9819864628340905, \"Accuracy\": 0.9592391304347826, \"Configuration\": \"LR_NB_RF_10_RF_50_GB_10_GB_20_MLP_10\"}, {\"F1-Score\": 0.9389830508474577, \"AUC-PR\": 0.9820602118206814, \"Accuracy\": 0.9510869565217391, \"Configuration\": \"LR_NB_RF_10_RF_50_GB_10_GB_20_MLP_16\"}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.HConcatChart(...)"
      ]
     },
     "execution_count": 997,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data_single + data_combined\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "f1_chart = alt.Chart(df).mark_point(fill=\"blue\").encode(\n",
    "    y=alt.Y('Configuration', sort=\"-x\", axis=alt.Axis(title=None)),\n",
    "    x=alt.X('F1-Score').scale(zero=False)\n",
    ").properties(width=120)\n",
    "\n",
    "aucpr_chart = alt.Chart(df).mark_point(fill=\"orange\", stroke=\"orange\").encode(\n",
    "    y=alt.Y('Configuration', sort=\"-x\", axis=alt.Axis(title=None)),\n",
    "    x=alt.X('AUC-PR').scale(zero=False)\n",
    ").properties(width=120)\n",
    "\n",
    "accuracy_chart = alt.Chart(df).mark_point(fill=\"purple\", stroke=\"purple\").encode(\n",
    "    y=alt.Y('Configuration', sort=\"-x\", axis=alt.Axis(title=None)),\n",
    "    x=alt.X('Accuracy').scale(zero=False)\n",
    ").properties(width=120)\n",
    "(aucpr_chart | f1_chart | accuracy_chart).configure_axis(labelLimit=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e782d1-53a0-4877-b236-8e47e851a1a5",
   "metadata": {},
   "source": [
    "We must note that all of the models perform comparably with the differences being minuscule. Even still we selected a subset of representative examples.\n",
    "From the following results we select:\n",
    "\n",
    "**Naive Bayes + Random Forest 50 trees + Gradient Boosting 10 trees + Gradient Boosting 50 trees + MLP with 16 neurons in 1 hidden layer** as second best performing (yet not the most complex) model according to the AUC-PR metric.\n",
    "\n",
    "**Naive Bayes + Random Forest 10 trees + Gradient Boosting 10 trees + Gradient Boosting 50 trees + MLP with 16 neurons in 1 hidden layer** as the best performing according to the F1 and Accuracy scores.\n",
    "\n",
    "**Logistic Regression + Random Forest 10 trees + Gradient Boosting 10 trees + Gradient Boosting 50 trees + MLP with 16 neurons in 1 hidden layer** as the model well balancing all the metrics.\n",
    "\n",
    "Additionaly we add a **simple stack** without tuned hyperparameters consisting of one version of each learner without MLP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1030,
   "id": "d4b87551-0608-4183-9c69-be433a74cc84",
   "metadata": {},
   "outputs": [],
   "source": [
    "learner01 = {\"NaiveBayes\": H2ONaiveBayesEstimator(nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True),\n",
    "                 \"RandomForest_50trees\": H2ORandomForestEstimator(\n",
    "                        ntrees=50, max_depth=10, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "                    ),\n",
    "                 \"GradientBoosting_10trees\": H2OGradientBoostingEstimator(\n",
    "                        ntrees=10, max_depth=10, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "                        ),\n",
    "                 \"GradientBoosting_50trees\": H2OGradientBoostingEstimator(\n",
    "                        ntrees=50, max_depth=10, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "                        ),\n",
    "             \"NeuralNetwork_16\": H2ODeepLearningEstimator(\n",
    "        hidden=[16], epochs=300, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "    ),\n",
    "}\n",
    "learner02 = {\"NaiveBayes\": H2ONaiveBayesEstimator(nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True),\n",
    "                \"RandomForest_10trees\": H2ORandomForestEstimator(\n",
    "                        ntrees=10, max_depth=10, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "                    ),\n",
    "                \"GradientBoosting_10trees\": H2OGradientBoostingEstimator(\n",
    "                        ntrees=10, max_depth=10, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "                        ),\n",
    "                \"GradientBoosting_50trees\": H2OGradientBoostingEstimator(\n",
    "                        ntrees=50, max_depth=10, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "                        ),\n",
    "             \"NeuralNetwork_16\": H2ODeepLearningEstimator(\n",
    "        hidden=[16], epochs=300, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "    ),\n",
    "}\n",
    "\n",
    "learner03 = {\"LogisticRegression_binomial\": H2OGeneralizedLinearEstimator(\n",
    "                        family=\"binomial\", nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "                    ),\n",
    "                  \"RandomForest_50trees\": H2ORandomForestEstimator(\n",
    "                        ntrees=50, max_depth=10, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "                    ),\n",
    "                 \"GradientBoosting_10trees\": H2OGradientBoostingEstimator(\n",
    "                        ntrees=10, max_depth=10, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "                        ),\n",
    "                 \"GradientBoosting_50trees\": H2OGradientBoostingEstimator(\n",
    "                        ntrees=50, max_depth=10, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "                        ),\n",
    "             \"NeuralNetwork_16\": H2ODeepLearningEstimator(\n",
    "        hidden=[16], epochs=300, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "    ),\n",
    "}\n",
    "\n",
    "\n",
    "learner04 = {\n",
    "    \"LogisticRegression\": H2OGeneralizedLinearEstimator(family=\"binomial\", nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True),\n",
    "    \"RandomForest\": H2ORandomForestEstimator(ntrees=50, max_depth=10, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True),\n",
    "    \"GradientBoosting\": H2OGradientBoostingEstimator(ntrees=50, max_depth=5, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True),\n",
    "    \"NaiveBayes\": H2ONaiveBayesEstimator(nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True)\n",
    "}\n",
    "\n",
    "learners = [learner01, learner02, learner03, learner04]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0b7e8d-6302-4c20-9745-fdbbe6b0dbea",
   "metadata": {},
   "source": [
    "## First we compare the results without any changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1009,
   "id": "5a42449a-49b2-4c72-9ab8-17991b7700f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Training base learners:\n",
      "\n",
      "    Training NaiveBayes with 12-fold cross-validation...\n",
      "naivebayes Model Build progress: |███████████████████████████████████████████████| (done) 100%\n",
      "    Training RandomForest_50trees with 12-fold cross-validation...\n",
      "drf Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting_10trees with 12-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting_50trees with 12-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training NeuralNetwork_16 with 12-fold cross-validation...\n",
      "deeplearning Model Build progress: |█████████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Training super learner:\n",
      "\n",
      "stackedensemble Model Build progress: |██████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Base learners' results:\n",
      "\n",
      "    NaiveBayes - F1-Score: 0.8303, AUC-PR: 0.7914, Accuracy (Test Set): 0.8628\n",
      "    RandomForest_50trees - F1-Score: 0.9298, AUC-PR: 0.9777, Accuracy (Test Set): 0.9429\n",
      "    GradientBoosting_10trees - F1-Score: 0.9186, AUC-PR: 0.9722, Accuracy (Test Set): 0.9348\n",
      "    GradientBoosting_50trees - F1-Score: 0.9472, AUC-PR: 0.9857, Accuracy (Test Set): 0.9579\n",
      "    NeuralNetwork_16 - F1-Score: 0.9317, AUC-PR: 0.9645, Accuracy (Test Set): 0.9457\n",
      "\n",
      ">>> Metalearner's results:\n",
      "\n",
      "    Super Learner - F1-Score: 0.9525, AUC-PR: 0.9847, Accuracy: 0.9620\n",
      "\n",
      ">>> Training base learners:\n",
      "\n",
      "    Training NaiveBayes with 12-fold cross-validation...\n",
      "naivebayes Model Build progress: |███████████████████████████████████████████████| (done) 100%\n",
      "    Training RandomForest_10trees with 12-fold cross-validation...\n",
      "drf Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting_10trees with 12-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting_50trees with 12-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training NeuralNetwork_16 with 12-fold cross-validation...\n",
      "deeplearning Model Build progress: |█████████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Training super learner:\n",
      "\n",
      "stackedensemble Model Build progress: |██████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Base learners' results:\n",
      "\n",
      "    NaiveBayes - F1-Score: 0.8303, AUC-PR: 0.7914, Accuracy (Test Set): 0.8628\n",
      "    RandomForest_10trees - F1-Score: 0.9310, AUC-PR: 0.9714, Accuracy (Test Set): 0.9457\n",
      "    GradientBoosting_10trees - F1-Score: 0.9186, AUC-PR: 0.9722, Accuracy (Test Set): 0.9348\n",
      "    GradientBoosting_50trees - F1-Score: 0.9472, AUC-PR: 0.9857, Accuracy (Test Set): 0.9579\n",
      "    NeuralNetwork_16 - F1-Score: 0.9313, AUC-PR: 0.9661, Accuracy (Test Set): 0.9443\n",
      "\n",
      ">>> Metalearner's results:\n",
      "\n",
      "    Super Learner - F1-Score: 0.9559, AUC-PR: 0.9807, Accuracy: 0.9647\n",
      "\n",
      ">>> Training base learners:\n",
      "\n",
      "    Training LogisticRegression_binomial with 12-fold cross-validation...\n",
      "glm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training RandomForest_50trees with 12-fold cross-validation...\n",
      "drf Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting_10trees with 12-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting_50trees with 12-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training NeuralNetwork_16 with 12-fold cross-validation...\n",
      "deeplearning Model Build progress: |█████████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Training super learner:\n",
      "\n",
      "stackedensemble Model Build progress: |██████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Base learners' results:\n",
      "\n",
      "    LogisticRegression_binomial - F1-Score: 0.9160, AUC-PR: 0.9554, Accuracy (Test Set): 0.9334\n",
      "    RandomForest_50trees - F1-Score: 0.9298, AUC-PR: 0.9777, Accuracy (Test Set): 0.9429\n",
      "    GradientBoosting_10trees - F1-Score: 0.9186, AUC-PR: 0.9722, Accuracy (Test Set): 0.9348\n",
      "    GradientBoosting_50trees - F1-Score: 0.9472, AUC-PR: 0.9857, Accuracy (Test Set): 0.9579\n",
      "    NeuralNetwork_16 - F1-Score: 0.9220, AUC-PR: 0.9654, Accuracy (Test Set): 0.9375\n",
      "\n",
      ">>> Metalearner's results:\n",
      "\n",
      "    Super Learner - F1-Score: 0.9481, AUC-PR: 0.9851, Accuracy: 0.9579\n",
      "\n",
      ">>> Training base learners:\n",
      "\n",
      "    Training LogisticRegression with 12-fold cross-validation...\n",
      "glm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training RandomForest with 12-fold cross-validation...\n",
      "drf Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting with 12-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training NaiveBayes with 12-fold cross-validation...\n",
      "naivebayes Model Build progress: |███████████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Training super learner:\n",
      "\n",
      "stackedensemble Model Build progress: |██████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Base learners' results:\n",
      "\n",
      "    LogisticRegression - F1-Score: 0.9160, AUC-PR: 0.9554, Accuracy (Test Set): 0.9334\n",
      "    RandomForest - F1-Score: 0.9298, AUC-PR: 0.9777, Accuracy (Test Set): 0.9429\n",
      "    GradientBoosting - F1-Score: 0.9442, AUC-PR: 0.9791, Accuracy (Test Set): 0.9552\n",
      "    NaiveBayes - F1-Score: 0.8303, AUC-PR: 0.7914, Accuracy (Test Set): 0.8628\n",
      "\n",
      ">>> Metalearner's results:\n",
      "\n",
      "    Super Learner - F1-Score: 0.9410, AUC-PR: 0.9809, Accuracy: 0.9524\n"
     ]
    }
   ],
   "source": [
    "results_final4 = dict()\n",
    "\n",
    "for i, stack in enumerate(learners):\n",
    "    results_final4[i] = train_evaluate_stack(stack, \"glm\", h2o_train, h2o_val, X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1038,
   "id": "914a718b-756f-4fe2-8d1c-82e08a8291e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-eacff15882124dd48a26845c7432331c.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-eacff15882124dd48a26845c7432331c.vega-embed details,\n",
       "  #altair-viz-eacff15882124dd48a26845c7432331c.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-eacff15882124dd48a26845c7432331c\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-eacff15882124dd48a26845c7432331c\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-eacff15882124dd48a26845c7432331c\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.8.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.8.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}, \"axis\": {\"labelLimit\": 1000}}, \"hconcat\": [{\"mark\": {\"type\": \"point\", \"fill\": \"orange\", \"stroke\": \"orange\"}, \"encoding\": {\"x\": {\"field\": \"AUC-PR\", \"scale\": {\"zero\": false}, \"type\": \"quantitative\"}, \"y\": {\"axis\": {\"title\": null}, \"field\": \"Configuration\", \"sort\": \"-x\", \"type\": \"nominal\"}}, \"width\": 120}, {\"mark\": {\"type\": \"point\", \"fill\": \"blue\"}, \"encoding\": {\"x\": {\"field\": \"F1-Score\", \"scale\": {\"zero\": false}, \"type\": \"quantitative\"}, \"y\": {\"axis\": {\"title\": null}, \"field\": \"Configuration\", \"sort\": \"-x\", \"type\": \"nominal\"}}, \"width\": 120}, {\"mark\": {\"type\": \"point\", \"fill\": \"purple\", \"stroke\": \"purple\"}, \"encoding\": {\"x\": {\"field\": \"Accuracy\", \"scale\": {\"zero\": false}, \"type\": \"quantitative\"}, \"y\": {\"axis\": {\"title\": null}, \"field\": \"Configuration\", \"sort\": \"-x\", \"type\": \"nominal\"}}, \"width\": 120}], \"data\": {\"name\": \"data-97536d9e191e5bb4401d13384137b331\"}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.8.0.json\", \"datasets\": {\"data-97536d9e191e5bb4401d13384137b331\": [{\"F1-Score\": 0.9525423728813558, \"AUC-PR\": 0.9847201776295894, \"Accuracy\": 0.9619565217391305, \"Configuration\": \"NB_RF_50_GB_10_GB_50_MLP_16\"}, {\"F1-Score\": 0.9559322033898305, \"AUC-PR\": 0.9807193355525295, \"Accuracy\": 0.9646739130434783, \"Configuration\": \"NB_RF_10_GB_10_GB_50_MLP_16\"}, {\"F1-Score\": 0.948073701842546, \"AUC-PR\": 0.9851253716886375, \"Accuracy\": 0.9578804347826086, \"Configuration\": \"LR_RF_50_GB_10_GB_50_MLP_16\"}, {\"F1-Score\": 0.9409780775716695, \"AUC-PR\": 0.9808937998136349, \"Accuracy\": 0.9524456521739131, \"Configuration\": \"LR_RF_GB_NB\"}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.HConcatChart(...)"
      ]
     },
     "execution_count": 1038,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = []\n",
    "for conf in learners:\n",
    "    label = \"_\".join(conf.keys())\n",
    "    label = label.replace(\"LogisticRegression_binomial\", \"LR\")\n",
    "    label = label.replace(\"LogisticRegression\", \"LR\")\n",
    "    label = label.replace(\"RandomForest\", \"RF\")\n",
    "    label = label.replace(\"GradientBoosting\", \"GB\")\n",
    "    label = label.replace(\"NeuralNetwork\", \"MLP\")\n",
    "    label = label.replace(\"trees\", \"\")\n",
    "    label = label.replace(\"NaiveBayes\", \"NB\")\n",
    "    labels.append(label)\n",
    "    \n",
    "data_final4 = []\n",
    "for label, record in zip(labels, results_final4.values()):\n",
    "    record[\"Configuration\"] = label\n",
    "    data_final4.append(record)\n",
    "data\n",
    "df = pd.DataFrame(data_final4)\n",
    "\n",
    "f1_chart = alt.Chart(df).mark_point(fill=\"blue\").encode(\n",
    "    y=alt.Y('Configuration', sort=\"-x\", axis=alt.Axis(title=None)),\n",
    "    x=alt.X('F1-Score').scale(zero=False)\n",
    ").properties(width=120)\n",
    "\n",
    "aucpr_chart = alt.Chart(df).mark_point(fill=\"orange\", stroke=\"orange\").encode(\n",
    "    y=alt.Y('Configuration', sort=\"-x\", axis=alt.Axis(title=None)),\n",
    "    x=alt.X('AUC-PR').scale(zero=False)\n",
    ").properties(width=120)\n",
    "\n",
    "accuracy_chart = alt.Chart(df).mark_point(fill=\"purple\", stroke=\"purple\").encode(\n",
    "    y=alt.Y('Configuration', sort=\"-x\", axis=alt.Axis(title=None)),\n",
    "    x=alt.X('Accuracy').scale(zero=False)\n",
    ").properties(width=120)\n",
    "(aucpr_chart | f1_chart | accuracy_chart).configure_axis(labelLimit=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8668566c-4152-4b11-bc3a-b233714e5995",
   "metadata": {},
   "source": [
    "## Second we try deeplearning as a choice of classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1018,
   "id": "d9c4b911-318a-4b7d-9e18-3e01a29bdd7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Training base learners:\n",
      "\n",
      "    Training NaiveBayes with 12-fold cross-validation...\n",
      "naivebayes Model Build progress: |███████████████████████████████████████████████| (done) 100%\n",
      "    Training RandomForest_50trees with 12-fold cross-validation...\n",
      "drf Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting_10trees with 12-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting_50trees with 12-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training NeuralNetwork_16 with 12-fold cross-validation...\n",
      "deeplearning Model Build progress: |█████████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Training super learner:\n",
      "\n",
      "stackedensemble Model Build progress: |██████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Base learners' results:\n",
      "\n",
      "    NaiveBayes - F1-Score: 0.8303, AUC-PR: 0.7914, Accuracy (Test Set): 0.8628\n",
      "    RandomForest_50trees - F1-Score: 0.9298, AUC-PR: 0.9777, Accuracy (Test Set): 0.9429\n",
      "    GradientBoosting_10trees - F1-Score: 0.9186, AUC-PR: 0.9722, Accuracy (Test Set): 0.9348\n",
      "    GradientBoosting_50trees - F1-Score: 0.9472, AUC-PR: 0.9857, Accuracy (Test Set): 0.9579\n",
      "    NeuralNetwork_16 - F1-Score: 0.9313, AUC-PR: 0.9712, Accuracy (Test Set): 0.9457\n",
      "\n",
      ">>> Metalearner's results:\n",
      "\n",
      "    Super Learner - F1-Score: 0.9501, AUC-PR: 0.9848, Accuracy: 0.9606\n",
      "\n",
      ">>> Training base learners:\n",
      "\n",
      "    Training NaiveBayes with 12-fold cross-validation...\n",
      "naivebayes Model Build progress: |███████████████████████████████████████████████| (done) 100%\n",
      "    Training RandomForest_10trees with 12-fold cross-validation...\n",
      "drf Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting_10trees with 12-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting_50trees with 12-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training NeuralNetwork_16 with 12-fold cross-validation...\n",
      "deeplearning Model Build progress: |█████████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Training super learner:\n",
      "\n",
      "stackedensemble Model Build progress: |██████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Base learners' results:\n",
      "\n",
      "    NaiveBayes - F1-Score: 0.8303, AUC-PR: 0.7914, Accuracy (Test Set): 0.8628\n",
      "    RandomForest_10trees - F1-Score: 0.9310, AUC-PR: 0.9714, Accuracy (Test Set): 0.9457\n",
      "    GradientBoosting_10trees - F1-Score: 0.9186, AUC-PR: 0.9722, Accuracy (Test Set): 0.9348\n",
      "    GradientBoosting_50trees - F1-Score: 0.9472, AUC-PR: 0.9857, Accuracy (Test Set): 0.9579\n",
      "    NeuralNetwork_16 - F1-Score: 0.9322, AUC-PR: 0.9664, Accuracy (Test Set): 0.9457\n",
      "\n",
      ">>> Metalearner's results:\n",
      "\n",
      "    Super Learner - F1-Score: 0.9490, AUC-PR: 0.9830, Accuracy: 0.9592\n",
      "\n",
      ">>> Training base learners:\n",
      "\n",
      "    Training LogisticRegression_binomial with 12-fold cross-validation...\n",
      "glm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training RandomForest_50trees with 12-fold cross-validation...\n",
      "drf Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting_10trees with 12-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting_50trees with 12-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training NeuralNetwork_16 with 12-fold cross-validation...\n",
      "deeplearning Model Build progress: |█████████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Training super learner:\n",
      "\n",
      "stackedensemble Model Build progress: |██████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Base learners' results:\n",
      "\n",
      "    LogisticRegression_binomial - F1-Score: 0.9160, AUC-PR: 0.9554, Accuracy (Test Set): 0.9334\n",
      "    RandomForest_50trees - F1-Score: 0.9298, AUC-PR: 0.9777, Accuracy (Test Set): 0.9429\n",
      "    GradientBoosting_10trees - F1-Score: 0.9186, AUC-PR: 0.9722, Accuracy (Test Set): 0.9348\n",
      "    GradientBoosting_50trees - F1-Score: 0.9472, AUC-PR: 0.9857, Accuracy (Test Set): 0.9579\n",
      "    NeuralNetwork_16 - F1-Score: 0.9349, AUC-PR: 0.9706, Accuracy (Test Set): 0.9484\n",
      "\n",
      ">>> Metalearner's results:\n",
      "\n",
      "    Super Learner - F1-Score: 0.9504, AUC-PR: 0.9857, Accuracy: 0.9606\n",
      "\n",
      ">>> Training base learners:\n",
      "\n",
      "    Training LogisticRegression with 12-fold cross-validation...\n",
      "glm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training RandomForest with 12-fold cross-validation...\n",
      "drf Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting with 12-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training NaiveBayes with 12-fold cross-validation...\n",
      "naivebayes Model Build progress: |███████████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Training super learner:\n",
      "\n",
      "stackedensemble Model Build progress: |██████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Base learners' results:\n",
      "\n",
      "    LogisticRegression - F1-Score: 0.9160, AUC-PR: 0.9554, Accuracy (Test Set): 0.9334\n",
      "    RandomForest - F1-Score: 0.9298, AUC-PR: 0.9777, Accuracy (Test Set): 0.9429\n",
      "    GradientBoosting - F1-Score: 0.9442, AUC-PR: 0.9791, Accuracy (Test Set): 0.9552\n",
      "    NaiveBayes - F1-Score: 0.8303, AUC-PR: 0.7914, Accuracy (Test Set): 0.8628\n",
      "\n",
      ">>> Metalearner's results:\n",
      "\n",
      "    Super Learner - F1-Score: 0.9440, AUC-PR: 0.9815, Accuracy: 0.9552\n"
     ]
    }
   ],
   "source": [
    "results_final4_dl = dict()\n",
    "\n",
    "for i, stack in enumerate(learners):\n",
    "    results_final4_dl[i] = train_evaluate_stack(stack, \"deeplearning\", h2o_train, h2o_val, X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1040,
   "id": "8abee8db-367e-4013-898a-ddf6c6052d05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-e753893ddaab43429c8c4bd8565fe886.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-e753893ddaab43429c8c4bd8565fe886.vega-embed details,\n",
       "  #altair-viz-e753893ddaab43429c8c4bd8565fe886.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-e753893ddaab43429c8c4bd8565fe886\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-e753893ddaab43429c8c4bd8565fe886\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-e753893ddaab43429c8c4bd8565fe886\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.8.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.8.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}, \"axis\": {\"labelLimit\": 1000}}, \"hconcat\": [{\"mark\": {\"type\": \"point\", \"fill\": \"orange\", \"stroke\": \"orange\"}, \"encoding\": {\"x\": {\"field\": \"AUC-PR\", \"scale\": {\"zero\": false}, \"type\": \"quantitative\"}, \"y\": {\"axis\": {\"title\": null}, \"field\": \"Configuration\", \"sort\": \"-x\", \"type\": \"nominal\"}}, \"width\": 120}, {\"mark\": {\"type\": \"point\", \"fill\": \"blue\"}, \"encoding\": {\"x\": {\"field\": \"F1-Score\", \"scale\": {\"zero\": false}, \"type\": \"quantitative\"}, \"y\": {\"axis\": {\"title\": null}, \"field\": \"Configuration\", \"sort\": \"-x\", \"type\": \"nominal\"}}, \"width\": 120}, {\"mark\": {\"type\": \"point\", \"fill\": \"purple\", \"stroke\": \"purple\"}, \"encoding\": {\"x\": {\"field\": \"Accuracy\", \"scale\": {\"zero\": false}, \"type\": \"quantitative\"}, \"y\": {\"axis\": {\"title\": null}, \"field\": \"Configuration\", \"sort\": \"-x\", \"type\": \"nominal\"}}, \"width\": 120}], \"data\": {\"name\": \"data-25688e2e0334dfb92af007e2685ebe2d\"}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.8.0.json\", \"datasets\": {\"data-25688e2e0334dfb92af007e2685ebe2d\": [{\"F1-Score\": 0.9500860585197934, \"AUC-PR\": 0.9847906972117936, \"Accuracy\": 0.9605978260869565, \"Configuration\": \"dl_NB_RF_50_GB_10_GB_50_MLP_16\"}, {\"F1-Score\": 0.9489795918367347, \"AUC-PR\": 0.982983427313053, \"Accuracy\": 0.9592391304347826, \"Configuration\": \"dl_NB_RF_10_GB_10_GB_50_MLP_16\"}, {\"F1-Score\": 0.9504273504273505, \"AUC-PR\": 0.985728232996546, \"Accuracy\": 0.9605978260869565, \"Configuration\": \"dl_LR_RF_50_GB_10_GB_50_MLP_16\"}, {\"F1-Score\": 0.9439728353140917, \"AUC-PR\": 0.9814504190814206, \"Accuracy\": 0.9551630434782609, \"Configuration\": \"dl_LR_RF_GB_NB\"}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.HConcatChart(...)"
      ]
     },
     "execution_count": 1040,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = []\n",
    "for conf in learners:\n",
    "    label = \"_\".join(conf.keys())\n",
    "    label = label.replace(\"LogisticRegression_binomial\", \"LR\")\n",
    "    label = label.replace(\"LogisticRegression\", \"LR\")\n",
    "    label = label.replace(\"RandomForest\", \"RF\")\n",
    "    label = label.replace(\"GradientBoosting\", \"GB\")\n",
    "    label = label.replace(\"NeuralNetwork\", \"MLP\")\n",
    "    label = label.replace(\"trees\", \"\")\n",
    "    label = label.replace(\"NaiveBayes\", \"NB\")\n",
    "    labels.append(\"dl_\" + label)\n",
    "    \n",
    "data_final4_dl = []\n",
    "for label, record in zip(labels, results_final4_dl.values()):\n",
    "    record[\"Configuration\"] = label\n",
    "    data_final4_dl.append(record)\n",
    "data\n",
    "df = pd.DataFrame(data_final4_dl)\n",
    "\n",
    "f1_chart = alt.Chart(df).mark_point(fill=\"blue\").encode(\n",
    "    y=alt.Y('Configuration', sort=\"-x\", axis=alt.Axis(title=None)),\n",
    "    x=alt.X('F1-Score').scale(zero=False)\n",
    ").properties(width=120)\n",
    "\n",
    "aucpr_chart = alt.Chart(df).mark_point(fill=\"orange\", stroke=\"orange\").encode(\n",
    "    y=alt.Y('Configuration', sort=\"-x\", axis=alt.Axis(title=None)),\n",
    "    x=alt.X('AUC-PR').scale(zero=False)\n",
    ").properties(width=120)\n",
    "\n",
    "accuracy_chart = alt.Chart(df).mark_point(fill=\"purple\", stroke=\"purple\").encode(\n",
    "    y=alt.Y('Configuration', sort=\"-x\", axis=alt.Axis(title=None)),\n",
    "    x=alt.X('Accuracy').scale(zero=False)\n",
    ").properties(width=120)\n",
    "(aucpr_chart | f1_chart | accuracy_chart).configure_axis(labelLimit=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c0cb27f-fcab-4bd5-8e6f-1ac8a2b0dc85",
   "metadata": {},
   "source": [
    "### Additionally we could try applying option of balancing classes and stratified fold assignment since we have inbalanced dataset\n",
    "However due to the results we have already obtained we don't apply those."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ecbba9-a330-4493-9289-c0163eb824fd",
   "metadata": {},
   "source": [
    "## Final results comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1050,
   "id": "56feb92c-3d84-4f1f-9d82-5a8981155147",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_final4 + data_final4_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1052,
   "id": "e1751cde-f2e3-4549-8fc5-375290d2cbd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-3a63d30bfce7465da6fcba28ebddff2d.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-3a63d30bfce7465da6fcba28ebddff2d.vega-embed details,\n",
       "  #altair-viz-3a63d30bfce7465da6fcba28ebddff2d.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-3a63d30bfce7465da6fcba28ebddff2d\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-3a63d30bfce7465da6fcba28ebddff2d\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-3a63d30bfce7465da6fcba28ebddff2d\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.8.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.8.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}, \"axis\": {\"labelLimit\": 1000}}, \"hconcat\": [{\"mark\": {\"type\": \"point\", \"fill\": \"orange\", \"stroke\": \"orange\"}, \"encoding\": {\"x\": {\"field\": \"AUC-PR\", \"scale\": {\"zero\": false}, \"type\": \"quantitative\"}, \"y\": {\"axis\": {\"title\": null}, \"field\": \"Configuration\", \"sort\": \"-x\", \"type\": \"nominal\"}}, \"width\": 120}, {\"mark\": {\"type\": \"point\", \"fill\": \"blue\"}, \"encoding\": {\"x\": {\"field\": \"F1-Score\", \"scale\": {\"zero\": false}, \"type\": \"quantitative\"}, \"y\": {\"axis\": {\"title\": null}, \"field\": \"Configuration\", \"sort\": \"-x\", \"type\": \"nominal\"}}, \"width\": 120}, {\"mark\": {\"type\": \"point\", \"fill\": \"purple\", \"stroke\": \"purple\"}, \"encoding\": {\"x\": {\"field\": \"Accuracy\", \"scale\": {\"zero\": false}, \"type\": \"quantitative\"}, \"y\": {\"axis\": {\"title\": null}, \"field\": \"Configuration\", \"sort\": \"-x\", \"type\": \"nominal\"}}, \"width\": 120}], \"data\": {\"name\": \"data-8b38aab0cd8cf96c585c88d50dda7777\"}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.8.0.json\", \"datasets\": {\"data-8b38aab0cd8cf96c585c88d50dda7777\": [{\"F1-Score\": 0.9525423728813558, \"AUC-PR\": 0.9847201776295894, \"Accuracy\": 0.9619565217391305, \"Configuration\": \"NB_RF_50_GB_10_GB_50_MLP_16\"}, {\"F1-Score\": 0.9559322033898305, \"AUC-PR\": 0.9807193355525295, \"Accuracy\": 0.9646739130434783, \"Configuration\": \"NB_RF_10_GB_10_GB_50_MLP_16\"}, {\"F1-Score\": 0.948073701842546, \"AUC-PR\": 0.9851253716886375, \"Accuracy\": 0.9578804347826086, \"Configuration\": \"LR_RF_50_GB_10_GB_50_MLP_16\"}, {\"F1-Score\": 0.9409780775716695, \"AUC-PR\": 0.9808937998136349, \"Accuracy\": 0.9524456521739131, \"Configuration\": \"LR_RF_GB_NB\"}, {\"F1-Score\": 0.9500860585197934, \"AUC-PR\": 0.9847906972117936, \"Accuracy\": 0.9605978260869565, \"Configuration\": \"dl_NB_RF_50_GB_10_GB_50_MLP_16\"}, {\"F1-Score\": 0.9489795918367347, \"AUC-PR\": 0.982983427313053, \"Accuracy\": 0.9592391304347826, \"Configuration\": \"dl_NB_RF_10_GB_10_GB_50_MLP_16\"}, {\"F1-Score\": 0.9504273504273505, \"AUC-PR\": 0.985728232996546, \"Accuracy\": 0.9605978260869565, \"Configuration\": \"dl_LR_RF_50_GB_10_GB_50_MLP_16\"}, {\"F1-Score\": 0.9439728353140917, \"AUC-PR\": 0.9814504190814206, \"Accuracy\": 0.9551630434782609, \"Configuration\": \"dl_LR_RF_GB_NB\"}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.HConcatChart(...)"
      ]
     },
     "execution_count": 1052,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data)\n",
    "\n",
    "f1_chart = alt.Chart(df).mark_point(fill=\"blue\").encode(\n",
    "    y=alt.Y('Configuration', sort=\"-x\", axis=alt.Axis(title=None)),\n",
    "    x=alt.X('F1-Score').scale(zero=False)\n",
    ").properties(width=120)\n",
    "\n",
    "aucpr_chart = alt.Chart(df).mark_point(fill=\"orange\", stroke=\"orange\").encode(\n",
    "    y=alt.Y('Configuration', sort=\"-x\", axis=alt.Axis(title=None)),\n",
    "    x=alt.X('AUC-PR').scale(zero=False)\n",
    ").properties(width=120)\n",
    "\n",
    "accuracy_chart = alt.Chart(df).mark_point(fill=\"purple\", stroke=\"purple\").encode(\n",
    "    y=alt.Y('Configuration', sort=\"-x\", axis=alt.Axis(title=None)),\n",
    "    x=alt.X('Accuracy').scale(zero=False)\n",
    ").properties(width=120)\n",
    "(aucpr_chart | f1_chart | accuracy_chart).configure_axis(labelLimit=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f3c60b-1590-45c9-91f1-505870a75c1c",
   "metadata": {},
   "source": [
    "Even though deeplearning metalearner performs the best on AUC-PR we choose the model **Naive Bayes + Random Forest 50 trees + Gradient Boosting 10 trees + Gradient Boosting 50 trees + MLP with 1 hidden layer with 16 neurons** as the model which best balances all metrics but primarily performs among the best on AUC-PR and F1-Score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1061,
   "id": "8bc653af-cda7-43dd-a8cf-bf18c691fc13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Training base learners:\n",
      "\n",
      "    Training NaiveBayes with 12-fold cross-validation...\n",
      "naivebayes Model Build progress: |███████████████████████████████████████████████| (done) 100%\n",
      "    Training RandomForest_50trees with 12-fold cross-validation...\n",
      "drf Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting_10trees with 12-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting_50trees with 12-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training NeuralNetwork_16 with 12-fold cross-validation...\n",
      "deeplearning Model Build progress: |█████████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Training super learner:\n",
      "\n",
      "stackedensemble Model Build progress: |██████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Base learners' results:\n",
      "\n",
      "    NaiveBayes - F1-Score: 0.8218, AUC-PR: 0.8056, Accuracy (Test Set): 0.8512\n",
      "    RandomForest_50trees - F1-Score: 0.9352, AUC-PR: 0.9788, Accuracy (Test Set): 0.9457\n",
      "    GradientBoosting_10trees - F1-Score: 0.9172, AUC-PR: 0.9749, Accuracy (Test Set): 0.9338\n",
      "    GradientBoosting_50trees - F1-Score: 0.9487, AUC-PR: 0.9871, Accuracy (Test Set): 0.9566\n",
      "    NeuralNetwork_16 - F1-Score: 0.9316, AUC-PR: 0.9656, Accuracy (Test Set): 0.9425\n",
      "\n",
      ">>> Metalearner's results:\n",
      "\n",
      "    Super Learner - F1-Score: 0.9537, AUC-PR: 0.9749, Accuracy: 0.9598\n"
     ]
    }
   ],
   "source": [
    "best_model = train_evaluate_stack(learner01, \"glm\", h2o_train, h2o_test, X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b77cf3-8b68-481f-b46a-b22e83845a8c",
   "metadata": {},
   "source": [
    "## The estimation of generalization error on the final (until now unseen) test data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a057bb-fc9a-4b23-873d-4ce77405ff25",
   "metadata": {},
   "source": [
    "#### **AUC-PR:** 0.9749\n",
    "#### **F1-Score:** 0.9537\n",
    "#### **Accuracy:** 0.9598\n",
    "\n",
    "Results are comparable with what we observed on the validation set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79737b2b-08ee-4814-862b-0df2aff527e7",
   "metadata": {},
   "source": [
    "## Conclusions & Observations\n",
    "\n",
    "* We note that as expected choice of a single simple model LR or NB performed significantly worsed compared to any other stack.\n",
    "\n",
    "* Stacks in general surpassed the results of the individual methods although the change was not too big so the original base learners probably manage to \n",
    "capture the relationships in the data well enough.\n",
    "\n",
    "* In the AUC-PR and F1-Score metrix which we have selected to account for inbalanced classes, most of the stacks perform very pretty similarly on AUC-PR with highest differences present in F1-Score results. In terms of accuracy they also varied minimally.\n",
    "\n",
    "* Even though we have inbalanced dataset accuracy is not significantly worse than the other metrics that take in account the inbalance.\n",
    "\n",
    "* High AUC-PR should signify that method manages very well the classification of the minority class - in this case spam.\n",
    "\n",
    "* High F1 also means it balanced pretty well precision and recall although in real life false positives and false negatives might not have similar consequences and we might focus more on rather not detecting good email as spam.\n",
    "\n",
    "* Suprisingly the inclusion of both simple methods (NB and LR) didn't significantly improve the results or perform in general better than the single simple method combinations.\n",
    "\n",
    "* The best stack combines Random Forest and Gradient Boosting, both with 50 trees which are both the default configurations that we would select if using these methods in separate.\n",
    "\n",
    "* Depth unbounded tree based ensembles performed worse in general compared to the ones bounded with max tree depth 10.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
