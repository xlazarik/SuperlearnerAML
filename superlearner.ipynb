{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e895586-1274-4b13-a031-4c799015d1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -f http://h2o-release.s3.amazonaws.com/h2o/latest_stable_Py.html h2o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ebe00c0-b3d2-4ca5-aa70-dde4ad6ebcef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "668aebb2-473c-4835-a538-b773ff24348c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321..... not found.\n",
      "Attempting to start a local H2O server...\n",
      "; OpenJDK 64-Bit Server VM JBR-11.0.13.7-1751.21-jcef (build 11.0.13+7-b1751.21, mixed mode)\n",
      "  Starting server from D:\\Archivos de programa\\Anaconda3\\envs\\Master_1\\Lib\\site-packages\\h2o\\backend\\bin\\h2o.jar\n",
      "  Ice root: C:\\Users\\david\\AppData\\Local\\Temp\\tmp73tmtmmz\n",
      "  JVM stdout: C:\\Users\\david\\AppData\\Local\\Temp\\tmp73tmtmmz\\h2o_david_started_from_python.out\n",
      "  JVM stderr: C:\\Users\\david\\AppData\\Local\\Temp\\tmp73tmtmmz\\h2o_david_started_from_python.err\n",
      "  Server is running at http://127.0.0.1:54321\n",
      "Connecting to H2O server at http://127.0.0.1:54321 ... successful.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "\n",
       "#h2o-table-1.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-1 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-1 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-1 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-1 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-1 .h2o-table th,\n",
       "#h2o-table-1 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-1 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-1\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption></caption>\n",
       "    <thead></thead>\n",
       "    <tbody><tr><td>H2O_cluster_uptime:</td>\n",
       "<td>04 secs</td></tr>\n",
       "<tr><td>H2O_cluster_timezone:</td>\n",
       "<td>Europe/Paris</td></tr>\n",
       "<tr><td>H2O_data_parsing_timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O_cluster_version:</td>\n",
       "<td>3.46.0.6</td></tr>\n",
       "<tr><td>H2O_cluster_version_age:</td>\n",
       "<td>2 months and 4 days</td></tr>\n",
       "<tr><td>H2O_cluster_name:</td>\n",
       "<td>H2O_from_python_david_9k1xw8</td></tr>\n",
       "<tr><td>H2O_cluster_total_nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O_cluster_free_memory:</td>\n",
       "<td>3.979 Gb</td></tr>\n",
       "<tr><td>H2O_cluster_total_cores:</td>\n",
       "<td>8</td></tr>\n",
       "<tr><td>H2O_cluster_allowed_cores:</td>\n",
       "<td>8</td></tr>\n",
       "<tr><td>H2O_cluster_status:</td>\n",
       "<td>locked, healthy</td></tr>\n",
       "<tr><td>H2O_connection_url:</td>\n",
       "<td>http://127.0.0.1:54321</td></tr>\n",
       "<tr><td>H2O_connection_proxy:</td>\n",
       "<td>{\"http\": null, \"https\": null}</td></tr>\n",
       "<tr><td>H2O_internal_security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>Python_version:</td>\n",
       "<td>3.10.13 final</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n"
      ],
      "text/plain": [
       "--------------------------  -----------------------------\n",
       "H2O_cluster_uptime:         04 secs\n",
       "H2O_cluster_timezone:       Europe/Paris\n",
       "H2O_data_parsing_timezone:  UTC\n",
       "H2O_cluster_version:        3.46.0.6\n",
       "H2O_cluster_version_age:    2 months and 4 days\n",
       "H2O_cluster_name:           H2O_from_python_david_9k1xw8\n",
       "H2O_cluster_total_nodes:    1\n",
       "H2O_cluster_free_memory:    3.979 Gb\n",
       "H2O_cluster_total_cores:    8\n",
       "H2O_cluster_allowed_cores:  8\n",
       "H2O_cluster_status:         locked, healthy\n",
       "H2O_connection_url:         http://127.0.0.1:54321\n",
       "H2O_connection_proxy:       {\"http\": null, \"https\": null}\n",
       "H2O_internal_security:      False\n",
       "Python_version:             3.10.13 final\n",
       "--------------------------  -----------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import h2o\n",
    "from h2o.estimators import (\n",
    "    H2OGeneralizedLinearEstimator, \n",
    "    H2ORandomForestEstimator, \n",
    "    H2OGradientBoostingEstimator, \n",
    "    H2ONaiveBayesEstimator,\n",
    "    H2OStackedEnsembleEstimator,\n",
    "    H2ODeepLearningEstimator\n",
    "\n",
    ")\n",
    "from h2o.frame import H2OFrame\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "h2o.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f58eaa-76e0-4f1f-9a27-1f226a47557c",
   "metadata": {},
   "source": [
    "### GLOBAL PRESETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 696,
   "id": "e7bc9feb-07d7-4b1e-8378-4d9f765c0b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "TEST_SIZE = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f58317b-ee47-4476-90cb-9440f0a63c2d",
   "metadata": {},
   "source": [
    "Throughout the project we reference many times the paper: **Practical considerations for specifying a super learner**\n",
    "https://arxiv.org/pdf/2204.06139"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a6973e-a3e7-4b1b-bcda-541feb7a8d63",
   "metadata": {},
   "source": [
    "### DATA LOADING AND PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d8d9852-ce43-4b48-b1aa-f6701bf176bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "63c2ad27-6da8-404c-9f2c-e4d7cf54b768",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vladi\\anaconda3\\Lib\\site-packages\\sklearn\\datasets\\_openml.py:968: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_freq_make</th>\n",
       "      <th>word_freq_address</th>\n",
       "      <th>word_freq_all</th>\n",
       "      <th>word_freq_3d</th>\n",
       "      <th>word_freq_our</th>\n",
       "      <th>word_freq_over</th>\n",
       "      <th>word_freq_remove</th>\n",
       "      <th>word_freq_internet</th>\n",
       "      <th>word_freq_order</th>\n",
       "      <th>word_freq_mail</th>\n",
       "      <th>...</th>\n",
       "      <th>word_freq_conference</th>\n",
       "      <th>char_freq_%3B</th>\n",
       "      <th>char_freq_%28</th>\n",
       "      <th>char_freq_%5B</th>\n",
       "      <th>char_freq_%21</th>\n",
       "      <th>char_freq_%24</th>\n",
       "      <th>char_freq_%23</th>\n",
       "      <th>capital_run_length_average</th>\n",
       "      <th>capital_run_length_longest</th>\n",
       "      <th>capital_run_length_total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.756</td>\n",
       "      <td>61</td>\n",
       "      <td>278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.048</td>\n",
       "      <td>5.114</td>\n",
       "      <td>101</td>\n",
       "      <td>1028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.010</td>\n",
       "      <td>9.821</td>\n",
       "      <td>485</td>\n",
       "      <td>2259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\n",
       "0            0.00               0.64           0.64           0.0   \n",
       "1            0.21               0.28           0.50           0.0   \n",
       "2            0.06               0.00           0.71           0.0   \n",
       "3            0.00               0.00           0.00           0.0   \n",
       "4            0.00               0.00           0.00           0.0   \n",
       "\n",
       "   word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  \\\n",
       "0           0.32            0.00              0.00                0.00   \n",
       "1           0.14            0.28              0.21                0.07   \n",
       "2           1.23            0.19              0.19                0.12   \n",
       "3           0.63            0.00              0.31                0.63   \n",
       "4           0.63            0.00              0.31                0.63   \n",
       "\n",
       "   word_freq_order  word_freq_mail  ...  word_freq_conference  char_freq_%3B  \\\n",
       "0             0.00            0.00  ...                   0.0           0.00   \n",
       "1             0.00            0.94  ...                   0.0           0.00   \n",
       "2             0.64            0.25  ...                   0.0           0.01   \n",
       "3             0.31            0.63  ...                   0.0           0.00   \n",
       "4             0.31            0.63  ...                   0.0           0.00   \n",
       "\n",
       "   char_freq_%28  char_freq_%5B  char_freq_%21  char_freq_%24  char_freq_%23  \\\n",
       "0          0.000            0.0          0.778          0.000          0.000   \n",
       "1          0.132            0.0          0.372          0.180          0.048   \n",
       "2          0.143            0.0          0.276          0.184          0.010   \n",
       "3          0.137            0.0          0.137          0.000          0.000   \n",
       "4          0.135            0.0          0.135          0.000          0.000   \n",
       "\n",
       "   capital_run_length_average  capital_run_length_longest  \\\n",
       "0                       3.756                          61   \n",
       "1                       5.114                         101   \n",
       "2                       9.821                         485   \n",
       "3                       3.537                          40   \n",
       "4                       3.537                          40   \n",
       "\n",
       "   capital_run_length_total  \n",
       "0                       278  \n",
       "1                      1028  \n",
       "2                      2259  \n",
       "3                       191  \n",
       "4                       191  \n",
       "\n",
       "[5 rows x 57 columns]"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_data = fetch_openml(data_id=44, as_frame=True)  \n",
    "spam_df = spam_data.frame\n",
    "# Split into features and target\n",
    "X = spam_df.iloc[:, :-1]  # All columns except the last are features\n",
    "y = spam_df.iloc[:, -1]   # The last column is the target (spam or not)\n",
    "\n",
    "# Convert target to numeric\n",
    "y = y.astype(int)\n",
    "\n",
    "# Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TEST_SIZE, random_state=42)\n",
    "\n",
    "# Convert to H2O Frames\n",
    "h2o_train = H2OFrame(pd.DataFrame(X_train).assign(label=y_train.values))\n",
    "h2o_test = H2OFrame(pd.DataFrame(X_test).assign(label=y_test.values))\n",
    "\n",
    "h2o_train['label'] = h2o_train['label'].asfactor()\n",
    "h2o_test['label'] = h2o_test['label'].asfactor()\n",
    "\n",
    "# Example of dataset\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "ec15cb0c-eaaf-48b4-95f9-04a388b61027",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_freq_make</th>\n",
       "      <th>word_freq_address</th>\n",
       "      <th>word_freq_all</th>\n",
       "      <th>word_freq_3d</th>\n",
       "      <th>word_freq_our</th>\n",
       "      <th>word_freq_over</th>\n",
       "      <th>word_freq_remove</th>\n",
       "      <th>word_freq_internet</th>\n",
       "      <th>word_freq_order</th>\n",
       "      <th>word_freq_mail</th>\n",
       "      <th>...</th>\n",
       "      <th>word_freq_conference</th>\n",
       "      <th>char_freq_%3B</th>\n",
       "      <th>char_freq_%28</th>\n",
       "      <th>char_freq_%5B</th>\n",
       "      <th>char_freq_%21</th>\n",
       "      <th>char_freq_%24</th>\n",
       "      <th>char_freq_%23</th>\n",
       "      <th>capital_run_length_average</th>\n",
       "      <th>capital_run_length_longest</th>\n",
       "      <th>capital_run_length_total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.104553</td>\n",
       "      <td>0.213015</td>\n",
       "      <td>0.280656</td>\n",
       "      <td>0.065425</td>\n",
       "      <td>0.312223</td>\n",
       "      <td>0.095901</td>\n",
       "      <td>0.114208</td>\n",
       "      <td>0.105295</td>\n",
       "      <td>0.090067</td>\n",
       "      <td>0.239413</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031869</td>\n",
       "      <td>0.038575</td>\n",
       "      <td>0.139030</td>\n",
       "      <td>0.016976</td>\n",
       "      <td>0.269071</td>\n",
       "      <td>0.075811</td>\n",
       "      <td>0.044238</td>\n",
       "      <td>5.191515</td>\n",
       "      <td>52.172789</td>\n",
       "      <td>283.289285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.305358</td>\n",
       "      <td>1.290575</td>\n",
       "      <td>0.504143</td>\n",
       "      <td>1.395151</td>\n",
       "      <td>0.672513</td>\n",
       "      <td>0.273824</td>\n",
       "      <td>0.391441</td>\n",
       "      <td>0.401071</td>\n",
       "      <td>0.278616</td>\n",
       "      <td>0.644755</td>\n",
       "      <td>...</td>\n",
       "      <td>0.285735</td>\n",
       "      <td>0.243471</td>\n",
       "      <td>0.270355</td>\n",
       "      <td>0.109394</td>\n",
       "      <td>0.815672</td>\n",
       "      <td>0.245882</td>\n",
       "      <td>0.429342</td>\n",
       "      <td>31.729449</td>\n",
       "      <td>194.891310</td>\n",
       "      <td>606.347851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.588000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>35.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.065000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.276000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>95.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.380000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.188000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.315000</td>\n",
       "      <td>0.052000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.706000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>266.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.540000</td>\n",
       "      <td>14.280000</td>\n",
       "      <td>5.100000</td>\n",
       "      <td>42.810000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>5.880000</td>\n",
       "      <td>7.270000</td>\n",
       "      <td>11.110000</td>\n",
       "      <td>5.260000</td>\n",
       "      <td>18.180000</td>\n",
       "      <td>...</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>4.385000</td>\n",
       "      <td>9.752000</td>\n",
       "      <td>4.081000</td>\n",
       "      <td>32.478000</td>\n",
       "      <td>6.003000</td>\n",
       "      <td>19.829000</td>\n",
       "      <td>1102.500000</td>\n",
       "      <td>9989.000000</td>\n",
       "      <td>15841.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\n",
       "count     4601.000000        4601.000000    4601.000000   4601.000000   \n",
       "mean         0.104553           0.213015       0.280656      0.065425   \n",
       "std          0.305358           1.290575       0.504143      1.395151   \n",
       "min          0.000000           0.000000       0.000000      0.000000   \n",
       "25%          0.000000           0.000000       0.000000      0.000000   \n",
       "50%          0.000000           0.000000       0.000000      0.000000   \n",
       "75%          0.000000           0.000000       0.420000      0.000000   \n",
       "max          4.540000          14.280000       5.100000     42.810000   \n",
       "\n",
       "       word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  \\\n",
       "count    4601.000000     4601.000000       4601.000000         4601.000000   \n",
       "mean        0.312223        0.095901          0.114208            0.105295   \n",
       "std         0.672513        0.273824          0.391441            0.401071   \n",
       "min         0.000000        0.000000          0.000000            0.000000   \n",
       "25%         0.000000        0.000000          0.000000            0.000000   \n",
       "50%         0.000000        0.000000          0.000000            0.000000   \n",
       "75%         0.380000        0.000000          0.000000            0.000000   \n",
       "max        10.000000        5.880000          7.270000           11.110000   \n",
       "\n",
       "       word_freq_order  word_freq_mail  ...  word_freq_conference  \\\n",
       "count      4601.000000     4601.000000  ...           4601.000000   \n",
       "mean          0.090067        0.239413  ...              0.031869   \n",
       "std           0.278616        0.644755  ...              0.285735   \n",
       "min           0.000000        0.000000  ...              0.000000   \n",
       "25%           0.000000        0.000000  ...              0.000000   \n",
       "50%           0.000000        0.000000  ...              0.000000   \n",
       "75%           0.000000        0.160000  ...              0.000000   \n",
       "max           5.260000       18.180000  ...             10.000000   \n",
       "\n",
       "       char_freq_%3B  char_freq_%28  char_freq_%5B  char_freq_%21  \\\n",
       "count    4601.000000    4601.000000    4601.000000    4601.000000   \n",
       "mean        0.038575       0.139030       0.016976       0.269071   \n",
       "std         0.243471       0.270355       0.109394       0.815672   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.065000       0.000000       0.000000   \n",
       "75%         0.000000       0.188000       0.000000       0.315000   \n",
       "max         4.385000       9.752000       4.081000      32.478000   \n",
       "\n",
       "       char_freq_%24  char_freq_%23  capital_run_length_average  \\\n",
       "count    4601.000000    4601.000000                 4601.000000   \n",
       "mean        0.075811       0.044238                    5.191515   \n",
       "std         0.245882       0.429342                   31.729449   \n",
       "min         0.000000       0.000000                    1.000000   \n",
       "25%         0.000000       0.000000                    1.588000   \n",
       "50%         0.000000       0.000000                    2.276000   \n",
       "75%         0.052000       0.000000                    3.706000   \n",
       "max         6.003000      19.829000                 1102.500000   \n",
       "\n",
       "       capital_run_length_longest  capital_run_length_total  \n",
       "count                 4601.000000               4601.000000  \n",
       "mean                    52.172789                283.289285  \n",
       "std                    194.891310                606.347851  \n",
       "min                      1.000000                  1.000000  \n",
       "25%                      6.000000                 35.000000  \n",
       "50%                     15.000000                 95.000000  \n",
       "75%                     43.000000                266.000000  \n",
       "max                   9989.000000              15841.000000  \n",
       "\n",
       "[8 rows x 57 columns]"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da495d0-1d7d-4850-8f27-a1da854d2a1f",
   "metadata": {},
   "source": [
    "## TODO Try out some feature selection maybe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c91792-1ec8-4fca-b714-c024a9df1177",
   "metadata": {},
   "source": [
    "#### Is SPAM class underepresented?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "id": "820d0484-447e-47d5-a571-b81da3a9ce15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records containing spam: 1813\n",
      "Records not containing spam: 2788\n"
     ]
    }
   ],
   "source": [
    "class_1 = len(spam_df[spam_df['class'] == '1'])\n",
    "class_0 = len(spam_df[spam_df['class'] == '0'])\n",
    "print(f\"Records containing spam: {class_1}\")\n",
    "print(f\"Records not containing spam: {class_0}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a416ec65-3b47-4474-aa36-6e2f04f8694f",
   "metadata": {},
   "source": [
    "#### Computing the effective sample size n_eff (from paper)\n",
    "\n",
    "We have binary data, the prevalence of Y is **p=class_1 / total_size**, subsequently **n_rare=n*min(p, 1-p)**, and finally **n_eff=min(n, 5*n_rare)** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 668,
   "id": "3617cd42-233b-4ace-b2a2-3b5f892f0346",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4601"
      ]
     },
     "execution_count": 668,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = len(spam_df)\n",
    "\n",
    "p = class_1 / n\n",
    "n_rare = n * min(p, 1-p)\n",
    "n_eff = min(n, 5*n_rare)\n",
    "n_eff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50c87ec-b54d-43f4-a51a-19a295ae274f",
   "metadata": {},
   "source": [
    "#### Computing the V for V-fold cross-validation\n",
    "Since n_eff >= 500 but not >= 5000 we should select a value between 20 and 10. We take in account that n_eff is closer to 5000 and so we focus on V slightly higher than 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 698,
   "id": "f9ee561d-d6f0-4583-babe-66fc7835ffe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_FOLDS = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223e2513-612b-43f5-8e60-557e13eb01f8",
   "metadata": {},
   "source": [
    "### BASE LEARNERS - SPECIFICATION\n",
    "\n",
    "When choosing the base learners for the first layer we have considered the properties of the dataset and the task in this case being binary classification. As the paper *Practical considerations for specifying a super learner* suggests \"An ideal, rich library is diverse in its learning strategies, able to adapt to a range of underlying functional forms for the true prediction function, computationally feasible, and effective at handling high dimensional data. Diverse libraries include parametric learners, highly data-adaptive learners, multiple variants of the same learner with different tuning parameter specifications...\". So the first layer should consist of diverse algorithms with different inductive biases to ensure a rich set of predictions for the metalearnerearner\".\n",
    "\n",
    "We have selected: \n",
    "\n",
    "**Random Forest:**\n",
    "\n",
    "Because they are robust to overfitting on datasets with many features and they handle noisy or irrelevant features well, which is can be a thing in this case.\n",
    "\n",
    "**Generalized Linear Model - Logistic regression:**\n",
    "\n",
    "We chose to add it because it's a simple yet effective baseline model, especially logistic regression for binary classification. It should provide a low-variance learner to complement the other high-variance ones.\n",
    "\n",
    "**Deep Learning (H20's MLP):**\n",
    "\n",
    "We add the neural networks, because of it's flexibility so it could capture non-linear relationships which should broaden the diversity of the stacks prediction.\n",
    "\n",
    "**Naive Bayes:**\n",
    "\n",
    "Why: Spam datasets often benefit from Naive Bayes since it assumes independence among features and thus might capture something more general than the other models.\n",
    "\n",
    "**Gradient Boosting Machines:**\n",
    "\n",
    "We choose them as another complement ensemble method that can capture rather complex relationship and so maybe overfit more to th data.\n",
    "\n",
    "\n",
    "We assume the simpler models like naive bayes and logistic regression should bring in the stack a more general view without focusing too much on the quirks in the data and to balance it out we have selected a more accurate and flexible methods like MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4444e6-ca57-4aa0-b2d2-47f88b70c244",
   "metadata": {},
   "source": [
    "Also we try various configurations of hyperparameters for each class of learners as the paper specifies: *\"Since the true functional form is unknown, it is a good idea to consider a variety of base learners, and to construct multiple variations of the same base learner with different tuning specifications. There is no harm in including a learner that performs poorly in the library, as it will be given a weight of zero...\"* (or close to 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "id": "8f66af53-4ce2-4ae7-87f2-b13466b994d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_learners_simple01 = {\n",
    "    \"LogisticRegression\": H2OGeneralizedLinearEstimator(family=\"binomial\", nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True),\n",
    "    \"RandomForest\": H2ORandomForestEstimator(ntrees=50, max_depth=10, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True),\n",
    "    \"GradientBoosting\": H2OGradientBoostingEstimator(ntrees=50, max_depth=5, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True),\n",
    "    \"NaiveBayes\": H2ONaiveBayesEstimator(nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True)\n",
    "}\n",
    "\n",
    "# TODO consider balance_class=True\n",
    "\n",
    "base_learners_mix_duplicates01 = {\n",
    "    \"LogisticRegression_binomial\": H2OGeneralizedLinearEstimator(\n",
    "        family=\"binomial\", nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "    ),\n",
    "    \"RandomForest_50trees\": H2ORandomForestEstimator(\n",
    "        ntrees=50, max_depth=10, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "    ),\n",
    "    \"RandomForest_50trees_unbounded_D\": H2ORandomForestEstimator(\n",
    "        ntrees=50, max_depth=10, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "    ),\n",
    "    \"RandomForest_10trees\": H2ORandomForestEstimator(\n",
    "        ntrees=10, max_depth=10, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "    ),\n",
    "    \"RandomForest_10trees_unbounded_D\": H2ORandomForestEstimator(\n",
    "        ntrees=10, max_depth=10, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "    ),\n",
    "    \"GradientBoosting\": H2OGradientBoostingEstimator(\n",
    "        ntrees=50, max_depth=5, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True, balance_classes=True\n",
    "    ),\n",
    "    \"NaiveBayes\": H2ONaiveBayesEstimator(\n",
    "        nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "    ),\n",
    "    \"NeuralNetwork_32\": H2ODeepLearningEstimator(\n",
    "        hidden=[32], epochs=10, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "    ),\n",
    "    \"NeuralNetwork_32_16\": H2ODeepLearningEstimator(\n",
    "        hidden=[32, 16], epochs=10, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "    )\n",
    "}\n",
    "\n",
    "base_learners_mix_rf_nns_01 = {\n",
    "    \"LogisticRegression_binomial\": H2OGeneralizedLinearEstimator(\n",
    "        family=\"binomial\", nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "    ),\n",
    "    \"RandomForest_50trees\": H2ORandomForestEstimator(\n",
    "        ntrees=50, max_depth=10, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "    ),\n",
    "    \"RandomForest_50trees_unbounded_D\": H2ORandomForestEstimator(\n",
    "    ntrees=50, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "    ),\n",
    "    \"RandomForest_10trees\": H2ORandomForestEstimator(\n",
    "        ntrees=10, max_depth=10, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "    ),\n",
    "    \"RandomForest_10trees_unbounded_D\": H2ORandomForestEstimator(\n",
    "        ntrees=10, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "    ),\n",
    "    \"GradientBoosting_10trees\": H2OGradientBoostingEstimator(\n",
    "        ntrees=10, max_depth=5, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True, balance_classes=True\n",
    "    ),\n",
    "    \"GradientBoosting_50trees\": H2OGradientBoostingEstimator(\n",
    "        ntrees=50, max_depth=5, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True, balance_classes=True\n",
    "    ),\n",
    "    \"NaiveBayes\": H2ONaiveBayesEstimator(\n",
    "        nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "    ),\n",
    "    \"NeuralNetwork_32_16\": H2ODeepLearningEstimator(\n",
    "        hidden=[32, 16], epochs=300, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "    ),\n",
    "    \"NeuralNetwork_32_32\": H2ODeepLearningEstimator(\n",
    "        hidden=[32, 32], epochs=300, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "    ),\n",
    "    \"NeuralNetwork_32\": H2ODeepLearningEstimator(\n",
    "        hidden=[32], epochs=300, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c7f67b-4ad5-4d78-a96a-5b21ba3566c6",
   "metadata": {},
   "source": [
    "### BASE LEARNERS - TRAINING & EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "613da5ef-a22d-45ee-9443-57d2457c92e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Train each base learner using cross-validation\n",
    "# for name, learner in base_learners.items():\n",
    "#     print(f\"Training {name} with {N_FOLDS}-fold cross-validation...\")\n",
    "#     learner.train(x=list(range(X_train.shape[1])), y=\"label\", training_frame=h2o_train)\n",
    "\n",
    "# results = {}\n",
    "# for name, learner in base_learners.items():\n",
    "#     performance = learner.model_performance(test_data=h2o_test)\n",
    "#     f1_score = performance.F1()[0][1]  \n",
    "#     auc_pr = performance.aucpr()      \n",
    "#     accuracy = performance.accuracy()[0][1]\n",
    "#     results[name] = accuracy\n",
    "#     results[name] = {\"F1-Score\": f1_score, \"AUC-PR\": auc_pr, \"Accuracy\": accuracy}\n",
    "#     print(f\"{name} - F1-Score: {f1_score:.4f}, AUC-PR: {auc_pr:.4f}, Accuracy (Test Set): {accuracy:.4f}\")\n",
    "\n",
    "\n",
    "# # Print results\n",
    "# print(\"Base Learner Results:\", results)\n",
    "\n",
    "# base_models = list(base_learners.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "id": "9ee8fbbf-aff0-4cd7-878d-84d6b0f0a07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_evaluate_stack(base_learners, metalearner, h2o_train, h2o_test, X_train):\n",
    "    \n",
    "    # TRAIN BASE LEARNERS\n",
    "    print(\"\\n>>> Training base learners:\\n\")\n",
    "    for name, learner in base_learners.items():\n",
    "        print(f\"    Training {name} with {N_FOLDS}-fold cross-validation...\")\n",
    "        learner.train(x=list(range(X_train.shape[1])), y=\"label\", training_frame=h2o_train)\n",
    "\n",
    "    super_learner = H2OStackedEnsembleEstimator(\n",
    "        base_models=list(base_learners.values()),\n",
    "        metalearner_algorithm=metalearner\n",
    "    )\n",
    "    # TRAIN THE METALEARNER\n",
    "    print(\"\\n>>> Training super learner:\\n\")\n",
    "    super_learner.train(x=list(range(X_train.shape[1])), y=\"label\", training_frame=h2o_train)\n",
    "\n",
    "    # EVAL BASE LEARNERS\n",
    "    print(\"\\n>>> Base learners' results:\\n\")\n",
    "    results = {}\n",
    "    for name, learner in base_learners.items():\n",
    "        performance = learner.model_performance(test_data=h2o_test)\n",
    "        f1_score = performance.F1()[0][1]  \n",
    "        auc_pr = performance.aucpr()      \n",
    "        accuracy = performance.accuracy()[0][1]\n",
    "        results[name] = accuracy\n",
    "        results[name] = {\"F1-Score\": f1_score, \"AUC-PR\": auc_pr, \"Accuracy\": accuracy}\n",
    "        print(f\"    {name} - F1-Score: {f1_score:.4f}, AUC-PR: {auc_pr:.4f}, Accuracy (Test Set): {accuracy:.4f}\")\n",
    "    \n",
    "    # EVAL THE METALEARNER\n",
    "    print(\"\\n>>> Metalearner's results:\\n\")\n",
    "    super_performance = super_learner.model_performance(test_data=h2o_test)\n",
    "    super_accuracy = super_performance.accuracy()[0][1]\n",
    "    super_f1 = super_performance.F1()[0][1]  \n",
    "    super_auc_pr = super_performance.aucpr()  \n",
    "    # print(f\"\\n    Super Learner - F1-Score: {super_f1:.4f}, AUC-PR: {super_auc_pr:.4f} | Super Learner Accuracy: {super_accuracy:.4f}\")\n",
    "    \n",
    "    \n",
    "    # print(\"\\nFinal Results Comparison:\")\n",
    "    # for name, metrics in results.items():\n",
    "    #     print(f\"{name} - F1-Score: {metrics['F1-Score']:.4f}, AUC-PR: {metrics['AUC-PR']:.4f}, Accuracy: {metrics['Accuracy']:.4f}\")\n",
    "        \n",
    "    print(f\"    Super Learner - F1-Score: {super_f1:.4f}, AUC-PR: {super_auc_pr:.4f}, Accuracy: {super_accuracy:.4f}\")\n",
    "    return {\"F1-Score\": super_f1, \"AUC-PR\": super_auc_pr, \"Accuracy\": super_accuracy}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b97691-0800-43f5-944e-4579f0563eb7",
   "metadata": {},
   "source": [
    "### METALEARNER - TRAINING & EVALUATION\n",
    "\n",
    "\n",
    "For the metalearner we principally selected two possible options for testing:\n",
    "\n",
    "**GLM:**\n",
    "\n",
    "We chose logistic regression because it is simple and interpretable and as a meta-learner we want it just combine the predictions of individual learners by weighting the them reducing the risk of overfitting when combining predictions. So in this case we are more focused on finding the best combination of predictions rather than adding more complexity.\n",
    "\n",
    "**Gradient Boosting Machine / MLP:**\n",
    "\n",
    "As an alternative second option we wanted something stronger, a bit of a bigger hammer sort to say, especially for our stacks which are more diverse in which case their predictions could be more complex, so they could capture non-linear relationships among them.\n",
    "\n",
    "**Evaluation metrics:**\n",
    "In accordance with the paper where our task is binary classification of imbalanced classes we chose AUCPR as a primary evaluation metric. In addition as alternatives we provide F1 (once again due uneven class distribution) and finally accuracy as complement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "id": "03d103a3-1605-4928-8931-db29b9bac0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TRAIN\n",
    "# super_learner = H2OStackedEnsembleEstimator(\n",
    "#     base_models=base_models,\n",
    "#     metalearner_algorithm=\"glm\"  # Uses Logistic Regression as the metalearner\n",
    "# )\n",
    "\n",
    "# # super_learner = H2OStackedEnsembleEstimator(\n",
    "# #     base_models=base_models,\n",
    "# #     metalearner_algorithm=\"deeplearning\"  # Uses Logistic Regression as the metalearner\n",
    "# # )\n",
    "\n",
    "# print(\"\\nTraining Super Learner:\\n\")\n",
    "# super_learner.train(x=list(range(X_train.shape[1])), y=\"label\", training_frame=h2o_train)\n",
    "\n",
    "# # EVAL\n",
    "# super_performance = super_learner.model_performance(test_data=h2o_test)\n",
    "# super_accuracy = super_performance.accuracy()[0][1]\n",
    "# super_f1 = super_performance.F1()[0][1]  \n",
    "# super_auc_pr = super_performance.aucpr()  \n",
    "# # print(f\"\\nSuper Learner - F1-Score: {super_f1:.4f}, AUC-PR: {super_auc_pr:.4f} | Super Learner Accuracy: {super_accuracy:.4f}\")\n",
    "\n",
    "\n",
    "# print(\"\\nFinal Results Comparison:\\n\")\n",
    "# for name, metrics in results.items():\n",
    "#     print(f\"    {name} - F1-Score: {metrics['F1-Score']:.4f}, AUC-PR: {metrics['AUC-PR']:.4f}, Accuracy: {metrics['Accuracy']:.4f}\")\n",
    "    \n",
    "# print(f\"    Super Learner - F1-Score: {super_f1:.4f}, AUC-PR: {super_auc_pr:.4f}, Accuracy: {super_accuracy:.4f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 700,
   "id": "f7e61dcd-28d1-4a92-8fc1-cfba19777b6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Training base learners:\n",
      "\n",
      "    Training LogisticRegression with 12-fold cross-validation...\n",
      "glm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training RandomForest with 12-fold cross-validation...\n",
      "drf Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting with 12-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training NaiveBayes with 12-fold cross-validation...\n",
      "naivebayes Model Build progress: |███████████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Training super learner:\n",
      "\n",
      "stackedensemble Model Build progress: |██████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Base learners' results:\n",
      "\n",
      "    LogisticRegression - F1-Score: 0.9125, AUC-PR: 0.9597, Accuracy (Test Set): 0.9251\n",
      "    RandomForest - F1-Score: 0.9375, AUC-PR: 0.9790, Accuracy (Test Set): 0.9479\n",
      "    GradientBoosting - F1-Score: 0.9490, AUC-PR: 0.9848, Accuracy (Test Set): 0.9566\n",
      "    NaiveBayes - F1-Score: 0.8303, AUC-PR: 0.8182, Accuracy (Test Set): 0.8588\n",
      "\n",
      ">>> Metalearner's results:\n",
      "\n",
      "    Super Learner - F1-Score: 0.9537, AUC-PR: 0.9839, Accuracy: 0.9609\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'F1-Score': 0.9537275064267353,\n",
       " 'AUC-PR': 0.98388486064698,\n",
       " 'Accuracy': 0.9609120521172638}"
      ]
     },
     "execution_count": 700,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_evaluate_stack(base_learners_simple01, \"glm\", h2o_train, h2o_test, X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "id": "a1caa0dd-550f-412d-9c41-3161d56e149b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Training base learners:\n",
      "\n",
      "    Training LogisticRegression_binomial with 5-fold cross-validation...\n",
      "glm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training RandomForest_50trees with 5-fold cross-validation...\n",
      "drf Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training RandomForest_50trees_unbounded_D with 5-fold cross-validation...\n",
      "drf Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training RandomForest_10trees with 5-fold cross-validation...\n",
      "drf Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training RandomForest_10trees_unbounded_D with 5-fold cross-validation...\n",
      "drf Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training NaiveBayes with 5-fold cross-validation...\n",
      "naivebayes Model Build progress: |███████████████████████████████████████████████| (done) 100%\n",
      "    Training NeuralNetwork with 5-fold cross-validation...\n",
      "deeplearning Model Build progress: |█████████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Training super learner:\n",
      "\n",
      "stackedensemble Model Build progress: |██████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Base learners' results:\n",
      "\n",
      "    LogisticRegression_binomial - F1-Score: 0.9125, AUC-PR: 0.9597, Accuracy (Test Set): 0.9251\n",
      "    RandomForest_50trees - F1-Score: 0.9375, AUC-PR: 0.9790, Accuracy (Test Set): 0.9479\n",
      "    RandomForest_50trees_unbounded_D - F1-Score: 0.9375, AUC-PR: 0.9790, Accuracy (Test Set): 0.9479\n",
      "    RandomForest_10trees - F1-Score: 0.9235, AUC-PR: 0.9688, Accuracy (Test Set): 0.9370\n",
      "    RandomForest_10trees_unbounded_D - F1-Score: 0.9235, AUC-PR: 0.9688, Accuracy (Test Set): 0.9370\n",
      "    NaiveBayes - F1-Score: 0.8303, AUC-PR: 0.8182, Accuracy (Test Set): 0.8588\n",
      "    NeuralNetwork - F1-Score: 0.9376, AUC-PR: 0.9743, Accuracy (Test Set): 0.9468\n",
      "\n",
      ">>> Metalearner's results:\n",
      "\n",
      "    Super Learner - F1-Score: 0.9404, AUC-PR: 0.9818, Accuracy: 0.9490\n"
     ]
    }
   ],
   "source": [
    "train_evaluate_stack(base_learners_mix_duplicates01, \"glm\", h2o_train, h2o_test, X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "id": "42f84d97-413f-43e5-9641-e64ca64c3239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Training base learners:\n",
      "\n",
      "    Training LogisticRegression_binomial with 5-fold cross-validation...\n",
      "glm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training RandomForest_50trees with 5-fold cross-validation...\n",
      "drf Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training RandomForest_50trees_unbounded_D with 5-fold cross-validation...\n",
      "drf Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training RandomForest_10trees with 5-fold cross-validation...\n",
      "drf Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training RandomForest_10trees_unbounded_D with 5-fold cross-validation...\n",
      "drf Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting with 5-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training NaiveBayes with 5-fold cross-validation...\n",
      "naivebayes Model Build progress: |███████████████████████████████████████████████| (done) 100%\n",
      "    Training NeuralNetwork_32_16 with 5-fold cross-validation...\n",
      "deeplearning Model Build progress: |█████████████████████████████████████████████| (done) 100%\n",
      "    Training NeuralNetwork_32_32 with 5-fold cross-validation...\n",
      "deeplearning Model Build progress: |█████████████████████████████████████████████| (done) 100%\n",
      "    Training NeuralNetwork_32 with 5-fold cross-validation...\n",
      "deeplearning Model Build progress: |█████████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Training super learner:\n",
      "\n",
      "stackedensemble Model Build progress: |██████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Base learners' results:\n",
      "\n",
      "    LogisticRegression_binomial - F1-Score: 0.9125, AUC-PR: 0.9597, Accuracy (Test Set): 0.9251\n",
      "    RandomForest_50trees - F1-Score: 0.9375, AUC-PR: 0.9790, Accuracy (Test Set): 0.9479\n",
      "    RandomForest_50trees_unbounded_D - F1-Score: 0.9501, AUC-PR: 0.9839, Accuracy (Test Set): 0.9577\n",
      "    RandomForest_10trees - F1-Score: 0.9235, AUC-PR: 0.9688, Accuracy (Test Set): 0.9370\n",
      "    RandomForest_10trees_unbounded_D - F1-Score: 0.9300, AUC-PR: 0.9756, Accuracy (Test Set): 0.9425\n",
      "    GradientBoosting - F1-Score: 0.9452, AUC-PR: 0.9838, Accuracy (Test Set): 0.9533\n",
      "    NaiveBayes - F1-Score: 0.8303, AUC-PR: 0.8182, Accuracy (Test Set): 0.8588\n",
      "    NeuralNetwork_32_16 - F1-Score: 0.9274, AUC-PR: 0.9594, Accuracy (Test Set): 0.9381\n",
      "    NeuralNetwork_32_32 - F1-Score: 0.9283, AUC-PR: 0.9676, Accuracy (Test Set): 0.9403\n",
      "    NeuralNetwork_32 - F1-Score: 0.9309, AUC-PR: 0.9660, Accuracy (Test Set): 0.9425\n",
      "\n",
      ">>> Metalearner's results:\n",
      "\n",
      "    Super Learner - F1-Score: 0.9494, AUC-PR: 0.9875, Accuracy: 0.9577\n"
     ]
    }
   ],
   "source": [
    "train_evaluate_stack(base_learners_mix_rf_nns_01, \"glm\", h2o_train, h2o_test, X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4a08d9-2542-42c7-a4db-5f4a6479658e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e595ae30-3eed-4f27-9da6-607ef4a31fc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "456ea211-3dd9-4845-ab77-c176675b55a8",
   "metadata": {},
   "source": [
    "# Ablation studies\n",
    "\n",
    "In the following we tried a more methodological way of building the stack. \n",
    "We tried two approaches and evaluated their effects on the final test metrics:\n",
    "\n",
    "**1) Building the stack from simpler models adding more complex ones:**\n",
    "\n",
    "In this method we start from a base consisting of simple models which we assume would capture the main / most general pattern in the data.\n",
    "Afterwards we gradually try adding more complex models to extend the stack capabilities to capture more finer intricacies and more complex (perhaps non-linear) relationships in the data and we observe the effect on the test metrics.\n",
    "\n",
    "\n",
    "**1) Building the stack from more complex models adding more general/simple ones:**\n",
    "In this method we start from a base consisting of more complex models which we assume would capture the complex relationships in data well and then\n",
    "we try to bring down the variance by adding simpler models that don't overfit to the data so much.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "id": "ed000c1c-6b4c-4079-8acc-bc8f7b80f791",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_learners = {\n",
    "                   \"LogisticRegression_binomial\": H2OGeneralizedLinearEstimator(\n",
    "                        family=\"binomial\", nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "                    ), \n",
    "                   \"NaiveBayes\": H2ONaiveBayesEstimator(nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True)}\n",
    "\n",
    "\n",
    "random_forests = {  \n",
    "                    \"RandomForest_10trees\": H2ORandomForestEstimator(\n",
    "                        ntrees=10, max_depth=10, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "                    ),\n",
    "                    \"RandomForest_20trees\": H2ORandomForestEstimator(\n",
    "                        ntrees=20, max_depth=10, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "                    ),\n",
    "                    \"RandomForest_50trees\": H2ORandomForestEstimator(\n",
    "                        ntrees=50, max_depth=10, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "                    ),\n",
    "                    \"RandomForest_10trees_unbounded_D\": H2ORandomForestEstimator(\n",
    "                        ntrees=10, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "                    ),\n",
    "                    \"RandomForest_20trees_unbounded_D\": H2ORandomForestEstimator(\n",
    "                        ntrees=20, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "                    ),\n",
    "                    \"RandomForest_50trees_unbounded_D\": H2ORandomForestEstimator(\n",
    "                        ntrees=50, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "                    )}\n",
    "\n",
    "gradient_boostings = {\n",
    "\n",
    "                    \"GradientBoosting_10trees\": H2OGradientBoostingEstimator(\n",
    "                        ntrees=10, max_depth=5, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True, balance_classes=True\n",
    "                    ),\n",
    "                    \"GradientBoosting_20trees\": H2OGradientBoostingEstimator(\n",
    "                        ntrees=20, max_depth=5, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True, balance_classes=True\n",
    "                    ),\n",
    "                    \"GradientBoosting_50trees\": H2OGradientBoostingEstimator(\n",
    "                        ntrees=50, max_depth=5, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True, balance_classes=True\n",
    "                    ),\n",
    "                    \"GradientBoosting_10trees_unbounded_D\": H2OGradientBoostingEstimator(\n",
    "                        ntrees=10, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True, balance_classes=True\n",
    "                    ),\n",
    "                    \"GradientBoosting_20trees_unbounded_D\": H2OGradientBoostingEstimator(\n",
    "                        ntrees=20, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True, balance_classes=True\n",
    "                    ),\n",
    "                    \"GradientBoosting_50trees_unbounded_D\": H2OGradientBoostingEstimator(\n",
    "                        ntrees=50, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True, balance_classes=True\n",
    "                    )}\n",
    "\n",
    "neural_networks = {\n",
    "                    \"NeuralNetwork_6\": H2ODeepLearningEstimator(\n",
    "                        hidden=[6], epochs=300, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "                    ), \n",
    "                    \"NeuralNetwork_16\": H2ODeepLearningEstimator(\n",
    "                        hidden=[16], epochs=300, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "                    ), \n",
    "                    \"NeuralNetwork_32\": H2ODeepLearningEstimator(\n",
    "                        hidden=[32], epochs=300, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "                    ), \n",
    "                    \"NeuralNetwork_32_16\": H2ODeepLearningEstimator(\n",
    "                    hidden=[32, 16], epochs=300, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "                    ),\n",
    "                    \"NeuralNetwork_32_32\": H2ODeepLearningEstimator(\n",
    "                        hidden=[32, 32], epochs=300, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "                    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6198921-0a69-413b-bd7b-257a367ec07a",
   "metadata": {},
   "source": [
    "### A more efficient variant would be training each model only once in case it is present in multiple combinations.\n",
    "\n",
    "Due to the tradeoff between the scope of this project and time capabilities we perform only superficial overview. If the problem would be a topic of major research where the time needed to search the vast hypothesis space is available, we would suggest performing more extensive per-class tests with higher hyperparameter sampling granularity to better observe how they affect the models performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "id": "b2891b93-e73c-495f-8e3c-97fccf7c98a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_to_complex01 = {                   \n",
    "    \"LogisticRegression_binomial\": H2OGeneralizedLinearEstimator(\n",
    "                        family=\"binomial\", nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "                    ), \n",
    "}\n",
    "\n",
    "simple_to_complex02 = {                   \n",
    "    \"LogisticRegression_binomial\": H2OGeneralizedLinearEstimator(\n",
    "                        family=\"binomial\", nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "                    ), \n",
    "    \"RandomForest_10trees\": H2ORandomForestEstimator(\n",
    "                        ntrees=10, max_depth=10, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "                    ),   \n",
    "}\n",
    "\n",
    "simple_to_complex03 = {                   \n",
    "    \"LogisticRegression_binomial\": H2OGeneralizedLinearEstimator(\n",
    "                        family=\"binomial\", nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "                    ), \n",
    "    \"RandomForest_10trees\": H2ORandomForestEstimator(\n",
    "                        ntrees=10, max_depth=10, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "                    ),   \n",
    "    \"RandomForest_20trees\": H2ORandomForestEstimator(\n",
    "    ntrees=20, max_depth=10, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "),\n",
    "}\n",
    "\n",
    "simple_to_complex04= {                   \n",
    "    \"LogisticRegression_binomial\": H2OGeneralizedLinearEstimator(\n",
    "                        family=\"binomial\", nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "                    ), \n",
    "    \"RandomForest_10trees\": H2ORandomForestEstimator(\n",
    "                        ntrees=10, max_depth=10, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "                    ),   \n",
    "    \"RandomForest_20trees\": H2ORandomForestEstimator(\n",
    "    ntrees=20, max_depth=10, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "),\n",
    "    \"RandomForest_50trees\": H2ORandomForestEstimator(\n",
    "    ntrees=50, max_depth=10, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "),\n",
    "}\n",
    "\n",
    "\n",
    "simple_to_complex05 = {                   \n",
    "    \"LogisticRegression_binomial\": H2OGeneralizedLinearEstimator(\n",
    "                        family=\"binomial\", nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "                    ), \n",
    "    \"RandomForest_10trees\": H2ORandomForestEstimator(\n",
    "                        ntrees=10, max_depth=10, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "                    ),   \n",
    "    \"RandomForest_50trees\": H2ORandomForestEstimator(\n",
    "    ntrees=50, max_depth=10, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "),\n",
    "}\n",
    "\n",
    "\n",
    "simple_to_complex06 = {                   \n",
    "    \"LogisticRegression_binomial\": H2OGeneralizedLinearEstimator(\n",
    "                        family=\"binomial\", nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "                    ), \n",
    "    \"RandomForest_10trees\": H2ORandomForestEstimator(\n",
    "                        ntrees=10, max_depth=10, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "                    ),   \n",
    "}\n",
    "\n",
    "\n",
    "simple_to_complex07 = {                   \n",
    "    \"LogisticRegression_binomial\": H2OGeneralizedLinearEstimator(\n",
    "                        family=\"binomial\", nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "                    ), \n",
    "    \"RandomForest_10trees\": H2ORandomForestEstimator(\n",
    "                    ntrees=10, max_depth=10, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "                ),   \n",
    "    \"RandomForest_10trees_unbounded_D\": H2ORandomForestEstimator(\n",
    "        ntrees=10, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "    ),\n",
    "}\n",
    "\n",
    "\n",
    "simple_to_complex08 = {                   \n",
    "    \"LogisticRegression_binomial\": H2OGeneralizedLinearEstimator(\n",
    "                        family=\"binomial\", nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "                    ), \n",
    "    \"RandomForest_10trees_unbounded_D\": H2ORandomForestEstimator(\n",
    "        ntrees=10, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "    ),\n",
    "}\n",
    "\n",
    "\n",
    "simple_to_complex09 = {                   \n",
    "    \"LogisticRegression_binomial\": H2OGeneralizedLinearEstimator(\n",
    "                        family=\"binomial\", nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "                    ), \n",
    "    \"RandomForest_10trees_unbounded_D\": H2ORandomForestEstimator(\n",
    "        ntrees=10, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "    ),\n",
    "    \"RandomForest_20trees_unbounded_D\": H2ORandomForestEstimator(\n",
    "    ntrees=20, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "),\n",
    "}\n",
    "\n",
    "simple_to_complex10 = {                   \n",
    "    \"LogisticRegression_binomial\": H2OGeneralizedLinearEstimator(\n",
    "                        family=\"binomial\", nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "                    ), \n",
    "    \"RandomForest_10trees_unbounded_D\": H2ORandomForestEstimator(\n",
    "        ntrees=10, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "    ),\n",
    "    \"RandomForest_20trees_unbounded_D\": H2ORandomForestEstimator(\n",
    "    ntrees=20, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "),\n",
    "    \"RandomForest_50trees_unbounded_D\": H2ORandomForestEstimator(\n",
    "    ntrees=50, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "),\n",
    "}\n",
    "\n",
    "random_forest_stacks = [\n",
    "                        simple_to_complex01,\n",
    "                        simple_to_complex02,\n",
    "                        simple_to_complex03,\n",
    "                        simple_to_complex04,\n",
    "                        simple_to_complex05,\n",
    "                        simple_to_complex06,\n",
    "                        simple_to_complex07,\n",
    "                        simple_to_complex08,\n",
    "                        simple_to_complex09,\n",
    "                        simple_to_complex10\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "id": "5989b9e6-20e2-42ce-b427-b9bab22a8431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Training base learners:\n",
      "\n",
      "    Training LogisticRegression_binomial with 5-fold cross-validation...\n",
      "glm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Training super learner:\n",
      "\n",
      "stackedensemble Model Build progress: |██████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Base learners' results:\n",
      "\n",
      "    LogisticRegression_binomial - F1-Score: 0.9125, AUC-PR: 0.9597, Accuracy (Test Set): 0.9251\n",
      "\n",
      ">>> Metalearner's results:\n",
      "\n",
      "    Super Learner - F1-Score: 0.9125, AUC-PR: 0.9597, Accuracy: 0.9251\n",
      "\n",
      ">>> Training base learners:\n",
      "\n",
      "    Training LogisticRegression_binomial with 5-fold cross-validation...\n",
      "glm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training RandomForest_10trees with 5-fold cross-validation...\n",
      "drf Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Training super learner:\n",
      "\n",
      "stackedensemble Model Build progress: |██████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Base learners' results:\n",
      "\n",
      "    LogisticRegression_binomial - F1-Score: 0.9125, AUC-PR: 0.9597, Accuracy (Test Set): 0.9251\n",
      "    RandomForest_10trees - F1-Score: 0.9235, AUC-PR: 0.9688, Accuracy (Test Set): 0.9370\n",
      "\n",
      ">>> Metalearner's results:\n",
      "\n",
      "    Super Learner - F1-Score: 0.9294, AUC-PR: 0.9759, Accuracy: 0.9403\n",
      "\n",
      ">>> Training base learners:\n",
      "\n",
      "    Training LogisticRegression_binomial with 5-fold cross-validation...\n",
      "glm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training RandomForest_10trees with 5-fold cross-validation...\n",
      "drf Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training RandomForest_20trees with 5-fold cross-validation...\n",
      "drf Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Training super learner:\n",
      "\n",
      "stackedensemble Model Build progress: |██████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Base learners' results:\n",
      "\n",
      "    LogisticRegression_binomial - F1-Score: 0.9125, AUC-PR: 0.9597, Accuracy (Test Set): 0.9251\n",
      "    RandomForest_10trees - F1-Score: 0.9235, AUC-PR: 0.9688, Accuracy (Test Set): 0.9370\n",
      "    RandomForest_20trees - F1-Score: 0.9291, AUC-PR: 0.9722, Accuracy (Test Set): 0.9403\n",
      "\n",
      ">>> Metalearner's results:\n",
      "\n",
      "    Super Learner - F1-Score: 0.9340, AUC-PR: 0.9757, Accuracy: 0.9446\n",
      "\n",
      ">>> Training base learners:\n",
      "\n",
      "    Training LogisticRegression_binomial with 5-fold cross-validation...\n",
      "glm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training RandomForest_10trees with 5-fold cross-validation...\n",
      "drf Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training RandomForest_20trees with 5-fold cross-validation...\n",
      "drf Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training RandomForest_50trees with 5-fold cross-validation...\n",
      "drf Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Training super learner:\n",
      "\n",
      "stackedensemble Model Build progress: |██████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Base learners' results:\n",
      "\n",
      "    LogisticRegression_binomial - F1-Score: 0.9125, AUC-PR: 0.9597, Accuracy (Test Set): 0.9251\n",
      "    RandomForest_10trees - F1-Score: 0.9235, AUC-PR: 0.9688, Accuracy (Test Set): 0.9370\n",
      "    RandomForest_20trees - F1-Score: 0.9291, AUC-PR: 0.9722, Accuracy (Test Set): 0.9403\n",
      "    RandomForest_50trees - F1-Score: 0.9375, AUC-PR: 0.9790, Accuracy (Test Set): 0.9479\n",
      "\n",
      ">>> Metalearner's results:\n",
      "\n",
      "    Super Learner - F1-Score: 0.9388, AUC-PR: 0.9796, Accuracy: 0.9479\n",
      "\n",
      ">>> Training base learners:\n",
      "\n",
      "    Training LogisticRegression_binomial with 5-fold cross-validation...\n",
      "glm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training RandomForest_10trees with 5-fold cross-validation...\n",
      "drf Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training RandomForest_50trees with 5-fold cross-validation...\n",
      "drf Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Training super learner:\n",
      "\n",
      "stackedensemble Model Build progress: |██████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Base learners' results:\n",
      "\n",
      "    LogisticRegression_binomial - F1-Score: 0.9125, AUC-PR: 0.9597, Accuracy (Test Set): 0.9251\n",
      "    RandomForest_10trees - F1-Score: 0.9235, AUC-PR: 0.9688, Accuracy (Test Set): 0.9370\n",
      "    RandomForest_50trees - F1-Score: 0.9375, AUC-PR: 0.9790, Accuracy (Test Set): 0.9479\n",
      "\n",
      ">>> Metalearner's results:\n",
      "\n",
      "    Super Learner - F1-Score: 0.9388, AUC-PR: 0.9797, Accuracy: 0.9479\n",
      "\n",
      ">>> Training base learners:\n",
      "\n",
      "    Training LogisticRegression_binomial with 5-fold cross-validation...\n",
      "glm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training RandomForest_10trees with 5-fold cross-validation...\n",
      "drf Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Training super learner:\n",
      "\n",
      "stackedensemble Model Build progress: |██████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Base learners' results:\n",
      "\n",
      "    LogisticRegression_binomial - F1-Score: 0.9125, AUC-PR: 0.9597, Accuracy (Test Set): 0.9251\n",
      "    RandomForest_10trees - F1-Score: 0.9235, AUC-PR: 0.9688, Accuracy (Test Set): 0.9370\n",
      "\n",
      ">>> Metalearner's results:\n",
      "\n",
      "    Super Learner - F1-Score: 0.9294, AUC-PR: 0.9759, Accuracy: 0.9403\n",
      "\n",
      ">>> Training base learners:\n",
      "\n",
      "    Training LogisticRegression_binomial with 5-fold cross-validation...\n",
      "glm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training RandomForest_10trees with 5-fold cross-validation...\n",
      "drf Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training RandomForest_10trees_unbounded_D with 5-fold cross-validation...\n",
      "drf Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Training super learner:\n",
      "\n",
      "stackedensemble Model Build progress: |██████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Base learners' results:\n",
      "\n",
      "    LogisticRegression_binomial - F1-Score: 0.9125, AUC-PR: 0.9597, Accuracy (Test Set): 0.9251\n",
      "    RandomForest_10trees - F1-Score: 0.9235, AUC-PR: 0.9688, Accuracy (Test Set): 0.9370\n",
      "    RandomForest_10trees_unbounded_D - F1-Score: 0.9300, AUC-PR: 0.9756, Accuracy (Test Set): 0.9425\n",
      "\n",
      ">>> Metalearner's results:\n",
      "\n",
      "    Super Learner - F1-Score: 0.9352, AUC-PR: 0.9813, Accuracy: 0.9457\n",
      "\n",
      ">>> Training base learners:\n",
      "\n",
      "    Training LogisticRegression_binomial with 5-fold cross-validation...\n",
      "glm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training RandomForest_10trees_unbounded_D with 5-fold cross-validation...\n",
      "drf Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Training super learner:\n",
      "\n",
      "stackedensemble Model Build progress: |██████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Base learners' results:\n",
      "\n",
      "    LogisticRegression_binomial - F1-Score: 0.9125, AUC-PR: 0.9597, Accuracy (Test Set): 0.9251\n",
      "    RandomForest_10trees_unbounded_D - F1-Score: 0.9300, AUC-PR: 0.9756, Accuracy (Test Set): 0.9425\n",
      "\n",
      ">>> Metalearner's results:\n",
      "\n",
      "    Super Learner - F1-Score: 0.9352, AUC-PR: 0.9813, Accuracy: 0.9457\n",
      "\n",
      ">>> Training base learners:\n",
      "\n",
      "    Training LogisticRegression_binomial with 5-fold cross-validation...\n",
      "glm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training RandomForest_10trees_unbounded_D with 5-fold cross-validation...\n",
      "drf Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training RandomForest_20trees_unbounded_D with 5-fold cross-validation...\n",
      "drf Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Training super learner:\n",
      "\n",
      "stackedensemble Model Build progress: |██████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Base learners' results:\n",
      "\n",
      "    LogisticRegression_binomial - F1-Score: 0.9125, AUC-PR: 0.9597, Accuracy (Test Set): 0.9251\n",
      "    RandomForest_10trees_unbounded_D - F1-Score: 0.9300, AUC-PR: 0.9756, Accuracy (Test Set): 0.9425\n",
      "    RandomForest_20trees_unbounded_D - F1-Score: 0.9429, AUC-PR: 0.9824, Accuracy (Test Set): 0.9522\n",
      "\n",
      ">>> Metalearner's results:\n",
      "\n",
      "    Super Learner - F1-Score: 0.9418, AUC-PR: 0.9833, Accuracy: 0.9490\n",
      "\n",
      ">>> Training base learners:\n",
      "\n",
      "    Training LogisticRegression_binomial with 5-fold cross-validation...\n",
      "glm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training RandomForest_10trees_unbounded_D with 5-fold cross-validation...\n",
      "drf Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training RandomForest_20trees_unbounded_D with 5-fold cross-validation...\n",
      "drf Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training RandomForest_50trees_unbounded_D with 5-fold cross-validation...\n",
      "drf Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Training super learner:\n",
      "\n",
      "stackedensemble Model Build progress: |██████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Base learners' results:\n",
      "\n",
      "    LogisticRegression_binomial - F1-Score: 0.9125, AUC-PR: 0.9597, Accuracy (Test Set): 0.9251\n",
      "    RandomForest_10trees_unbounded_D - F1-Score: 0.9300, AUC-PR: 0.9756, Accuracy (Test Set): 0.9425\n",
      "    RandomForest_20trees_unbounded_D - F1-Score: 0.9429, AUC-PR: 0.9824, Accuracy (Test Set): 0.9522\n",
      "    RandomForest_50trees_unbounded_D - F1-Score: 0.9501, AUC-PR: 0.9839, Accuracy (Test Set): 0.9577\n",
      "\n",
      ">>> Metalearner's results:\n",
      "\n",
      "    Super Learner - F1-Score: 0.9448, AUC-PR: 0.9841, Accuracy: 0.9533\n"
     ]
    }
   ],
   "source": [
    "comparative_results = dict()\n",
    "\n",
    "for i, stack in enumerate(random_forest_stacks):\n",
    "    comparative_results[i] = train_evaluate_stack(stack, \"glm\", h2o_train, h2o_test, X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "id": "1749f7e4-99db-4fc4-8b28-cec6a96bcd3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'F1-Score': 0.9125475285171102,\n",
       "  'AUC-PR': 0.9597218422898272,\n",
       "  'Accuracy': 0.9250814332247557},\n",
       " 1: {'F1-Score': 0.9293966623876766,\n",
       "  'AUC-PR': 0.9758698759347404,\n",
       "  'Accuracy': 0.9402823018458197},\n",
       " 2: {'F1-Score': 0.9340232858990944,\n",
       "  'AUC-PR': 0.9757153213406631,\n",
       "  'Accuracy': 0.9446254071661238},\n",
       " 3: {'F1-Score': 0.9387755102040817,\n",
       "  'AUC-PR': 0.9795668851614707,\n",
       "  'Accuracy': 0.9478827361563518},\n",
       " 4: {'F1-Score': 0.9387755102040817,\n",
       "  'AUC-PR': 0.9796881186326951,\n",
       "  'Accuracy': 0.9478827361563518},\n",
       " 5: {'F1-Score': 0.9293966623876766,\n",
       "  'AUC-PR': 0.9758698759347404,\n",
       "  'Accuracy': 0.9402823018458197},\n",
       " 6: {'F1-Score': 0.9352331606217616,\n",
       "  'AUC-PR': 0.9813380626444366,\n",
       "  'Accuracy': 0.9457111834961998},\n",
       " 7: {'F1-Score': 0.9352331606217616,\n",
       "  'AUC-PR': 0.9813341873888645,\n",
       "  'Accuracy': 0.9457111834961998},\n",
       " 8: {'F1-Score': 0.9417596034696407,\n",
       "  'AUC-PR': 0.9833251110322214,\n",
       "  'Accuracy': 0.9489685124864278},\n",
       " 9: {'F1-Score': 0.9448010269576379,\n",
       "  'AUC-PR': 0.9840776825669,\n",
       "  'Accuracy': 0.9533116178067318}}"
      ]
     },
     "execution_count": 596,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparative_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "id": "a10f51af-62a2-4315-a566-722d4d8a6d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_to_complex01 = {                   \n",
    "    \"NaiveBayes\": H2ONaiveBayesEstimator(nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True)\n",
    "}\n",
    "\n",
    "simple_to_complex02 = {                   \n",
    "    \"NaiveBayes\": H2ONaiveBayesEstimator(nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True), \n",
    "    \"RandomForest_10trees\": H2ORandomForestEstimator(\n",
    "                        ntrees=10, max_depth=10, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "                    ),   \n",
    "}\n",
    "\n",
    "simple_to_complex03 = {                   \n",
    "    \"NaiveBayes\": H2ONaiveBayesEstimator(nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True), \n",
    "    \"RandomForest_10trees\": H2ORandomForestEstimator(\n",
    "                        ntrees=10, max_depth=10, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "                    ),   \n",
    "    \"RandomForest_20trees\": H2ORandomForestEstimator(\n",
    "    ntrees=20, max_depth=10, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "),\n",
    "}\n",
    "\n",
    "simple_to_complex04= {                   \n",
    "    \"NaiveBayes\": H2ONaiveBayesEstimator(nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True), \n",
    "    \"RandomForest_10trees\": H2ORandomForestEstimator(\n",
    "                        ntrees=10, max_depth=10, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "                    ),   \n",
    "    \"RandomForest_20trees\": H2ORandomForestEstimator(\n",
    "    ntrees=20, max_depth=10, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "),\n",
    "    \"RandomForest_50trees\": H2ORandomForestEstimator(\n",
    "    ntrees=50, max_depth=10, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "),\n",
    "}\n",
    "\n",
    "\n",
    "simple_to_complex05 = {                   \n",
    "   \"NaiveBayes\": H2ONaiveBayesEstimator(nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True), \n",
    "    \"RandomForest_10trees\": H2ORandomForestEstimator(\n",
    "                        ntrees=10, max_depth=10, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "                    ),   \n",
    "    \"RandomForest_50trees\": H2ORandomForestEstimator(\n",
    "    ntrees=50, max_depth=10, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "),\n",
    "}\n",
    "\n",
    "\n",
    "simple_to_complex06 = {                   \n",
    "    \"NaiveBayes\": H2ONaiveBayesEstimator(nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True), \n",
    "    \"RandomForest_10trees\": H2ORandomForestEstimator(\n",
    "                        ntrees=10, max_depth=10, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "                    ),   \n",
    "}\n",
    "\n",
    "\n",
    "simple_to_complex07 = {                   \n",
    "    \"NaiveBayes\": H2ONaiveBayesEstimator(nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True), \n",
    "    \"RandomForest_10trees\": H2ORandomForestEstimator(\n",
    "                    ntrees=10, max_depth=10, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "                ),   \n",
    "    \"RandomForest_10trees_unbounded_D\": H2ORandomForestEstimator(\n",
    "        ntrees=10, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "    ),\n",
    "}\n",
    "\n",
    "\n",
    "simple_to_complex08 = {                   \n",
    "    \"NaiveBayes\": H2ONaiveBayesEstimator(nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True), \n",
    "    \"RandomForest_10trees_unbounded_D\": H2ORandomForestEstimator(\n",
    "        ntrees=10, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "    ),\n",
    "}\n",
    "\n",
    "\n",
    "simple_to_complex09 = {                   \n",
    "    \"NaiveBayes\": H2ONaiveBayesEstimator(nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True), \n",
    "    \"RandomForest_10trees_unbounded_D\": H2ORandomForestEstimator(\n",
    "        ntrees=10, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "    ),\n",
    "    \"RandomForest_20trees_unbounded_D\": H2ORandomForestEstimator(\n",
    "    ntrees=20, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "),\n",
    "}\n",
    "\n",
    "simple_to_complex10 = {                   \n",
    "    \"NaiveBayes\": H2ONaiveBayesEstimator(nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True), \n",
    "    \"RandomForest_10trees_unbounded_D\": H2ORandomForestEstimator(\n",
    "        ntrees=10, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "    ),\n",
    "    \"RandomForest_20trees_unbounded_D\": H2ORandomForestEstimator(\n",
    "    ntrees=20, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "),\n",
    "    \"RandomForest_50trees_unbounded_D\": H2ORandomForestEstimator(\n",
    "    ntrees=50, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "),\n",
    "}\n",
    "\n",
    "random_forest_stacks_nbayes = [\n",
    "                        simple_to_complex01,\n",
    "                        simple_to_complex02,\n",
    "                        simple_to_complex03,\n",
    "                        simple_to_complex04,\n",
    "                        simple_to_complex05,\n",
    "                        simple_to_complex06,\n",
    "                        simple_to_complex07,\n",
    "                        simple_to_complex08,\n",
    "                        simple_to_complex09,\n",
    "                        simple_to_complex10\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "id": "cee605ff-77d9-4b9a-bae2-c5b189c734ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Training base learners:\n",
      "\n",
      "    Training NaiveBayes with 5-fold cross-validation...\n",
      "naivebayes Model Build progress: |███████████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Training super learner:\n",
      "\n",
      "stackedensemble Model Build progress: |██████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Base learners' results:\n",
      "\n",
      "    NaiveBayes - F1-Score: 0.8303, AUC-PR: 0.8182, Accuracy (Test Set): 0.8588\n",
      "\n",
      ">>> Metalearner's results:\n",
      "\n",
      "    Super Learner - F1-Score: 0.8303, AUC-PR: 0.8156, Accuracy: 0.8588\n",
      "\n",
      ">>> Training base learners:\n",
      "\n",
      "    Training NaiveBayes with 5-fold cross-validation...\n",
      "naivebayes Model Build progress: |███████████████████████████████████████████████| (done) 100%\n",
      "    Training RandomForest_10trees with 5-fold cross-validation...\n",
      "drf Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Training super learner:\n",
      "\n",
      "stackedensemble Model Build progress: |██████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Base learners' results:\n",
      "\n",
      "    NaiveBayes - F1-Score: 0.8303, AUC-PR: 0.8182, Accuracy (Test Set): 0.8588\n",
      "    RandomForest_10trees - F1-Score: 0.9235, AUC-PR: 0.9688, Accuracy (Test Set): 0.9370\n",
      "\n",
      ">>> Metalearner's results:\n",
      "\n",
      "    Super Learner - F1-Score: 0.9273, AUC-PR: 0.9717, Accuracy: 0.9370\n",
      "\n",
      ">>> Training base learners:\n",
      "\n",
      "    Training NaiveBayes with 5-fold cross-validation...\n",
      "naivebayes Model Build progress: |███████████████████████████████████████████████| (done) 100%\n",
      "    Training RandomForest_10trees with 5-fold cross-validation...\n",
      "drf Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training RandomForest_20trees with 5-fold cross-validation...\n",
      "drf Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Training super learner:\n",
      "\n",
      "stackedensemble Model Build progress: |██████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Base learners' results:\n",
      "\n",
      "    NaiveBayes - F1-Score: 0.8303, AUC-PR: 0.8182, Accuracy (Test Set): 0.8588\n",
      "    RandomForest_10trees - F1-Score: 0.9235, AUC-PR: 0.9688, Accuracy (Test Set): 0.9370\n",
      "    RandomForest_20trees - F1-Score: 0.9291, AUC-PR: 0.9722, Accuracy (Test Set): 0.9403\n",
      "\n",
      ">>> Metalearner's results:\n",
      "\n",
      "    Super Learner - F1-Score: 0.9323, AUC-PR: 0.9736, Accuracy: 0.9414\n",
      "\n",
      ">>> Training base learners:\n",
      "\n",
      "    Training NaiveBayes with 5-fold cross-validation...\n",
      "naivebayes Model Build progress: |███████████████████████████████████████████████| (done) 100%\n",
      "    Training RandomForest_10trees with 5-fold cross-validation...\n",
      "drf Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training RandomForest_20trees with 5-fold cross-validation...\n",
      "drf Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training RandomForest_50trees with 5-fold cross-validation...\n",
      "drf Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Training super learner:\n",
      "\n",
      "stackedensemble Model Build progress: |██████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Base learners' results:\n",
      "\n",
      "    NaiveBayes - F1-Score: 0.8303, AUC-PR: 0.8182, Accuracy (Test Set): 0.8588\n",
      "    RandomForest_10trees - F1-Score: 0.9235, AUC-PR: 0.9688, Accuracy (Test Set): 0.9370\n",
      "    RandomForest_20trees - F1-Score: 0.9291, AUC-PR: 0.9722, Accuracy (Test Set): 0.9403\n",
      "    RandomForest_50trees - F1-Score: 0.9375, AUC-PR: 0.9790, Accuracy (Test Set): 0.9479\n",
      "\n",
      ">>> Metalearner's results:\n",
      "\n",
      "    Super Learner - F1-Score: 0.9373, AUC-PR: 0.9801, Accuracy: 0.9479\n",
      "\n",
      ">>> Training base learners:\n",
      "\n",
      "    Training NaiveBayes with 5-fold cross-validation...\n",
      "naivebayes Model Build progress: |███████████████████████████████████████████████| (done) 100%\n",
      "    Training RandomForest_10trees with 5-fold cross-validation...\n",
      "drf Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training RandomForest_50trees with 5-fold cross-validation...\n",
      "drf Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Training super learner:\n",
      "\n",
      "stackedensemble Model Build progress: |██████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Base learners' results:\n",
      "\n",
      "    NaiveBayes - F1-Score: 0.8303, AUC-PR: 0.8182, Accuracy (Test Set): 0.8588\n",
      "    RandomForest_10trees - F1-Score: 0.9235, AUC-PR: 0.9688, Accuracy (Test Set): 0.9370\n",
      "    RandomForest_50trees - F1-Score: 0.9375, AUC-PR: 0.9790, Accuracy (Test Set): 0.9479\n",
      "\n",
      ">>> Metalearner's results:\n",
      "\n",
      "    Super Learner - F1-Score: 0.9384, AUC-PR: 0.9803, Accuracy: 0.9490\n",
      "\n",
      ">>> Training base learners:\n",
      "\n",
      "    Training NaiveBayes with 5-fold cross-validation...\n",
      "naivebayes Model Build progress: |███████████████████████████████████████████████| (done) 100%\n",
      "    Training RandomForest_10trees with 5-fold cross-validation...\n",
      "drf Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Training super learner:\n",
      "\n",
      "stackedensemble Model Build progress: |██████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Base learners' results:\n",
      "\n",
      "    NaiveBayes - F1-Score: 0.8303, AUC-PR: 0.8182, Accuracy (Test Set): 0.8588\n",
      "    RandomForest_10trees - F1-Score: 0.9235, AUC-PR: 0.9688, Accuracy (Test Set): 0.9370\n",
      "\n",
      ">>> Metalearner's results:\n",
      "\n",
      "    Super Learner - F1-Score: 0.9273, AUC-PR: 0.9717, Accuracy: 0.9370\n",
      "\n",
      ">>> Training base learners:\n",
      "\n",
      "    Training NaiveBayes with 5-fold cross-validation...\n",
      "naivebayes Model Build progress: |███████████████████████████████████████████████| (done) 100%\n",
      "    Training RandomForest_10trees with 5-fold cross-validation...\n",
      "drf Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training RandomForest_10trees_unbounded_D with 5-fold cross-validation...\n",
      "drf Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Training super learner:\n",
      "\n",
      "stackedensemble Model Build progress: |██████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Base learners' results:\n",
      "\n",
      "    NaiveBayes - F1-Score: 0.8303, AUC-PR: 0.8182, Accuracy (Test Set): 0.8588\n",
      "    RandomForest_10trees - F1-Score: 0.9235, AUC-PR: 0.9688, Accuracy (Test Set): 0.9370\n",
      "    RandomForest_10trees_unbounded_D - F1-Score: 0.9300, AUC-PR: 0.9756, Accuracy (Test Set): 0.9425\n",
      "\n",
      ">>> Metalearner's results:\n",
      "\n",
      "    Super Learner - F1-Score: 0.9342, AUC-PR: 0.9721, Accuracy: 0.9446\n",
      "\n",
      ">>> Training base learners:\n",
      "\n",
      "    Training NaiveBayes with 5-fold cross-validation...\n",
      "naivebayes Model Build progress: |███████████████████████████████████████████████| (done) 100%\n",
      "    Training RandomForest_10trees_unbounded_D with 5-fold cross-validation...\n",
      "drf Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Training super learner:\n",
      "\n",
      "stackedensemble Model Build progress: |██████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Base learners' results:\n",
      "\n",
      "    NaiveBayes - F1-Score: 0.8303, AUC-PR: 0.8182, Accuracy (Test Set): 0.8588\n",
      "    RandomForest_10trees_unbounded_D - F1-Score: 0.9300, AUC-PR: 0.9756, Accuracy (Test Set): 0.9425\n",
      "\n",
      ">>> Metalearner's results:\n",
      "\n",
      "    Super Learner - F1-Score: 0.9339, AUC-PR: 0.9781, Accuracy: 0.9446\n",
      "\n",
      ">>> Training base learners:\n",
      "\n",
      "    Training NaiveBayes with 5-fold cross-validation...\n",
      "naivebayes Model Build progress: |███████████████████████████████████████████████| (done) 100%\n",
      "    Training RandomForest_10trees_unbounded_D with 5-fold cross-validation...\n",
      "drf Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training RandomForest_20trees_unbounded_D with 5-fold cross-validation...\n",
      "drf Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Training super learner:\n",
      "\n",
      "stackedensemble Model Build progress: |██████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Base learners' results:\n",
      "\n",
      "    NaiveBayes - F1-Score: 0.8303, AUC-PR: 0.8182, Accuracy (Test Set): 0.8588\n",
      "    RandomForest_10trees_unbounded_D - F1-Score: 0.9300, AUC-PR: 0.9756, Accuracy (Test Set): 0.9425\n",
      "    RandomForest_20trees_unbounded_D - F1-Score: 0.9429, AUC-PR: 0.9824, Accuracy (Test Set): 0.9522\n",
      "\n",
      ">>> Metalearner's results:\n",
      "\n",
      "    Super Learner - F1-Score: 0.9410, AUC-PR: 0.9834, Accuracy: 0.9501\n",
      "\n",
      ">>> Training base learners:\n",
      "\n",
      "    Training NaiveBayes with 5-fold cross-validation...\n",
      "naivebayes Model Build progress: |███████████████████████████████████████████████| (done) 100%\n",
      "    Training RandomForest_10trees_unbounded_D with 5-fold cross-validation...\n",
      "drf Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training RandomForest_20trees_unbounded_D with 5-fold cross-validation...\n",
      "drf Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training RandomForest_50trees_unbounded_D with 5-fold cross-validation...\n",
      "drf Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Training super learner:\n",
      "\n",
      "stackedensemble Model Build progress: |██████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Base learners' results:\n",
      "\n",
      "    NaiveBayes - F1-Score: 0.8303, AUC-PR: 0.8182, Accuracy (Test Set): 0.8588\n",
      "    RandomForest_10trees_unbounded_D - F1-Score: 0.9300, AUC-PR: 0.9756, Accuracy (Test Set): 0.9425\n",
      "    RandomForest_20trees_unbounded_D - F1-Score: 0.9429, AUC-PR: 0.9824, Accuracy (Test Set): 0.9522\n",
      "    RandomForest_50trees_unbounded_D - F1-Score: 0.9501, AUC-PR: 0.9839, Accuracy (Test Set): 0.9577\n",
      "\n",
      ">>> Metalearner's results:\n",
      "\n",
      "    Super Learner - F1-Score: 0.9456, AUC-PR: 0.9849, Accuracy: 0.9544\n"
     ]
    }
   ],
   "source": [
    "comparative_results_rf_nbayes = dict()\n",
    "\n",
    "for i, stack in enumerate(random_forest_stacks_nbayes):\n",
    "    comparative_results_rf_nbayes[i] = train_evaluate_stack(stack, \"glm\", h2o_train, h2o_test, X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "id": "dfea2fb9-5307-444c-bd74-0ddd2b744670",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'F1-Score': 0.8302872062663186,\n",
       "  'AUC-PR': 0.8156212228909406,\n",
       "  'Accuracy': 0.8588490770901195},\n",
       " 1: {'F1-Score': 0.9272503082614056,\n",
       "  'AUC-PR': 0.9717393268505077,\n",
       "  'Accuracy': 0.9370249728555917},\n",
       " 2: {'F1-Score': 0.9323308270676691,\n",
       "  'AUC-PR': 0.9735836638851284,\n",
       "  'Accuracy': 0.9413680781758957},\n",
       " 3: {'F1-Score': 0.9373368146214098,\n",
       "  'AUC-PR': 0.9801066804200346,\n",
       "  'Accuracy': 0.9478827361563518},\n",
       " 4: {'F1-Score': 0.9384010484927915,\n",
       "  'AUC-PR': 0.9802906334378295,\n",
       "  'Accuracy': 0.9489685124864278},\n",
       " 5: {'F1-Score': 0.9272503082614056,\n",
       "  'AUC-PR': 0.9717393268505077,\n",
       "  'Accuracy': 0.9370249728555917},\n",
       " 6: {'F1-Score': 0.9341935483870969,\n",
       "  'AUC-PR': 0.9721179310626975,\n",
       "  'Accuracy': 0.9446254071661238},\n",
       " 7: {'F1-Score': 0.9338521400778211,\n",
       "  'AUC-PR': 0.9781291721202493,\n",
       "  'Accuracy': 0.9446254071661238},\n",
       " 8: {'F1-Score': 0.941025641025641,\n",
       "  'AUC-PR': 0.9834072699744336,\n",
       "  'Accuracy': 0.9500542888165038},\n",
       " 9: {'F1-Score': 0.9455958549222797,\n",
       "  'AUC-PR': 0.9848639416777758,\n",
       "  'Accuracy': 0.9543973941368078}}"
      ]
     },
     "execution_count": 606,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparative_results_rf_nbayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331277c3-9d0c-49d7-b18c-e7ef442e168f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c982a3-4b6a-4557-80a1-2186423abb4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "id": "6a3c163d-2c4f-4d80-9e9f-95eb602b1ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_to_complex01 = {                   \n",
    "    \"LogisticRegression_binomial\": H2OGeneralizedLinearEstimator(\n",
    "                        family=\"binomial\", nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "                    ), \n",
    "}\n",
    "\n",
    "simple_to_complex02 = {                   \n",
    "    \"LogisticRegression_binomial\": H2OGeneralizedLinearEstimator(\n",
    "                        family=\"binomial\", nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "                    ), \n",
    "    \"GradientBoosting_10trees\": H2OGradientBoostingEstimator(\n",
    "                        ntrees=10, max_depth=10, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "                    ),   \n",
    "}\n",
    "\n",
    "simple_to_complex03 = {                   \n",
    "    \"LogisticRegression_binomial\": H2OGeneralizedLinearEstimator(\n",
    "                        family=\"binomial\", nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "                    ), \n",
    "    \"GradientBoosting_10trees\": H2OGradientBoostingEstimator(\n",
    "                        ntrees=10, max_depth=10, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "                    ),   \n",
    "    \"GradientBoosting_20trees\": H2OGradientBoostingEstimator(\n",
    "    ntrees=20, max_depth=10, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "),\n",
    "}\n",
    "\n",
    "simple_to_complex04= {                   \n",
    "    \"LogisticRegression_binomial\": H2OGeneralizedLinearEstimator(\n",
    "                        family=\"binomial\", nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "                    ), \n",
    "    \"GradientBoosting_10trees\": H2OGradientBoostingEstimator(\n",
    "                        ntrees=10, max_depth=10, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "                    ),   \n",
    "    \"GradientBoosting_20trees\": H2OGradientBoostingEstimator(\n",
    "    ntrees=20, max_depth=10, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "),\n",
    "    \"GradientBoosting_50trees\": H2OGradientBoostingEstimator(\n",
    "    ntrees=50, max_depth=10, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "),\n",
    "}\n",
    "\n",
    "\n",
    "simple_to_complex05 = {                   \n",
    "    \"LogisticRegression_binomial\": H2OGeneralizedLinearEstimator(\n",
    "                        family=\"binomial\", nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "                    ), \n",
    "    \"GradientBoosting_10trees\": H2OGradientBoostingEstimator(\n",
    "                        ntrees=10, max_depth=10, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "                    ),   \n",
    "    \"GradientBoosting_50trees\": H2OGradientBoostingEstimator(\n",
    "    ntrees=50, max_depth=10, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "),\n",
    "}\n",
    "\n",
    "\n",
    "simple_to_complex06 = {                   \n",
    "    \"LogisticRegression_binomial\": H2OGeneralizedLinearEstimator(\n",
    "                        family=\"binomial\", nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "                    ), \n",
    "    \"GradientBoosting_10trees\": H2OGradientBoostingEstimator(\n",
    "                        ntrees=10, max_depth=10, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "                    ),   \n",
    "}\n",
    "\n",
    "\n",
    "simple_to_complex07 = {                   \n",
    "    \"LogisticRegression_binomial\": H2OGeneralizedLinearEstimator(\n",
    "                        family=\"binomial\", nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "                    ), \n",
    "    \"GradientBoosting_10trees\": H2OGradientBoostingEstimator(\n",
    "                    ntrees=10, max_depth=10, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "                ),   \n",
    "    \"GradientBoosting_10trees_unbounded_D\": H2OGradientBoostingEstimator(\n",
    "        ntrees=10, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "    ),\n",
    "}\n",
    "\n",
    "\n",
    "simple_to_complex08 = {                   \n",
    "    \"LogisticRegression_binomial\": H2OGeneralizedLinearEstimator(\n",
    "                        family=\"binomial\", nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "                    ), \n",
    "    \"GradientBoosting_10trees_unbounded_D\": H2OGradientBoostingEstimator(\n",
    "        ntrees=10, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "    ),\n",
    "}\n",
    "\n",
    "\n",
    "simple_to_complex09 = {                   \n",
    "    \"LogisticRegression_binomial\": H2OGeneralizedLinearEstimator(\n",
    "                        family=\"binomial\", nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "                    ), \n",
    "    \"GradientBoosting_10trees_unbounded_D\": H2OGradientBoostingEstimator(\n",
    "        ntrees=10, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "    ),\n",
    "    \"GradientBoosting_20trees_unbounded_D\": H2OGradientBoostingEstimator(\n",
    "    ntrees=20, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "),\n",
    "}\n",
    "\n",
    "simple_to_complex10 = {                   \n",
    "    \"LogisticRegression_binomial\": H2OGeneralizedLinearEstimator(\n",
    "                        family=\"binomial\", nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "                    ), \n",
    "    \"GradientBoosting_10trees_unbounded_D\": H2OGradientBoostingEstimator(\n",
    "        ntrees=10, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "    ),\n",
    "    \"GradientBoosting_20trees_unbounded_D\": H2OGradientBoostingEstimator(\n",
    "    ntrees=20, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "),\n",
    "    \"GradientBoosting_50trees_unbounded_D\": H2OGradientBoostingEstimator(\n",
    "    ntrees=50, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "),\n",
    "}\n",
    "\n",
    "gradient_boosting_stacks = [\n",
    "                        simple_to_complex01,\n",
    "                        simple_to_complex02,\n",
    "                        simple_to_complex03,\n",
    "                        simple_to_complex04,\n",
    "                        simple_to_complex05,\n",
    "                        simple_to_complex06,\n",
    "                        simple_to_complex07,\n",
    "                        simple_to_complex08,\n",
    "                        simple_to_complex09,\n",
    "                        simple_to_complex10\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "id": "df9e2da1-4fd3-4ba1-a771-05c08ebe5ab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Training base learners:\n",
      "\n",
      "    Training LogisticRegression_binomial with 5-fold cross-validation...\n",
      "glm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Training super learner:\n",
      "\n",
      "stackedensemble Model Build progress: |██████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Base learners' results:\n",
      "\n",
      "    LogisticRegression_binomial - F1-Score: 0.9125, AUC-PR: 0.9597, Accuracy (Test Set): 0.9251\n",
      "\n",
      ">>> Metalearner's results:\n",
      "\n",
      "    Super Learner - F1-Score: 0.9125, AUC-PR: 0.9597, Accuracy: 0.9251\n",
      "\n",
      ">>> Training base learners:\n",
      "\n",
      "    Training LogisticRegression_binomial with 5-fold cross-validation...\n",
      "glm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting_10trees with 5-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Training super learner:\n",
      "\n",
      "stackedensemble Model Build progress: |██████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Base learners' results:\n",
      "\n",
      "    LogisticRegression_binomial - F1-Score: 0.9125, AUC-PR: 0.9597, Accuracy (Test Set): 0.9251\n",
      "    GradientBoosting_10trees - F1-Score: 0.9167, AUC-PR: 0.9730, Accuracy (Test Set): 0.9316\n",
      "\n",
      ">>> Metalearner's results:\n",
      "\n",
      "    Super Learner - F1-Score: 0.9318, AUC-PR: 0.9781, Accuracy: 0.9435\n",
      "\n",
      ">>> Training base learners:\n",
      "\n",
      "    Training LogisticRegression_binomial with 5-fold cross-validation...\n",
      "glm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting_10trees with 5-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting_20trees with 5-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Training super learner:\n",
      "\n",
      "stackedensemble Model Build progress: |██████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Base learners' results:\n",
      "\n",
      "    LogisticRegression_binomial - F1-Score: 0.9125, AUC-PR: 0.9597, Accuracy (Test Set): 0.9251\n",
      "    GradientBoosting_10trees - F1-Score: 0.9167, AUC-PR: 0.9730, Accuracy (Test Set): 0.9316\n",
      "    GradientBoosting_20trees - F1-Score: 0.9326, AUC-PR: 0.9790, Accuracy (Test Set): 0.9446\n",
      "\n",
      ">>> Metalearner's results:\n",
      "\n",
      "    Super Learner - F1-Score: 0.9404, AUC-PR: 0.9822, Accuracy: 0.9501\n",
      "\n",
      ">>> Training base learners:\n",
      "\n",
      "    Training LogisticRegression_binomial with 5-fold cross-validation...\n",
      "glm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting_10trees with 5-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting_20trees with 5-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting_50trees with 5-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Training super learner:\n",
      "\n",
      "stackedensemble Model Build progress: |██████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Base learners' results:\n",
      "\n",
      "    LogisticRegression_binomial - F1-Score: 0.9125, AUC-PR: 0.9597, Accuracy (Test Set): 0.9251\n",
      "    GradientBoosting_10trees - F1-Score: 0.9167, AUC-PR: 0.9730, Accuracy (Test Set): 0.9316\n",
      "    GradientBoosting_20trees - F1-Score: 0.9326, AUC-PR: 0.9790, Accuracy (Test Set): 0.9446\n",
      "    GradientBoosting_50trees - F1-Score: 0.9447, AUC-PR: 0.9858, Accuracy (Test Set): 0.9544\n",
      "\n",
      ">>> Metalearner's results:\n",
      "\n",
      "    Super Learner - F1-Score: 0.9491, AUC-PR: 0.9856, Accuracy: 0.9566\n",
      "\n",
      ">>> Training base learners:\n",
      "\n",
      "    Training LogisticRegression_binomial with 5-fold cross-validation...\n",
      "glm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting_10trees with 5-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting_50trees with 5-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Training super learner:\n",
      "\n",
      "stackedensemble Model Build progress: |██████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Base learners' results:\n",
      "\n",
      "    LogisticRegression_binomial - F1-Score: 0.9125, AUC-PR: 0.9597, Accuracy (Test Set): 0.9251\n",
      "    GradientBoosting_10trees - F1-Score: 0.9167, AUC-PR: 0.9730, Accuracy (Test Set): 0.9316\n",
      "    GradientBoosting_50trees - F1-Score: 0.9447, AUC-PR: 0.9858, Accuracy (Test Set): 0.9544\n",
      "\n",
      ">>> Metalearner's results:\n",
      "\n",
      "    Super Learner - F1-Score: 0.9491, AUC-PR: 0.9857, Accuracy: 0.9566\n",
      "\n",
      ">>> Training base learners:\n",
      "\n",
      "    Training LogisticRegression_binomial with 5-fold cross-validation...\n",
      "glm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting_10trees with 5-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Training super learner:\n",
      "\n",
      "stackedensemble Model Build progress: |██████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Base learners' results:\n",
      "\n",
      "    LogisticRegression_binomial - F1-Score: 0.9125, AUC-PR: 0.9597, Accuracy (Test Set): 0.9251\n",
      "    GradientBoosting_10trees - F1-Score: 0.9167, AUC-PR: 0.9730, Accuracy (Test Set): 0.9316\n",
      "\n",
      ">>> Metalearner's results:\n",
      "\n",
      "    Super Learner - F1-Score: 0.9318, AUC-PR: 0.9781, Accuracy: 0.9435\n",
      "\n",
      ">>> Training base learners:\n",
      "\n",
      "    Training LogisticRegression_binomial with 5-fold cross-validation...\n",
      "glm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting_10trees with 5-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting_10trees_unbounded_D with 5-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Training super learner:\n",
      "\n",
      "stackedensemble Model Build progress: |██████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Base learners' results:\n",
      "\n",
      "    LogisticRegression_binomial - F1-Score: 0.9125, AUC-PR: 0.9597, Accuracy (Test Set): 0.9251\n",
      "    GradientBoosting_10trees - F1-Score: 0.9167, AUC-PR: 0.9730, Accuracy (Test Set): 0.9316\n",
      "    GradientBoosting_10trees_unbounded_D - F1-Score: 0.9157, AUC-PR: 0.9698, Accuracy (Test Set): 0.9294\n",
      "\n",
      ">>> Metalearner's results:\n",
      "\n",
      "    Super Learner - F1-Score: 0.9318, AUC-PR: 0.9784, Accuracy: 0.9435\n",
      "\n",
      ">>> Training base learners:\n",
      "\n",
      "    Training LogisticRegression_binomial with 5-fold cross-validation...\n",
      "glm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting_10trees_unbounded_D with 5-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Training super learner:\n",
      "\n",
      "stackedensemble Model Build progress: |██████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Base learners' results:\n",
      "\n",
      "    LogisticRegression_binomial - F1-Score: 0.9125, AUC-PR: 0.9597, Accuracy (Test Set): 0.9251\n",
      "    GradientBoosting_10trees_unbounded_D - F1-Score: 0.9157, AUC-PR: 0.9698, Accuracy (Test Set): 0.9294\n",
      "\n",
      ">>> Metalearner's results:\n",
      "\n",
      "    Super Learner - F1-Score: 0.9302, AUC-PR: 0.9766, Accuracy: 0.9414\n",
      "\n",
      ">>> Training base learners:\n",
      "\n",
      "    Training LogisticRegression_binomial with 5-fold cross-validation...\n",
      "glm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting_10trees_unbounded_D with 5-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting_20trees_unbounded_D with 5-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Training super learner:\n",
      "\n",
      "stackedensemble Model Build progress: |██████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Base learners' results:\n",
      "\n",
      "    LogisticRegression_binomial - F1-Score: 0.9125, AUC-PR: 0.9597, Accuracy (Test Set): 0.9251\n",
      "    GradientBoosting_10trees_unbounded_D - F1-Score: 0.9157, AUC-PR: 0.9698, Accuracy (Test Set): 0.9294\n",
      "    GradientBoosting_20trees_unbounded_D - F1-Score: 0.9272, AUC-PR: 0.9792, Accuracy (Test Set): 0.9403\n",
      "\n",
      ">>> Metalearner's results:\n",
      "\n",
      "    Super Learner - F1-Score: 0.9347, AUC-PR: 0.9813, Accuracy: 0.9446\n",
      "\n",
      ">>> Training base learners:\n",
      "\n",
      "    Training LogisticRegression_binomial with 5-fold cross-validation...\n",
      "glm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting_10trees_unbounded_D with 5-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting_20trees_unbounded_D with 5-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting_50trees_unbounded_D with 5-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Training super learner:\n",
      "\n",
      "stackedensemble Model Build progress: |██████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Base learners' results:\n",
      "\n",
      "    LogisticRegression_binomial - F1-Score: 0.9125, AUC-PR: 0.9597, Accuracy (Test Set): 0.9251\n",
      "    GradientBoosting_10trees_unbounded_D - F1-Score: 0.9157, AUC-PR: 0.9698, Accuracy (Test Set): 0.9294\n",
      "    GradientBoosting_20trees_unbounded_D - F1-Score: 0.9272, AUC-PR: 0.9792, Accuracy (Test Set): 0.9403\n",
      "    GradientBoosting_50trees_unbounded_D - F1-Score: 0.9490, AUC-PR: 0.9848, Accuracy (Test Set): 0.9566\n",
      "\n",
      ">>> Metalearner's results:\n",
      "\n",
      "    Super Learner - F1-Score: 0.9494, AUC-PR: 0.9710, Accuracy: 0.9566\n"
     ]
    }
   ],
   "source": [
    "comparative_results_gb = dict()\n",
    "\n",
    "for i, stack in enumerate(gradient_boosting_stacks):\n",
    "    comparative_results_gb[i] = train_evaluate_stack(stack, \"glm\", h2o_train, h2o_test, X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "id": "0b6a259e-6a32-4c87-a763-593edd286143",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'F1-Score': 0.9125475285171102,\n",
       "  'AUC-PR': 0.9597218422898272,\n",
       "  'Accuracy': 0.9250814332247557},\n",
       " 1: {'F1-Score': 0.931758530183727,\n",
       "  'AUC-PR': 0.9781269287795011,\n",
       "  'Accuracy': 0.9435396308360477},\n",
       " 2: {'F1-Score': 0.9404145077720208,\n",
       "  'AUC-PR': 0.982245293612598,\n",
       "  'Accuracy': 0.9500542888165038},\n",
       " 3: {'F1-Score': 0.9491094147582697,\n",
       "  'AUC-PR': 0.985633926339467,\n",
       "  'Accuracy': 0.9565689467969598},\n",
       " 4: {'F1-Score': 0.9491094147582697,\n",
       "  'AUC-PR': 0.9857138714775479,\n",
       "  'Accuracy': 0.9565689467969598},\n",
       " 5: {'F1-Score': 0.931758530183727,\n",
       "  'AUC-PR': 0.9781269287795011,\n",
       "  'Accuracy': 0.9435396308360477},\n",
       " 6: {'F1-Score': 0.931758530183727,\n",
       "  'AUC-PR': 0.9783592567374547,\n",
       "  'Accuracy': 0.9435396308360477},\n",
       " 7: {'F1-Score': 0.9302325581395349,\n",
       "  'AUC-PR': 0.9766319390181104,\n",
       "  'Accuracy': 0.9413680781758957},\n",
       " 8: {'F1-Score': 0.9346991037131882,\n",
       "  'AUC-PR': 0.9813076643772469,\n",
       "  'Accuracy': 0.9446254071661238},\n",
       " 9: {'F1-Score': 0.9493670886075949,\n",
       "  'AUC-PR': 0.9710341932881718,\n",
       "  'Accuracy': 0.9565689467969598}}"
      ]
     },
     "execution_count": 611,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparative_results_gb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "id": "66fade31-9a20-42fe-a1ec-67d12e2e3d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_to_complex01 = {                   \n",
    "    \"NaiveBayes\": H2ONaiveBayesEstimator(nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True), \n",
    "}\n",
    "\n",
    "simple_to_complex02 = {                   \n",
    "\"NaiveBayes\": H2ONaiveBayesEstimator(nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True), \n",
    "    \"GradientBoosting_10trees\": H2OGradientBoostingEstimator(\n",
    "                        ntrees=10, max_depth=10, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "                    ),   \n",
    "}\n",
    "\n",
    "simple_to_complex03 = {                   \n",
    "\"NaiveBayes\": H2ONaiveBayesEstimator(nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True), \n",
    "    \"GradientBoosting_10trees\": H2OGradientBoostingEstimator(\n",
    "                        ntrees=10, max_depth=10, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "                    ),   \n",
    "    \"GradientBoosting_20trees\": H2OGradientBoostingEstimator(\n",
    "    ntrees=20, max_depth=10, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "),\n",
    "}\n",
    "\n",
    "simple_to_complex04= {                   \n",
    "\"NaiveBayes\": H2ONaiveBayesEstimator(nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True), \n",
    "    \"GradientBoosting_10trees\": H2OGradientBoostingEstimator(\n",
    "                        ntrees=10, max_depth=10, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "                    ),   \n",
    "    \"GradientBoosting_20trees\": H2OGradientBoostingEstimator(\n",
    "    ntrees=20, max_depth=10, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "),\n",
    "    \"GradientBoosting_50trees\": H2OGradientBoostingEstimator(\n",
    "    ntrees=50, max_depth=10, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "),\n",
    "}\n",
    "\n",
    "\n",
    "simple_to_complex05 = {                   \n",
    "\"NaiveBayes\": H2ONaiveBayesEstimator(nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True), \n",
    "    \"GradientBoosting_10trees\": H2OGradientBoostingEstimator(\n",
    "                        ntrees=10, max_depth=10, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "                    ),   \n",
    "    \"GradientBoosting_50trees\": H2OGradientBoostingEstimator(\n",
    "    ntrees=50, max_depth=10, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "),\n",
    "}\n",
    "\n",
    "\n",
    "simple_to_complex06 = {                   \n",
    "\"NaiveBayes\": H2ONaiveBayesEstimator(nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True), \n",
    "    \"GradientBoosting_10trees\": H2OGradientBoostingEstimator(\n",
    "                        ntrees=10, max_depth=10, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "                    ),   \n",
    "}\n",
    "\n",
    "\n",
    "simple_to_complex07 = {                   \n",
    "\"NaiveBayes\": H2ONaiveBayesEstimator(nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True), \n",
    "    \"GradientBoosting_10trees\": H2OGradientBoostingEstimator(\n",
    "                    ntrees=10, max_depth=10, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "                ),   \n",
    "    \"GradientBoosting_10trees_unbounded_D\": H2OGradientBoostingEstimator(\n",
    "        ntrees=10, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "    ),\n",
    "}\n",
    "\n",
    "\n",
    "simple_to_complex08 = {                   \n",
    "\"NaiveBayes\": H2ONaiveBayesEstimator(nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True), \n",
    "    \"GradientBoosting_10trees_unbounded_D\": H2OGradientBoostingEstimator(\n",
    "        ntrees=10, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "    ),\n",
    "}\n",
    "\n",
    "\n",
    "simple_to_complex09 = {                   \n",
    "\"NaiveBayes\": H2ONaiveBayesEstimator(nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True), \n",
    "    \"GradientBoosting_10trees_unbounded_D\": H2OGradientBoostingEstimator(\n",
    "        ntrees=10, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "    ),\n",
    "    \"GradientBoosting_20trees_unbounded_D\": H2OGradientBoostingEstimator(\n",
    "    ntrees=20, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "),\n",
    "}\n",
    "\n",
    "simple_to_complex10 = {                   \n",
    "\"NaiveBayes\": H2ONaiveBayesEstimator(nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True), \n",
    "    \"GradientBoosting_10trees_unbounded_D\": H2OGradientBoostingEstimator(\n",
    "        ntrees=10, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "    ),\n",
    "    \"GradientBoosting_20trees_unbounded_D\": H2OGradientBoostingEstimator(\n",
    "    ntrees=20, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "),\n",
    "    \"GradientBoosting_50trees_unbounded_D\": H2OGradientBoostingEstimator(\n",
    "    ntrees=50, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "),\n",
    "}\n",
    "\n",
    "gradient_boosting_stacks_nbayes = [\n",
    "                        simple_to_complex01,\n",
    "                        simple_to_complex02,\n",
    "                        simple_to_complex03,\n",
    "                        simple_to_complex04,\n",
    "                        simple_to_complex05,\n",
    "                        simple_to_complex06,\n",
    "                        simple_to_complex07,\n",
    "                        simple_to_complex08,\n",
    "                        simple_to_complex09,\n",
    "                        simple_to_complex10\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "id": "1643c5c8-087d-4351-b439-72769152c1e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Training base learners:\n",
      "\n",
      "    Training NaiveBayes with 5-fold cross-validation...\n",
      "naivebayes Model Build progress: |███████████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Training super learner:\n",
      "\n",
      "stackedensemble Model Build progress: |██████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Base learners' results:\n",
      "\n",
      "    NaiveBayes - F1-Score: 0.8303, AUC-PR: 0.8182, Accuracy (Test Set): 0.8588\n",
      "\n",
      ">>> Metalearner's results:\n",
      "\n",
      "    Super Learner - F1-Score: 0.8303, AUC-PR: 0.8156, Accuracy: 0.8588\n",
      "\n",
      ">>> Training base learners:\n",
      "\n",
      "    Training NaiveBayes with 5-fold cross-validation...\n",
      "naivebayes Model Build progress: |███████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting_10trees with 5-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Training super learner:\n",
      "\n",
      "stackedensemble Model Build progress: |██████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Base learners' results:\n",
      "\n",
      "    NaiveBayes - F1-Score: 0.8303, AUC-PR: 0.8182, Accuracy (Test Set): 0.8588\n",
      "    GradientBoosting_10trees - F1-Score: 0.9167, AUC-PR: 0.9730, Accuracy (Test Set): 0.9316\n",
      "\n",
      ">>> Metalearner's results:\n",
      "\n",
      "    Super Learner - F1-Score: 0.9268, AUC-PR: 0.9766, Accuracy: 0.9381\n",
      "\n",
      ">>> Training base learners:\n",
      "\n",
      "    Training NaiveBayes with 5-fold cross-validation...\n",
      "naivebayes Model Build progress: |███████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting_10trees with 5-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting_20trees with 5-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Training super learner:\n",
      "\n",
      "stackedensemble Model Build progress: |██████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Base learners' results:\n",
      "\n",
      "    NaiveBayes - F1-Score: 0.8303, AUC-PR: 0.8182, Accuracy (Test Set): 0.8588\n",
      "    GradientBoosting_10trees - F1-Score: 0.9167, AUC-PR: 0.9730, Accuracy (Test Set): 0.9316\n",
      "    GradientBoosting_20trees - F1-Score: 0.9326, AUC-PR: 0.9790, Accuracy (Test Set): 0.9446\n",
      "\n",
      ">>> Metalearner's results:\n",
      "\n",
      "    Super Learner - F1-Score: 0.9388, AUC-PR: 0.9808, Accuracy: 0.9479\n",
      "\n",
      ">>> Training base learners:\n",
      "\n",
      "    Training NaiveBayes with 5-fold cross-validation...\n",
      "naivebayes Model Build progress: |███████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting_10trees with 5-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting_20trees with 5-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting_50trees with 5-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Training super learner:\n",
      "\n",
      "stackedensemble Model Build progress: |██████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Base learners' results:\n",
      "\n",
      "    NaiveBayes - F1-Score: 0.8303, AUC-PR: 0.8182, Accuracy (Test Set): 0.8588\n",
      "    GradientBoosting_10trees - F1-Score: 0.9167, AUC-PR: 0.9730, Accuracy (Test Set): 0.9316\n",
      "    GradientBoosting_20trees - F1-Score: 0.9326, AUC-PR: 0.9790, Accuracy (Test Set): 0.9446\n",
      "    GradientBoosting_50trees - F1-Score: 0.9447, AUC-PR: 0.9858, Accuracy (Test Set): 0.9544\n",
      "\n",
      ">>> Metalearner's results:\n",
      "\n",
      "    Super Learner - F1-Score: 0.9471, AUC-PR: 0.9865, Accuracy: 0.9566\n",
      "\n",
      ">>> Training base learners:\n",
      "\n",
      "    Training NaiveBayes with 5-fold cross-validation...\n",
      "naivebayes Model Build progress: |███████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting_10trees with 5-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting_50trees with 5-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Training super learner:\n",
      "\n",
      "stackedensemble Model Build progress: |██████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Base learners' results:\n",
      "\n",
      "    NaiveBayes - F1-Score: 0.8303, AUC-PR: 0.8182, Accuracy (Test Set): 0.8588\n",
      "    GradientBoosting_10trees - F1-Score: 0.9167, AUC-PR: 0.9730, Accuracy (Test Set): 0.9316\n",
      "    GradientBoosting_50trees - F1-Score: 0.9447, AUC-PR: 0.9858, Accuracy (Test Set): 0.9544\n",
      "\n",
      ">>> Metalearner's results:\n",
      "\n",
      "    Super Learner - F1-Score: 0.9471, AUC-PR: 0.9865, Accuracy: 0.9566\n",
      "\n",
      ">>> Training base learners:\n",
      "\n",
      "    Training NaiveBayes with 5-fold cross-validation...\n",
      "naivebayes Model Build progress: |███████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting_10trees with 5-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Training super learner:\n",
      "\n",
      "stackedensemble Model Build progress: |██████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Base learners' results:\n",
      "\n",
      "    NaiveBayes - F1-Score: 0.8303, AUC-PR: 0.8182, Accuracy (Test Set): 0.8588\n",
      "    GradientBoosting_10trees - F1-Score: 0.9167, AUC-PR: 0.9730, Accuracy (Test Set): 0.9316\n",
      "\n",
      ">>> Metalearner's results:\n",
      "\n",
      "    Super Learner - F1-Score: 0.9268, AUC-PR: 0.9766, Accuracy: 0.9381\n",
      "\n",
      ">>> Training base learners:\n",
      "\n",
      "    Training NaiveBayes with 5-fold cross-validation...\n",
      "naivebayes Model Build progress: |███████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting_10trees with 5-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting_10trees_unbounded_D with 5-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Training super learner:\n",
      "\n",
      "stackedensemble Model Build progress: |██████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Base learners' results:\n",
      "\n",
      "    NaiveBayes - F1-Score: 0.8303, AUC-PR: 0.8182, Accuracy (Test Set): 0.8588\n",
      "    GradientBoosting_10trees - F1-Score: 0.9167, AUC-PR: 0.9730, Accuracy (Test Set): 0.9316\n",
      "    GradientBoosting_10trees_unbounded_D - F1-Score: 0.9157, AUC-PR: 0.9698, Accuracy (Test Set): 0.9294\n",
      "\n",
      ">>> Metalearner's results:\n",
      "\n",
      "    Super Learner - F1-Score: 0.9273, AUC-PR: 0.9769, Accuracy: 0.9392\n",
      "\n",
      ">>> Training base learners:\n",
      "\n",
      "    Training NaiveBayes with 5-fold cross-validation...\n",
      "naivebayes Model Build progress: |███████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting_10trees_unbounded_D with 5-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Training super learner:\n",
      "\n",
      "stackedensemble Model Build progress: |██████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Base learners' results:\n",
      "\n",
      "    NaiveBayes - F1-Score: 0.8303, AUC-PR: 0.8182, Accuracy (Test Set): 0.8588\n",
      "    GradientBoosting_10trees_unbounded_D - F1-Score: 0.9157, AUC-PR: 0.9698, Accuracy (Test Set): 0.9294\n",
      "\n",
      ">>> Metalearner's results:\n",
      "\n",
      "    Super Learner - F1-Score: 0.9241, AUC-PR: 0.9739, Accuracy: 0.9370\n",
      "\n",
      ">>> Training base learners:\n",
      "\n",
      "    Training NaiveBayes with 5-fold cross-validation...\n",
      "naivebayes Model Build progress: |███████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting_10trees_unbounded_D with 5-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting_20trees_unbounded_D with 5-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Training super learner:\n",
      "\n",
      "stackedensemble Model Build progress: |██████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Base learners' results:\n",
      "\n",
      "    NaiveBayes - F1-Score: 0.8303, AUC-PR: 0.8182, Accuracy (Test Set): 0.8588\n",
      "    GradientBoosting_10trees_unbounded_D - F1-Score: 0.9157, AUC-PR: 0.9698, Accuracy (Test Set): 0.9294\n",
      "    GradientBoosting_20trees_unbounded_D - F1-Score: 0.9272, AUC-PR: 0.9792, Accuracy (Test Set): 0.9403\n",
      "\n",
      ">>> Metalearner's results:\n",
      "\n",
      "    Super Learner - F1-Score: 0.9301, AUC-PR: 0.9818, Accuracy: 0.9414\n",
      "\n",
      ">>> Training base learners:\n",
      "\n",
      "    Training NaiveBayes with 5-fold cross-validation...\n",
      "naivebayes Model Build progress: |███████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting_10trees_unbounded_D with 5-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting_20trees_unbounded_D with 5-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training GradientBoosting_50trees_unbounded_D with 5-fold cross-validation...\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Training super learner:\n",
      "\n",
      "stackedensemble Model Build progress: |██████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Base learners' results:\n",
      "\n",
      "    NaiveBayes - F1-Score: 0.8303, AUC-PR: 0.8182, Accuracy (Test Set): 0.8588\n",
      "    GradientBoosting_10trees_unbounded_D - F1-Score: 0.9157, AUC-PR: 0.9698, Accuracy (Test Set): 0.9294\n",
      "    GradientBoosting_20trees_unbounded_D - F1-Score: 0.9272, AUC-PR: 0.9792, Accuracy (Test Set): 0.9403\n",
      "    GradientBoosting_50trees_unbounded_D - F1-Score: 0.9490, AUC-PR: 0.9848, Accuracy (Test Set): 0.9566\n",
      "\n",
      ">>> Metalearner's results:\n",
      "\n",
      "    Super Learner - F1-Score: 0.9497, AUC-PR: 0.9702, Accuracy: 0.9577\n"
     ]
    }
   ],
   "source": [
    "comparative_results_gb_nbayes = dict()\n",
    "\n",
    "for i, stack in enumerate(gradient_boosting_stacks_nbayes):\n",
    "    comparative_results_gb_nbayes[i] = train_evaluate_stack(stack, \"glm\", h2o_train, h2o_test, X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713a74e7-d0e9-4952-a906-0490d8f54256",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb9e22d-56f2-4925-ab59-730869494439",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "id": "04a37103-c637-432f-bf09-2b8007cb3606",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_to_complex01 = {                   \n",
    "    \"LogisticRegression_binomial\": H2OGeneralizedLinearEstimator(\n",
    "                        family=\"binomial\", nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "                    ), \n",
    "}\n",
    "\n",
    "simple_to_complex02 = {                   \n",
    "    \"LogisticRegression_binomial\": H2OGeneralizedLinearEstimator(\n",
    "                        family=\"binomial\", nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "                    ), \n",
    "                    \"NeuralNetwork_6\": H2ODeepLearningEstimator(\n",
    "                        hidden=[6], epochs=300, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "                    ),   \n",
    "}\n",
    "\n",
    "simple_to_complex03 = {                   \n",
    "    \"LogisticRegression_binomial\": H2OGeneralizedLinearEstimator(\n",
    "                        family=\"binomial\", nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "                    ), \n",
    "                    \"NeuralNetwork_16\": H2ODeepLearningEstimator(\n",
    "                        hidden=[16], epochs=300, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "                    ), \n",
    "}\n",
    "\n",
    "simple_to_complex04= {                   \n",
    "    \"LogisticRegression_binomial\": H2OGeneralizedLinearEstimator(\n",
    "                        family=\"binomial\", nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "                    ), \n",
    "                    \"NeuralNetwork_6\": H2ODeepLearningEstimator(\n",
    "                        hidden=[6], epochs=300, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "                    ), \n",
    "                    \"NeuralNetwork_16\": H2ODeepLearningEstimator(\n",
    "                        hidden=[16], epochs=300, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "                    ), \n",
    "}\n",
    "\n",
    "\n",
    "simple_to_complex05 = {                   \n",
    "        \"LogisticRegression_binomial\": H2OGeneralizedLinearEstimator(\n",
    "                        family=\"binomial\", nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "                    ), \n",
    "                    \"NeuralNetwork_32\": H2ODeepLearningEstimator(\n",
    "                        hidden=[32], epochs=300, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "                    ), \n",
    "}\n",
    "\n",
    "\n",
    "simple_to_complex06 = {                   \n",
    "        \"LogisticRegression_binomial\": H2OGeneralizedLinearEstimator(\n",
    "                        family=\"binomial\", nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "                    ), \n",
    "                    \"NeuralNetwork_6\": H2ODeepLearningEstimator(\n",
    "                        hidden=[6], epochs=300, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "                    ), \n",
    "                    \"NeuralNetwork_16\": H2ODeepLearningEstimator(\n",
    "                        hidden=[16], epochs=300, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "                    ), \n",
    "                    \"NeuralNetwork_32\": H2ODeepLearningEstimator(\n",
    "                        hidden=[32], epochs=300, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "                    ), \n",
    "}\n",
    "\n",
    "\n",
    "simple_to_complex07 = {            \n",
    "        \"LogisticRegression_binomial\": H2OGeneralizedLinearEstimator(\n",
    "                        family=\"binomial\", nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "                    ), \n",
    "                    \"NeuralNetwork_32_16\": H2ODeepLearningEstimator(\n",
    "                    hidden=[32, 16], epochs=300, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "                    ),\n",
    "}\n",
    "\n",
    "\n",
    "simple_to_complex08 = {         \n",
    "        \"LogisticRegression_binomial\": H2OGeneralizedLinearEstimator(\n",
    "                        family=\"binomial\", nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "                    ), \n",
    "                    \"NeuralNetwork_6\": H2ODeepLearningEstimator(\n",
    "                        hidden=[6], epochs=300, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "                    ), \n",
    "                    \"NeuralNetwork_32_16\": H2ODeepLearningEstimator(\n",
    "                    hidden=[32, 16], epochs=300, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "                    ),\n",
    "}\n",
    "\n",
    "simple_to_complex09 = {       \n",
    "        \"LogisticRegression_binomial\": H2OGeneralizedLinearEstimator(\n",
    "                        family=\"binomial\", nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "                    ), \n",
    "                    \"NeuralNetwork_6\": H2ODeepLearningEstimator(\n",
    "                        hidden=[6], epochs=300, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "                    ), \n",
    "                    \"NeuralNetwork_16\": H2ODeepLearningEstimator(\n",
    "                        hidden=[16], epochs=300, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "                    ), \n",
    "                    \"NeuralNetwork_32\": H2ODeepLearningEstimator(\n",
    "                        hidden=[32], epochs=300, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "                    ), \n",
    "                    \"NeuralNetwork_32_16\": H2ODeepLearningEstimator(\n",
    "                    hidden=[32, 16], epochs=300, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "                    ),\n",
    "\n",
    "}\n",
    "\n",
    "simple_to_complex10 = {       \n",
    "        \"LogisticRegression_binomial\": H2OGeneralizedLinearEstimator(\n",
    "                        family=\"binomial\", nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "                    ), \n",
    "                    \"NeuralNetwork_32_32\": H2ODeepLearningEstimator(\n",
    "                        hidden=[32, 32], epochs=300, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "                    ),\n",
    "}\n",
    "\n",
    "neural_net_stacks = [\n",
    "                        simple_to_complex01,\n",
    "                        simple_to_complex02,\n",
    "                        simple_to_complex03,\n",
    "                        simple_to_complex04,\n",
    "                        simple_to_complex05,\n",
    "                        simple_to_complex06,\n",
    "                        simple_to_complex07,\n",
    "                        simple_to_complex08,\n",
    "                        simple_to_complex09,\n",
    "                        simple_to_complex10\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "id": "79fc895d-96fa-4278-8048-5798dd6f31bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Training base learners:\n",
      "\n",
      "    Training LogisticRegression_binomial with 5-fold cross-validation...\n",
      "glm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Training super learner:\n",
      "\n",
      "stackedensemble Model Build progress: |██████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Base learners' results:\n",
      "\n",
      "    LogisticRegression_binomial - F1-Score: 0.9125, AUC-PR: 0.9597, Accuracy (Test Set): 0.9251\n",
      "\n",
      ">>> Metalearner's results:\n",
      "\n",
      "    Super Learner - F1-Score: 0.9125, AUC-PR: 0.9597, Accuracy: 0.9251\n",
      "\n",
      ">>> Training base learners:\n",
      "\n",
      "    Training LogisticRegression_binomial with 5-fold cross-validation...\n",
      "glm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training NeuralNetwork_6 with 5-fold cross-validation...\n",
      "deeplearning Model Build progress: |█████████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Training super learner:\n",
      "\n",
      "stackedensemble Model Build progress: |██████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Base learners' results:\n",
      "\n",
      "    LogisticRegression_binomial - F1-Score: 0.9125, AUC-PR: 0.9597, Accuracy (Test Set): 0.9251\n",
      "    NeuralNetwork_6 - F1-Score: 0.9287, AUC-PR: 0.9598, Accuracy (Test Set): 0.9403\n",
      "\n",
      ">>> Metalearner's results:\n",
      "\n",
      "    Super Learner - F1-Score: 0.9295, AUC-PR: 0.9707, Accuracy: 0.9392\n",
      "\n",
      ">>> Training base learners:\n",
      "\n",
      "    Training LogisticRegression_binomial with 5-fold cross-validation...\n",
      "glm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training NeuralNetwork_16 with 5-fold cross-validation...\n",
      "deeplearning Model Build progress: |█████████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Training super learner:\n",
      "\n",
      "stackedensemble Model Build progress: |██████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Base learners' results:\n",
      "\n",
      "    LogisticRegression_binomial - F1-Score: 0.9125, AUC-PR: 0.9597, Accuracy (Test Set): 0.9251\n",
      "    NeuralNetwork_16 - F1-Score: 0.9278, AUC-PR: 0.9583, Accuracy (Test Set): 0.9381\n",
      "\n",
      ">>> Metalearner's results:\n",
      "\n",
      "    Super Learner - F1-Score: 0.9385, AUC-PR: 0.9755, Accuracy: 0.9468\n",
      "\n",
      ">>> Training base learners:\n",
      "\n",
      "    Training LogisticRegression_binomial with 5-fold cross-validation...\n",
      "glm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training NeuralNetwork_6 with 5-fold cross-validation...\n",
      "deeplearning Model Build progress: |█████████████████████████████████████████████| (done) 100%\n",
      "    Training NeuralNetwork_16 with 5-fold cross-validation...\n",
      "deeplearning Model Build progress: |█████████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Training super learner:\n",
      "\n",
      "stackedensemble Model Build progress: |██████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Base learners' results:\n",
      "\n",
      "    LogisticRegression_binomial - F1-Score: 0.9125, AUC-PR: 0.9597, Accuracy (Test Set): 0.9251\n",
      "    NeuralNetwork_6 - F1-Score: 0.9276, AUC-PR: 0.9608, Accuracy (Test Set): 0.9392\n",
      "    NeuralNetwork_16 - F1-Score: 0.9389, AUC-PR: 0.9670, Accuracy (Test Set): 0.9479\n",
      "\n",
      ">>> Metalearner's results:\n",
      "\n",
      "    Super Learner - F1-Score: 0.9366, AUC-PR: 0.9767, Accuracy: 0.9457\n",
      "\n",
      ">>> Training base learners:\n",
      "\n",
      "    Training LogisticRegression_binomial with 5-fold cross-validation...\n",
      "glm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training NeuralNetwork_32 with 5-fold cross-validation...\n",
      "deeplearning Model Build progress: |█████████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Training super learner:\n",
      "\n",
      "stackedensemble Model Build progress: |██████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Base learners' results:\n",
      "\n",
      "    LogisticRegression_binomial - F1-Score: 0.9125, AUC-PR: 0.9597, Accuracy (Test Set): 0.9251\n",
      "    NeuralNetwork_32 - F1-Score: 0.9437, AUC-PR: 0.9627, Accuracy (Test Set): 0.9522\n",
      "\n",
      ">>> Metalearner's results:\n",
      "\n",
      "    Super Learner - F1-Score: 0.9412, AUC-PR: 0.9757, Accuracy: 0.9501\n",
      "\n",
      ">>> Training base learners:\n",
      "\n",
      "    Training LogisticRegression_binomial with 5-fold cross-validation...\n",
      "glm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training NeuralNetwork_6 with 5-fold cross-validation...\n",
      "deeplearning Model Build progress: |█████████████████████████████████████████████| (done) 100%\n",
      "    Training NeuralNetwork_16 with 5-fold cross-validation...\n",
      "deeplearning Model Build progress: |█████████████████████████████████████████████| (done) 100%\n",
      "    Training NeuralNetwork_32 with 5-fold cross-validation...\n",
      "deeplearning Model Build progress: |█████████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Training super learner:\n",
      "\n",
      "stackedensemble Model Build progress: |██████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Base learners' results:\n",
      "\n",
      "    LogisticRegression_binomial - F1-Score: 0.9125, AUC-PR: 0.9597, Accuracy (Test Set): 0.9251\n",
      "    NeuralNetwork_6 - F1-Score: 0.9265, AUC-PR: 0.9662, Accuracy (Test Set): 0.9381\n",
      "    NeuralNetwork_16 - F1-Score: 0.9309, AUC-PR: 0.9647, Accuracy (Test Set): 0.9414\n",
      "    NeuralNetwork_32 - F1-Score: 0.9346, AUC-PR: 0.9676, Accuracy (Test Set): 0.9457\n",
      "\n",
      ">>> Metalearner's results:\n",
      "\n",
      "    Super Learner - F1-Score: 0.9444, AUC-PR: 0.9788, Accuracy: 0.9522\n",
      "\n",
      ">>> Training base learners:\n",
      "\n",
      "    Training LogisticRegression_binomial with 5-fold cross-validation...\n",
      "glm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training NeuralNetwork_32_16 with 5-fold cross-validation...\n",
      "deeplearning Model Build progress: |█████████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Training super learner:\n",
      "\n",
      "stackedensemble Model Build progress: |██████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Base learners' results:\n",
      "\n",
      "    LogisticRegression_binomial - F1-Score: 0.9125, AUC-PR: 0.9597, Accuracy (Test Set): 0.9251\n",
      "    NeuralNetwork_32_16 - F1-Score: 0.9272, AUC-PR: 0.9586, Accuracy (Test Set): 0.9381\n",
      "\n",
      ">>> Metalearner's results:\n",
      "\n",
      "    Super Learner - F1-Score: 0.9319, AUC-PR: 0.9754, Accuracy: 0.9435\n",
      "\n",
      ">>> Training base learners:\n",
      "\n",
      "    Training LogisticRegression_binomial with 5-fold cross-validation...\n",
      "glm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training NeuralNetwork_6 with 5-fold cross-validation...\n",
      "deeplearning Model Build progress: |█████████████████████████████████████████████| (done) 100%\n",
      "    Training NeuralNetwork_32_16 with 5-fold cross-validation...\n",
      "deeplearning Model Build progress: |█████████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Training super learner:\n",
      "\n",
      "stackedensemble Model Build progress: |██████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Base learners' results:\n",
      "\n",
      "    LogisticRegression_binomial - F1-Score: 0.9125, AUC-PR: 0.9597, Accuracy (Test Set): 0.9251\n",
      "    NeuralNetwork_6 - F1-Score: 0.9292, AUC-PR: 0.9626, Accuracy (Test Set): 0.9403\n",
      "    NeuralNetwork_32_16 - F1-Score: 0.9257, AUC-PR: 0.9595, Accuracy (Test Set): 0.9381\n",
      "\n",
      ">>> Metalearner's results:\n",
      "\n",
      "    Super Learner - F1-Score: 0.9332, AUC-PR: 0.9781, Accuracy: 0.9446\n",
      "\n",
      ">>> Training base learners:\n",
      "\n",
      "    Training LogisticRegression_binomial with 5-fold cross-validation...\n",
      "glm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training NeuralNetwork_6 with 5-fold cross-validation...\n",
      "deeplearning Model Build progress: |█████████████████████████████████████████████| (done) 100%\n",
      "    Training NeuralNetwork_16 with 5-fold cross-validation...\n",
      "deeplearning Model Build progress: |█████████████████████████████████████████████| (done) 100%\n",
      "    Training NeuralNetwork_32 with 5-fold cross-validation...\n",
      "deeplearning Model Build progress: |█████████████████████████████████████████████| (done) 100%\n",
      "    Training NeuralNetwork_32_16 with 5-fold cross-validation...\n",
      "deeplearning Model Build progress: |█████████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Training super learner:\n",
      "\n",
      "stackedensemble Model Build progress: |██████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Base learners' results:\n",
      "\n",
      "    LogisticRegression_binomial - F1-Score: 0.9125, AUC-PR: 0.9597, Accuracy (Test Set): 0.9251\n",
      "    NeuralNetwork_6 - F1-Score: 0.9274, AUC-PR: 0.9611, Accuracy (Test Set): 0.9381\n",
      "    NeuralNetwork_16 - F1-Score: 0.9335, AUC-PR: 0.9712, Accuracy (Test Set): 0.9446\n",
      "    NeuralNetwork_32 - F1-Score: 0.9255, AUC-PR: 0.9617, Accuracy (Test Set): 0.9392\n",
      "    NeuralNetwork_32_16 - F1-Score: 0.9269, AUC-PR: 0.9531, Accuracy (Test Set): 0.9392\n",
      "\n",
      ">>> Metalearner's results:\n",
      "\n",
      "    Super Learner - F1-Score: 0.9370, AUC-PR: 0.9785, Accuracy: 0.9457\n",
      "\n",
      ">>> Training base learners:\n",
      "\n",
      "    Training LogisticRegression_binomial with 5-fold cross-validation...\n",
      "glm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "    Training NeuralNetwork_32_32 with 5-fold cross-validation...\n",
      "deeplearning Model Build progress: |█████████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Training super learner:\n",
      "\n",
      "stackedensemble Model Build progress: |██████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Base learners' results:\n",
      "\n",
      "    LogisticRegression_binomial - F1-Score: 0.9125, AUC-PR: 0.9597, Accuracy (Test Set): 0.9251\n",
      "    NeuralNetwork_32_32 - F1-Score: 0.9337, AUC-PR: 0.9611, Accuracy (Test Set): 0.9446\n",
      "\n",
      ">>> Metalearner's results:\n",
      "\n",
      "    Super Learner - F1-Score: 0.9373, AUC-PR: 0.9742, Accuracy: 0.9468\n"
     ]
    }
   ],
   "source": [
    "comparative_results_nns = dict()\n",
    "\n",
    "for i, stack in enumerate(neural_net_stacks):\n",
    "    comparative_results_nns[i] = train_evaluate_stack(stack, \"glm\", h2o_train, h2o_test, X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "id": "160742f0-46de-4c97-98e7-a96a9ffde1db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'F1-Score': 0.9125475285171102,\n",
       "  'AUC-PR': 0.9597218422898272,\n",
       "  'Accuracy': 0.9250814332247557},\n",
       " 1: {'F1-Score': 0.929471032745592,\n",
       "  'AUC-PR': 0.9706865387483506,\n",
       "  'Accuracy': 0.9391965255157437},\n",
       " 2: {'F1-Score': 0.9385194479297365,\n",
       "  'AUC-PR': 0.975450983779792,\n",
       "  'Accuracy': 0.9467969598262758},\n",
       " 3: {'F1-Score': 0.9366459627329192,\n",
       "  'AUC-PR': 0.9767069820621652,\n",
       "  'Accuracy': 0.9457111834961998},\n",
       " 4: {'F1-Score': 0.9411764705882353,\n",
       "  'AUC-PR': 0.9756518323050383,\n",
       "  'Accuracy': 0.9500542888165038},\n",
       " 5: {'F1-Score': 0.9444444444444444,\n",
       "  'AUC-PR': 0.9788064971632069,\n",
       "  'Accuracy': 0.9522258414766558},\n",
       " 6: {'F1-Score': 0.9319371727748691,\n",
       "  'AUC-PR': 0.9753691548470975,\n",
       "  'Accuracy': 0.9435396308360477},\n",
       " 7: {'F1-Score': 0.9331585845347313,\n",
       "  'AUC-PR': 0.9781172006621045,\n",
       "  'Accuracy': 0.9446254071661238},\n",
       " 8: {'F1-Score': 0.9370277078085643,\n",
       "  'AUC-PR': 0.9784595400137599,\n",
       "  'Accuracy': 0.9457111834961998},\n",
       " 9: {'F1-Score': 0.9372599231754161,\n",
       "  'AUC-PR': 0.974241852770546,\n",
       "  'Accuracy': 0.9467969598262758}}"
      ]
     },
     "execution_count": 632,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparative_results_nns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "id": "303f957b-352f-41e1-ac90-f14d666974f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_to_complex01 = {                   \n",
    "   \"NaiveBayes\": H2ONaiveBayesEstimator(nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True),\n",
    "}\n",
    "\n",
    "simple_to_complex02 = {                   \n",
    "   \"NaiveBayes\": H2ONaiveBayesEstimator(nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True),\n",
    "                    \"NeuralNetwork_6\": H2ODeepLearningEstimator(\n",
    "                        hidden=[6], epochs=300, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "                    ),   \n",
    "}\n",
    "\n",
    "simple_to_complex03 = {                   \n",
    "   \"NaiveBayes\": H2ONaiveBayesEstimator(nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True),\n",
    "                    \"NeuralNetwork_16\": H2ODeepLearningEstimator(\n",
    "                        hidden=[16], epochs=300, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "                    ), \n",
    "}\n",
    "\n",
    "simple_to_complex04= {                   \n",
    "   \"NaiveBayes\": H2ONaiveBayesEstimator(nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True),\n",
    "                    \"NeuralNetwork_6\": H2ODeepLearningEstimator(\n",
    "                        hidden=[6], epochs=300, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "                    ), \n",
    "                    \"NeuralNetwork_16\": H2ODeepLearningEstimator(\n",
    "                        hidden=[16], epochs=300, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "                    ), \n",
    "}\n",
    "\n",
    "\n",
    "simple_to_complex05 = {\n",
    "    \"NaiveBayes\": H2ONaiveBayesEstimator(nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True),\n",
    "                    \"NeuralNetwork_32\": H2ODeepLearningEstimator(\n",
    "                        hidden=[32], epochs=300, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "                    ), \n",
    "}\n",
    "\n",
    "\n",
    "simple_to_complex06 = {                   \n",
    "    \"NaiveBayes\": H2ONaiveBayesEstimator(nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True),\n",
    "                    \"NeuralNetwork_6\": H2ODeepLearningEstimator(\n",
    "                        hidden=[6], epochs=300, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "                    ), \n",
    "                    \"NeuralNetwork_16\": H2ODeepLearningEstimator(\n",
    "                        hidden=[16], epochs=300, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "                    ), \n",
    "                    \"NeuralNetwork_32\": H2ODeepLearningEstimator(\n",
    "                        hidden=[32], epochs=300, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "                    ), \n",
    "}\n",
    "\n",
    "\n",
    "simple_to_complex07 = {                   \n",
    "    \"NaiveBayes\": H2ONaiveBayesEstimator(nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True),\n",
    "                    \"NeuralNetwork_32_16\": H2ODeepLearningEstimator(\n",
    "                    hidden=[32, 16], epochs=300, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "                    ),\n",
    "}\n",
    "\n",
    "\n",
    "simple_to_complex08 = {                   \n",
    "    \"NaiveBayes\": H2ONaiveBayesEstimator(nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True),\n",
    "                    \"NeuralNetwork_6\": H2ODeepLearningEstimator(\n",
    "                        hidden=[6], epochs=300, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "                    ), \n",
    "                    \"NeuralNetwork_32_16\": H2ODeepLearningEstimator(\n",
    "                    hidden=[32, 16], epochs=300, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "                    ),\n",
    "}\n",
    "\n",
    "simple_to_complex09 = {                   \n",
    "    \"NaiveBayes\": H2ONaiveBayesEstimator(nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True),\n",
    "                    \"NeuralNetwork_6\": H2ODeepLearningEstimator(\n",
    "                        hidden=[6], epochs=300, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "                    ), \n",
    "                    \"NeuralNetwork_16\": H2ODeepLearningEstimator(\n",
    "                        hidden=[16], epochs=300, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "                    ), \n",
    "                    \"NeuralNetwork_32\": H2ODeepLearningEstimator(\n",
    "                        hidden=[32], epochs=300, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "                    ), \n",
    "                    \"NeuralNetwork_32_16\": H2ODeepLearningEstimator(\n",
    "                    hidden=[32, 16], epochs=300, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "                    ),\n",
    "\n",
    "}\n",
    "\n",
    "simple_to_complex10 = {              \n",
    "    \"NaiveBayes\": H2ONaiveBayesEstimator(nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True),\n",
    "                    \"NeuralNetwork_32_32\": H2ODeepLearningEstimator(\n",
    "                        hidden=[32, 32], epochs=300, nfolds=N_FOLDS, seed=42, keep_cross_validation_predictions=True\n",
    "                    ),\n",
    "}\n",
    "\n",
    "neural_net_stacks_nbayes = [\n",
    "                        simple_to_complex01,\n",
    "                        simple_to_complex02,\n",
    "                        simple_to_complex03,\n",
    "                        simple_to_complex04,\n",
    "                        simple_to_complex05,\n",
    "                        simple_to_complex06,\n",
    "                        simple_to_complex07,\n",
    "                        simple_to_complex08,\n",
    "                        simple_to_complex09,\n",
    "                        simple_to_complex10\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "id": "592bc5db-9cb3-431f-a3b9-9c851eca9e61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Training base learners:\n",
      "\n",
      "    Training NaiveBayes with 5-fold cross-validation...\n",
      "naivebayes Model Build progress: |███████████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Training super learner:\n",
      "\n",
      "stackedensemble Model Build progress: |██████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Base learners' results:\n",
      "\n",
      "    NaiveBayes - F1-Score: 0.8303, AUC-PR: 0.8182, Accuracy (Test Set): 0.8588\n",
      "\n",
      ">>> Metalearner's results:\n",
      "\n",
      "    Super Learner - F1-Score: 0.8303, AUC-PR: 0.8156, Accuracy: 0.8588\n",
      "\n",
      ">>> Training base learners:\n",
      "\n",
      "    Training NaiveBayes with 5-fold cross-validation...\n",
      "naivebayes Model Build progress: |███████████████████████████████████████████████| (done) 100%\n",
      "    Training NeuralNetwork_6 with 5-fold cross-validation...\n",
      "deeplearning Model Build progress: |█████████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Training super learner:\n",
      "\n",
      "stackedensemble Model Build progress: |██████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Base learners' results:\n",
      "\n",
      "    NaiveBayes - F1-Score: 0.8303, AUC-PR: 0.8182, Accuracy (Test Set): 0.8588\n",
      "    NeuralNetwork_6 - F1-Score: 0.9304, AUC-PR: 0.9623, Accuracy (Test Set): 0.9414\n",
      "\n",
      ">>> Metalearner's results:\n",
      "\n",
      "    Super Learner - F1-Score: 0.9326, AUC-PR: 0.9609, Accuracy: 0.9435\n",
      "\n",
      ">>> Training base learners:\n",
      "\n",
      "    Training NaiveBayes with 5-fold cross-validation...\n",
      "naivebayes Model Build progress: |███████████████████████████████████████████████| (done) 100%\n",
      "    Training NeuralNetwork_16 with 5-fold cross-validation...\n",
      "deeplearning Model Build progress: |█████████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Training super learner:\n",
      "\n",
      "stackedensemble Model Build progress: |██████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Base learners' results:\n",
      "\n",
      "    NaiveBayes - F1-Score: 0.8303, AUC-PR: 0.8182, Accuracy (Test Set): 0.8588\n",
      "    NeuralNetwork_16 - F1-Score: 0.9335, AUC-PR: 0.9692, Accuracy (Test Set): 0.9435\n",
      "\n",
      ">>> Metalearner's results:\n",
      "\n",
      "    Super Learner - F1-Score: 0.9359, AUC-PR: 0.9710, Accuracy: 0.9457\n",
      "\n",
      ">>> Training base learners:\n",
      "\n",
      "    Training NaiveBayes with 5-fold cross-validation...\n",
      "naivebayes Model Build progress: |███████████████████████████████████████████████| (done) 100%\n",
      "    Training NeuralNetwork_6 with 5-fold cross-validation...\n",
      "deeplearning Model Build progress: |█████████████████████████████████████████████| (done) 100%\n",
      "    Training NeuralNetwork_16 with 5-fold cross-validation...\n",
      "deeplearning Model Build progress: |█████████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Training super learner:\n",
      "\n",
      "stackedensemble Model Build progress: |██████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Base learners' results:\n",
      "\n",
      "    NaiveBayes - F1-Score: 0.8303, AUC-PR: 0.8182, Accuracy (Test Set): 0.8588\n",
      "    NeuralNetwork_6 - F1-Score: 0.9245, AUC-PR: 0.9604, Accuracy (Test Set): 0.9359\n",
      "    NeuralNetwork_16 - F1-Score: 0.9351, AUC-PR: 0.9660, Accuracy (Test Set): 0.9457\n",
      "\n",
      ">>> Metalearner's results:\n",
      "\n",
      "    Super Learner - F1-Score: 0.9368, AUC-PR: 0.9703, Accuracy: 0.9468\n",
      "\n",
      ">>> Training base learners:\n",
      "\n",
      "    Training NaiveBayes with 5-fold cross-validation...\n",
      "naivebayes Model Build progress: |███████████████████████████████████████████████| (done) 100%\n",
      "    Training NeuralNetwork_32 with 5-fold cross-validation...\n",
      "deeplearning Model Build progress: |█████████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Training super learner:\n",
      "\n",
      "stackedensemble Model Build progress: |██████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Base learners' results:\n",
      "\n",
      "    NaiveBayes - F1-Score: 0.8303, AUC-PR: 0.8182, Accuracy (Test Set): 0.8588\n",
      "    NeuralNetwork_32 - F1-Score: 0.9415, AUC-PR: 0.9714, Accuracy (Test Set): 0.9501\n",
      "\n",
      ">>> Metalearner's results:\n",
      "\n",
      "    Super Learner - F1-Score: 0.9413, AUC-PR: 0.9691, Accuracy: 0.9501\n",
      "\n",
      ">>> Training base learners:\n",
      "\n",
      "    Training NaiveBayes with 5-fold cross-validation...\n",
      "naivebayes Model Build progress: |███████████████████████████████████████████████| (done) 100%\n",
      "    Training NeuralNetwork_6 with 5-fold cross-validation...\n",
      "deeplearning Model Build progress: |█████████████████████████████████████████████| (done) 100%\n",
      "    Training NeuralNetwork_16 with 5-fold cross-validation...\n",
      "deeplearning Model Build progress: |█████████████████████████████████████████████| (done) 100%\n",
      "    Training NeuralNetwork_32 with 5-fold cross-validation...\n",
      "deeplearning Model Build progress: |█████████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Training super learner:\n",
      "\n",
      "stackedensemble Model Build progress: |██████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Base learners' results:\n",
      "\n",
      "    NaiveBayes - F1-Score: 0.8303, AUC-PR: 0.8182, Accuracy (Test Set): 0.8588\n",
      "    NeuralNetwork_6 - F1-Score: 0.9246, AUC-PR: 0.9593, Accuracy (Test Set): 0.9349\n",
      "    NeuralNetwork_16 - F1-Score: 0.9305, AUC-PR: 0.9724, Accuracy (Test Set): 0.9425\n",
      "    NeuralNetwork_32 - F1-Score: 0.9273, AUC-PR: 0.9635, Accuracy (Test Set): 0.9403\n",
      "\n",
      ">>> Metalearner's results:\n",
      "\n",
      "    Super Learner - F1-Score: 0.9376, AUC-PR: 0.9725, Accuracy: 0.9468\n",
      "\n",
      ">>> Training base learners:\n",
      "\n",
      "    Training NaiveBayes with 5-fold cross-validation...\n",
      "naivebayes Model Build progress: |███████████████████████████████████████████████| (done) 100%\n",
      "    Training NeuralNetwork_32_16 with 5-fold cross-validation...\n",
      "deeplearning Model Build progress: |█████████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Training super learner:\n",
      "\n",
      "stackedensemble Model Build progress: |██████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Base learners' results:\n",
      "\n",
      "    NaiveBayes - F1-Score: 0.8303, AUC-PR: 0.8182, Accuracy (Test Set): 0.8588\n",
      "    NeuralNetwork_32_16 - F1-Score: 0.9193, AUC-PR: 0.9506, Accuracy (Test Set): 0.9316\n",
      "\n",
      ">>> Metalearner's results:\n",
      "\n",
      "    Super Learner - F1-Score: 0.9191, AUC-PR: 0.9544, Accuracy: 0.9316\n",
      "\n",
      ">>> Training base learners:\n",
      "\n",
      "    Training NaiveBayes with 5-fold cross-validation...\n",
      "naivebayes Model Build progress: |███████████████████████████████████████████████| (done) 100%\n",
      "    Training NeuralNetwork_6 with 5-fold cross-validation...\n",
      "deeplearning Model Build progress: |█████████████████████████████████████████████| (done) 100%\n",
      "    Training NeuralNetwork_32_16 with 5-fold cross-validation...\n",
      "deeplearning Model Build progress: |█████████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Training super learner:\n",
      "\n",
      "stackedensemble Model Build progress: |██████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Base learners' results:\n",
      "\n",
      "    NaiveBayes - F1-Score: 0.8303, AUC-PR: 0.8182, Accuracy (Test Set): 0.8588\n",
      "    NeuralNetwork_6 - F1-Score: 0.9188, AUC-PR: 0.9654, Accuracy (Test Set): 0.9327\n",
      "    NeuralNetwork_32_16 - F1-Score: 0.9272, AUC-PR: 0.9490, Accuracy (Test Set): 0.9381\n",
      "\n",
      ">>> Metalearner's results:\n",
      "\n",
      "    Super Learner - F1-Score: 0.9333, AUC-PR: 0.9691, Accuracy: 0.9446\n",
      "\n",
      ">>> Training base learners:\n",
      "\n",
      "    Training NaiveBayes with 5-fold cross-validation...\n",
      "naivebayes Model Build progress: |███████████████████████████████████████████████| (done) 100%\n",
      "    Training NeuralNetwork_6 with 5-fold cross-validation...\n",
      "deeplearning Model Build progress: |█████████████████████████████████████████████| (done) 100%\n",
      "    Training NeuralNetwork_16 with 5-fold cross-validation...\n",
      "deeplearning Model Build progress: |█████████████████████████████████████████████| (done) 100%\n",
      "    Training NeuralNetwork_32 with 5-fold cross-validation...\n",
      "deeplearning Model Build progress: |█████████████████████████████████████████████| (done) 100%\n",
      "    Training NeuralNetwork_32_16 with 5-fold cross-validation...\n",
      "deeplearning Model Build progress: |█████████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Training super learner:\n",
      "\n",
      "stackedensemble Model Build progress: |██████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Base learners' results:\n",
      "\n",
      "    NaiveBayes - F1-Score: 0.8303, AUC-PR: 0.8182, Accuracy (Test Set): 0.8588\n",
      "    NeuralNetwork_6 - F1-Score: 0.9208, AUC-PR: 0.9593, Accuracy (Test Set): 0.9349\n",
      "    NeuralNetwork_16 - F1-Score: 0.9374, AUC-PR: 0.9667, Accuracy (Test Set): 0.9468\n",
      "    NeuralNetwork_32 - F1-Score: 0.9481, AUC-PR: 0.9665, Accuracy (Test Set): 0.9566\n",
      "    NeuralNetwork_32_16 - F1-Score: 0.9342, AUC-PR: 0.9536, Accuracy (Test Set): 0.9446\n",
      "\n",
      ">>> Metalearner's results:\n",
      "\n",
      "    Super Learner - F1-Score: 0.9523, AUC-PR: 0.9730, Accuracy: 0.9598\n",
      "\n",
      ">>> Training base learners:\n",
      "\n",
      "    Training NaiveBayes with 5-fold cross-validation...\n",
      "naivebayes Model Build progress: |███████████████████████████████████████████████| (done) 100%\n",
      "    Training NeuralNetwork_32_32 with 5-fold cross-validation...\n",
      "deeplearning Model Build progress: |█████████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Training super learner:\n",
      "\n",
      "stackedensemble Model Build progress: |██████████████████████████████████████████| (done) 100%\n",
      "\n",
      ">>> Base learners' results:\n",
      "\n",
      "    NaiveBayes - F1-Score: 0.8303, AUC-PR: 0.8182, Accuracy (Test Set): 0.8588\n",
      "    NeuralNetwork_32_32 - F1-Score: 0.9308, AUC-PR: 0.9618, Accuracy (Test Set): 0.9403\n",
      "\n",
      ">>> Metalearner's results:\n",
      "\n",
      "    Super Learner - F1-Score: 0.9320, AUC-PR: 0.9706, Accuracy: 0.9414\n"
     ]
    }
   ],
   "source": [
    "comparative_results_nns_nbayes = dict()\n",
    "\n",
    "for i, stack in enumerate(neural_net_stacks_nbayes):\n",
    "    comparative_results_nns_nbayes[i] = train_evaluate_stack(stack, \"glm\", h2o_train, h2o_test, X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba1f489-7ba5-4ea4-a3f0-2fc4b2aae69e",
   "metadata": {},
   "source": [
    "# BALANCE CLASSES TRUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c58787c-2653-4b46-a383-adf90700e6c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aaa8f24c-ed59-4124-ad25-41a64bb34c9f",
   "metadata": {},
   "source": [
    "## SIMPLE TO COMPLEX\n",
    "\n",
    "To try all possible combinations would be computationally unfeaseble. Therefore we chose a more naive tactic, where we examine the combination of a \n",
    "simple learner with the a few representative selections of a single class of complex learners and we choose the best performing options for combinations with others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "id": "02d78971-d365-4e4c-97a3-fdfe158b05d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "def simple_copy_dict(dct):\n",
    "    new_dct = dict()\n",
    "    for elem in dct.items():\n",
    "        new_dct[elem[0]] = elem[1] \n",
    "    return new_dct\n",
    "\n",
    "def simpler_to_complex():\n",
    "    base_learner_stacks_logistic_reg = [{list(simple_learners.items())[0][0]: list(simple_learners.items())[0][1]}]\n",
    "    for random_forest in random_forests.items():\n",
    "        base_learner_stacks_logistic_reg_snapshot = deepcopy(base_learner_stacks_logistic_reg)\n",
    "        for stack in base_learner_stacks_logistic_reg_snapshot:\n",
    "            new_stack = simple_copy_dict(stack)\n",
    "            new_stack[random_forest[0]] = random_forest[1]\n",
    "            base_learner_stacks_logistic_reg.append(new_stack)\n",
    "            for gradient_boosting in gradient_boostings.items():\n",
    "                base_learner_stacks_logistic_reg_snapshot = deepcopy(base_learner_stacks_logistic_reg)\n",
    "                for stack in base_learner_stacks_logistic_reg_snapshot:\n",
    "                    new_stack = simple_copy_dict(stack)\n",
    "                    new_stack[gradient_boosting[0]] = gradient_boosting[1]\n",
    "                    base_learner_stacks_logistic_reg.append(new_stack)\n",
    "                    for neural_network in neural_networks.items():\n",
    "                        base_learner_stacks_logistic_reg_snapshot = deepcopy(base_learner_stacks_logistic_reg)\n",
    "                        for stack in base_learner_stacks_logistic_reg_snapshot:\n",
    "                            new_stack = simple_copy_dict(stack)\n",
    "                            new_stack[neural_network[0]] = neural_network[1]\n",
    "                            base_learner_stacks_logistic_reg.append(new_stack)\n",
    "\n",
    "\n",
    "    # base_learner_stacks_naive_bayes = [{list(simple_learners.items())[1][0]: list(simple_learners.items())[1][1]}]\n",
    "    # for random_forest in random_forests.items():\n",
    "    #     for stack in base_learner_stacks_naive_bayes:\n",
    "    #         stack[random_forest[0]] = random_forest[1]\n",
    "    #         for gradient_boosting in gradient_boostings.items():\n",
    "    #             for stack in base_learner_stacks_naive_bayes:\n",
    "    #                 stack[gradient_boosting[0]] = gradient_boosting[1]\n",
    "    #                 for neural_network in neural_networks.items():\n",
    "    #                     for stack in base_learner_stacks_naive_bayes:\n",
    "    #                         stack[neural_network[0]] = neural_network[1]\n",
    "\n",
    "    # base_learner_stacks_naive_bayes_logistic_reg = [simple_learners]\n",
    "    # for random_forest in random_forests.items():\n",
    "    #     for stack in base_learner_stacks_naive_bayes_logistic_reg:\n",
    "    #         stack[random_forest[0]] = random_forest[1]\n",
    "    #         for gradient_boosting in gradient_boostings.items():\n",
    "    #             for stack in base_learner_stacks_naive_bayes_logistic_reg:\n",
    "    #                 stack[gradient_boosting[0]] = gradient_boosting[1]\n",
    "    #                 for neural_network in neural_networks.items():\n",
    "    #                     for stack in base_learner_stacks_naive_bayes_logistic_reg:\n",
    "    #                         stack[neural_network[0]] = neural_network[1]\n",
    "    return base_learner_stacks_logistic_reg#, base_learner_stacks_naive_bayes, base_learner_stacks_naive_bayes_logistic_reg\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "id": "1ddd705a-736e-4ae5-82a2-f58ebca52911",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[573], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m simpler_to_complex()\n",
      "Cell \u001b[1;32mIn[571], line 24\u001b[0m, in \u001b[0;36msimpler_to_complex\u001b[1;34m()\u001b[0m\n\u001b[0;32m     22\u001b[0m base_learner_stacks_logistic_reg\u001b[38;5;241m.\u001b[39mappend(new_stack)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m neural_network \u001b[38;5;129;01min\u001b[39;00m neural_networks\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m---> 24\u001b[0m     base_learner_stacks_logistic_reg_snapshot \u001b[38;5;241m=\u001b[39m deepcopy(base_learner_stacks_logistic_reg)\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m stack \u001b[38;5;129;01min\u001b[39;00m base_learner_stacks_logistic_reg_snapshot:\n\u001b[0;32m     26\u001b[0m         new_stack \u001b[38;5;241m=\u001b[39m simple_copy_dict(stack)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\copy.py:146\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    144\u001b[0m copier \u001b[38;5;241m=\u001b[39m _deepcopy_dispatch\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 146\u001b[0m     y \u001b[38;5;241m=\u001b[39m copier(x, memo)\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;28mtype\u001b[39m):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\copy.py:206\u001b[0m, in \u001b[0;36m_deepcopy_list\u001b[1;34m(x, memo, deepcopy)\u001b[0m\n\u001b[0;32m    204\u001b[0m append \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mappend\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m x:\n\u001b[1;32m--> 206\u001b[0m     append(deepcopy(a, memo))\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\copy.py:146\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    144\u001b[0m copier \u001b[38;5;241m=\u001b[39m _deepcopy_dispatch\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 146\u001b[0m     y \u001b[38;5;241m=\u001b[39m copier(x, memo)\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;28mtype\u001b[39m):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\copy.py:231\u001b[0m, in \u001b[0;36m_deepcopy_dict\u001b[1;34m(x, memo, deepcopy)\u001b[0m\n\u001b[0;32m    229\u001b[0m memo[\u001b[38;5;28mid\u001b[39m(x)] \u001b[38;5;241m=\u001b[39m y\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m x\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m--> 231\u001b[0m     y[deepcopy(key, memo)] \u001b[38;5;241m=\u001b[39m deepcopy(value, memo)\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\copy.py:172\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    170\u001b[0m                 y \u001b[38;5;241m=\u001b[39m x\n\u001b[0;32m    171\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 172\u001b[0m                 y \u001b[38;5;241m=\u001b[39m _reconstruct(x, memo, \u001b[38;5;241m*\u001b[39mrv)\n\u001b[0;32m    174\u001b[0m \u001b[38;5;66;03m# If is its own copy, don't memoize.\u001b[39;00m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m x:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\copy.py:271\u001b[0m, in \u001b[0;36m_reconstruct\u001b[1;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m state \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    270\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m deep:\n\u001b[1;32m--> 271\u001b[0m         state \u001b[38;5;241m=\u001b[39m deepcopy(state, memo)\n\u001b[0;32m    272\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(y, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__setstate__\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    273\u001b[0m         y\u001b[38;5;241m.\u001b[39m__setstate__(state)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\copy.py:146\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    144\u001b[0m copier \u001b[38;5;241m=\u001b[39m _deepcopy_dispatch\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 146\u001b[0m     y \u001b[38;5;241m=\u001b[39m copier(x, memo)\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;28mtype\u001b[39m):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\copy.py:231\u001b[0m, in \u001b[0;36m_deepcopy_dict\u001b[1;34m(x, memo, deepcopy)\u001b[0m\n\u001b[0;32m    229\u001b[0m memo[\u001b[38;5;28mid\u001b[39m(x)] \u001b[38;5;241m=\u001b[39m y\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m x\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m--> 231\u001b[0m     y[deepcopy(key, memo)] \u001b[38;5;241m=\u001b[39m deepcopy(value, memo)\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\copy.py:146\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    144\u001b[0m copier \u001b[38;5;241m=\u001b[39m _deepcopy_dispatch\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 146\u001b[0m     y \u001b[38;5;241m=\u001b[39m copier(x, memo)\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;28mtype\u001b[39m):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\copy.py:231\u001b[0m, in \u001b[0;36m_deepcopy_dict\u001b[1;34m(x, memo, deepcopy)\u001b[0m\n\u001b[0;32m    229\u001b[0m memo[\u001b[38;5;28mid\u001b[39m(x)] \u001b[38;5;241m=\u001b[39m y\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m x\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m--> 231\u001b[0m     y[deepcopy(key, memo)] \u001b[38;5;241m=\u001b[39m deepcopy(value, memo)\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\copy.py:137\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m memo \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    135\u001b[0m     memo \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m--> 137\u001b[0m d \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mid\u001b[39m(x)\n\u001b[0;32m    138\u001b[0m y \u001b[38;5;241m=\u001b[39m memo\u001b[38;5;241m.\u001b[39mget(d, _nil)\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _nil:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6477efa1-fb4f-4b7c-9a04-3231076ca24f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4a631f-30e6-4efd-9d3a-6bb70a6655d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fab61e9-a039-45ad-ad24-bed7bb395e46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1771b136-e8c8-4b79-b304-0368dab6f3ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45dd21c-c565-4cd7-9bf0-2f62437bb576",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea401df-3b89-42d0-94a4-1f5865f5dc1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eb35ae20-50da-4eb9-b567-8f5824082e39",
   "metadata": {},
   "source": [
    "## TRYING OUT GRID SEARCH FROM\n",
    "https://docs.h2o.ai/h2o/latest-stable/h2o-docs/data-science/stacked-ensembles.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b66844c6-9dc5-493a-89fb-c1fb41759eab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbm Grid Build progress: |███████████████████████████████████████████████████████| (done) 100%\n",
      "stackedensemble Model Build progress: |██████████████████████████████████████████| (done) 100%\n",
      "\n",
      "Super Learner - F1-Score: 0.9096, AUC-PR: 0.9690 | Super Learner Accuracy: 0.9240\n",
      "\n",
      "Final Results Comparison:\n",
      "LogisticRegression - F1-Score: 0.9125, AUC-PR: 0.9597, Accuracy: 0.9251\n",
      "RandomForest - F1-Score: 0.9375, AUC-PR: 0.9790, Accuracy: 0.9479\n",
      "GradientBoosting - F1-Score: 0.9490, AUC-PR: 0.9848, Accuracy: 0.9566\n",
      "NaiveBayes - F1-Score: 0.8303, AUC-PR: 0.8182, Accuracy: 0.8588\n",
      "Super Learner - F1-Score: 0.9096, AUC-PR: 0.9690, Accuracy: 0.9240\n"
     ]
    }
   ],
   "source": [
    "from h2o.grid.grid_search import H2OGridSearch\n",
    "\n",
    "# Specify GBM hyperparameters for the grid\n",
    "hyper_params = {\"learn_rate\": [0.01, 0.03],\n",
    "                \"max_depth\": [3, 4, 5, 6, 9],\n",
    "                \"sample_rate\": [0.7, 0.8, 0.9, 1.0],\n",
    "                \"col_sample_rate\": [0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8]}\n",
    "search_criteria = {\"strategy\": \"RandomDiscrete\", \"max_models\": 3, \"seed\": 1}\n",
    "\n",
    "# Train the grid\n",
    "grid = H2OGridSearch(model=H2OGradientBoostingEstimator(ntrees=10,\n",
    "                                                        seed=1,\n",
    "                                                        nfolds=N_FOLDS,\n",
    "                                                        fold_assignment=\"Modulo\",\n",
    "                                                        keep_cross_validation_predictions=True),\n",
    "                     hyper_params=hyper_params,\n",
    "                     search_criteria=search_criteria,\n",
    "                     grid_id=\"gbm_grid_binomial\")\n",
    "grid.train(x=list(range(X_train.shape[1])), y=\"label\", training_frame=h2o_train)\n",
    "\n",
    "# Train a stacked ensemble using the GBM grid\n",
    "super_learner = H2OStackedEnsembleEstimator(model_id=\"my_ensemble_gbm_grid_binomial\",\n",
    "                                       base_models=grid.model_ids)\n",
    "super_learner.train(x=list(range(X_train.shape[1])), y=\"label\", training_frame=h2o_train)\n",
    "\n",
    "\n",
    "\n",
    "super_performance = super_learner.model_performance(test_data=h2o_test)\n",
    "super_accuracy = super_performance.accuracy()[0][1]\n",
    "super_f1 = super_performance.F1()[0][1]  \n",
    "super_auc_pr = super_performance.aucpr()  \n",
    "print(f\"\\nSuper Learner - F1-Score: {super_f1:.4f}, AUC-PR: {super_auc_pr:.4f} | Super Learner Accuracy: {super_accuracy:.4f}\")\n",
    "\n",
    "\n",
    "print(\"\\nFinal Results Comparison:\")\n",
    "for name, metrics in results.items():\n",
    "    print(f\"{name} - F1-Score: {metrics['F1-Score']:.4f}, AUC-PR: {metrics['AUC-PR']:.4f}, Accuracy: {metrics['Accuracy']:.4f}\")\n",
    "    \n",
    "print(f\"Super Learner - F1-Score: {super_f1:.4f}, AUC-PR: {super_auc_pr:.4f}, Accuracy: {super_accuracy:.4f}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
